[
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_0",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 1,
    "text": "NIST/ITL CYBERSECURITY PROGRAM\nA N N U A L  R E P O R T\n2 0 1 6\nN I S T  S P E C I A L  P U B L I C AT I O N  8 0 0 - 1 9 5"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_1",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 2,
    "text": "THIS PAGE IS LEFT INTENTIONALLY BLANK.\nT H I S  P U B L I C AT I O N  I S  AVA I L A B L E  F R E E  O F  C H A R G E  F R O M : \nh t t p : //d x . d o i . o r g / 1 0 . 6 0 2 8 / N I S T. S P. 8 0 0 - 1 9 5"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_2",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 3,
    "text": "PATRICK O’REILLY, EDITOR\nComputer Security Division  \nInformation Technology Laboratory\n      \nKRISTINA RIGOPOULOS, EDITOR\n      Applied Cybersecurity Division \nInformation Technology Laboratory\nTHIS PUBLICATION IS AVAILABLE FREE OF CHARGE FROM\nhttps://doi.org/10.6028/NIST.SP.800-195\nSEPTEMBER 2017\nU.S. DEPARTMENT OF COMMERCE\nWilbur L. Ross, Jr., Secretary\nNATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY \nKent Rochford, Acting Under Secretary of Commerce for Standards and Technology and Acting Director\nNIST/ITL CYBERSECURITY PROGRAM\n2 0 1 6\nA N N U A L  R E P O R T\nCO-EDITORS:\nLarry Feldman\nGreg Witte\nG2, Inc.  \nAnnapolis Junction, Maryland\nT H I S  P U B L I C AT I O N  I S  AVA I L A B L E  F R E E  O F  C H A R G E  F R O M :  \nh t t p : //d x . d o i . o r g / 1 0 . 6 0 2 8 / N I S T. S P. 8 0 0 - 1 9 5"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_3",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 4,
    "text": "N I S T/ I T L  C Y B E R S E C U R I T Y  P R O G R A M  A N N U A L  R E P O R T  2 0 1 6\nI V\nN I S T/ I T L  C Y B E R S E C U R I T Y  P R O G R A M  A N N U A L  R E P O R T  2 0 1 6\nI V\nA U T H O R I T Y\n\t\nThis publication has been developed by NIST in accordance with its statutory responsibilities under \nthe Federal Information Security Modernization Act (FISMA) of 2014, 44 U.S.C. § 3541 et seq., Public Law  (P.L.) \n113-283. NIST is responsible for developing information security standards and guidelines, including minimum \nrequirements for federal information systems, but such standards and guidelines shall not apply to national \nsecurity systems without the express approval of appropriate federal officials exercising policy authority over \nsuch systems. This guideline is consistent with the requirements of the Office of Management and Budget (OMB) \nCircular A-130.\n\t\nNothing in this publication should be taken to contradict the standards and guidelines made mandatory \nand binding on federal agencies by the Secretary of Commerce under statutory authority. Nor should these \nguidelines be interpreted as altering or superseding the existing authorities of the Secretary of Commerce, \nDirector of the OMB, or any other federal official.  This publication may be used by nongovernmental \norganizations on a voluntary basis and is not subject to copyright in the United States. Attribution would, \nhowever, be appreciated by NIST.  \nNational Institute of Standards and Technology Special Publication 800-195 \nNatl. Inst. Stand. Technol. Spec. Publ. 800-195, 156 pages (September 2017) \nCODEN: NSPUE2\nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-195\nR E P O R T S  O N  C O M P U T E R  S Y S T E M S  T E C H N O L O G Y\n\t\nThe Information Technology Laboratory (ITL) at the National Institute of Standards and Technology \n(NIST) promotes the U.S. economy and public welfare by providing technical leadership for the Nation’s \nmeasurement and standards infrastructure. ITL develops tests, test methods, reference data, proof of concept \nimplementations, and technical analyses to advance the development and productive use of information \ntechnology. ITL’s responsibilities include the development of management, administrative, technical, and \nphysical standards and guidelines for the cost-effective security and privacy of other than national security-\nrelated information in federal information systems. The Special Publication 800-series reports on ITL’s research, \nguidelines, and outreach efforts in information system security, and its collaborative activities with industry, \ngovernment, and academic organizations.\nT H I S  P U B L I C AT I O N  I S  AVA I L A B L E  F R E E  O F  C H A R G E  F R O M : \nh t t p : //d x . d o i . o r g / 1 0 . 6 0 2 8 / N I S T. S P. 8 0 0 - 1 9 5"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_4",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 5,
    "text": "V\nA C K N O W L E D G M E N T S   |   F Y  2 0 1 6\nV\nA C K N O W L E D G M E N T S\nThe editors, Patrick O’Reilly of the Computer Security Division \n(CSD) and Kristina Rigopoulos of the Applied Cybersecurity Division \n(ACD), would like to thank their ITL colleagues who provided write-\nups on their 2016 project highlights and accomplishments for this \nannual report (their names are mentioned after each project write-\nup). The editors would also like to acknowledge Elaine Barker (CSD), \nLisa Carnahan (Standards Coordination Office, NIST), Greg Witte and \nLarry Feldman (G2) for reviewing and providing valuable feedback for \nthis annual report.\nThe editors would also like to acknowledge Kristen Dill of Dill and \nCompany, Inc. for designing the cover and inside layout for this 2016 \nannual report.\n \nD I S C L A I M E R\nAny mention of commercial products or organizations is for \ninformational purposes only; it is not intended to imply recommendation \nor endorsement by the National Institute of Standards and Technology, \nnor is it intended to imply that the products identified are necessarily \nthe best available for the purpose.\nT R A D E M A R K  I N F O R M AT I O N\nAll names are trademarks or registered trademarks of their \nrespective owners.\nT H I S  P U B L I C AT I O N  I S  AVA I L A B L E  F R E E  O F  C H A R G E  F R O M :  \nh t t p : //d x . d o i . o r g / 1 0 . 6 0 2 8 / N I S T. S P. 8 0 0 - 1 9 5"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_5",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 6,
    "text": "N I S T/ I T L  C Y B E R S E C U R I T Y  P R O G R A M  A N N U A L  R E P O R T  2 0 1 6\nV I\nN I S T/ I T L  C Y B E R S E C U R I T Y  P R O G R A M  A N N U A L  R E P O R T  2 0 1 6\nV I\nACKNOWLEDGMENTS....................................................................................................................................................................V\nDISCLAIMER....................................................................................................................................................................................V\nTRADEMARK INFORMATION..........................................................................................................................................................V\nWELCOME LETTER...........................................................................................................................................................................1\nBACKGROUND INFORMATION OF ANNUAL REPORT................................................................................................................... 3\nTHE INFORMATION TECHNOLOGY LABORATORY IMPLEMENTS THE FEDERAL INFORMATION SECURITY  \nMANAGEMENT ACT........................................................................................................................................................................4\nITL CYBERSECURITY PROGRAM ACCOMPLISHMENTS FOR FISCAL YEAR 2016........................................................................ 9\nITL INVOLVEMENT WITH NATIONAL AND INTERNATIONAL IT SECURITY STANDARDS......................................................... 10\nFocus on ISO and ANSI Standardization (ISO/IEC JTC1 SC27 IT Security)..................................................................................10\nIT Security Techniques Standards......................................................................................................................................................10\nNext Generation Access Control Standards.......................................................................................................................................11\nISO Standardization of Security Requirements for Cryptographic Modules................................................................................11\nIdentity Management Devices and Infrastructures Standards (JTC1 SC17 Cards and Personal Identification Devices)........13\nCloud Computing Standards Within ISO/IEC JTC 1/SC 38 Cloud Computing and INCITS Cloud 38........................................13\nBiometric Standards and Associated Conformity Assessment Testing Tools..............................................................................14 \nRISK MANAGEMENT......................................................................................................................................................................14\nFramework for Improving Critical Infrastructure Cybersecurity (Cybersecurity Framework)..................................................14\nFederal Information Security Management Act (FISMA) Implementation Project.....................................................................15\nPrivacy Engineering Program.............................................................................................................................................................17\nCyber Supply Chain Risk Management (SCRM)...............................................................................................................................19\nBIOMETRIC STANDARDS AND ASSOCIATED CONFORMITY ASSESSMENT TESTING TOOLS...................................................21\nSECURITY OF CYBER-PHYSICAL AND INDUSTRIAL CONTROL SYSTEMS......................................................................................22\nSecurity of Cyber Physical Systems.................................................................................................................................................. 22\nCybersecurity for Industrial Control Systems.................................................................................................................................. 23\nFEDERAL CYBERSECURITY RESEARCH & DEVELOPMENT (R&D)............................................................................................. 23\nSECURITY ASPECTS OF ELECTRONIC VOTING...........................................................................................................................24\nSOFTWARE ASSURANCE & RELIABILITY....................................................................................................................................24\nCOMPUTER FORENSICS............................................................................................................................................................... 25\nNATIONWIDE PUBLIC SAFETY BROADBAND NETWORK (NPSBN) CYBERSECURITY.............................................................26\nSMART GRID CYBERSECURITY.................................................................................................................................................... 27\nCYBERSECURITY AWARENESS, TRAINING, EDUCATION, AND OUTREACH............................................................................. 28\nNational Initiative for Cybersecurity Education (NICE)................................................................................................................. 28\nComputer Security Resource Center (CSRC)................................................................................................................................... 29\nFederal Computer Security Managers’ (FCSM) Forum..................................................................................................................30\nFederal Information Systems Security Educators’ Association (FISSEA)............................................................................................................31\nInformation Security and Privacy Advisory Board (ISPAB).......................................................................................................... 33\nSmall and Medium Size Business (SMB) Cybersecurity Outreach Workshop............................................................................. 35\nCRYPTOGRAPHIC STANDARDS PROGRAM.................................................................................................................................36"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_6",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 6,
    "text": "28\nComputer Security Resource Center (CSRC)................................................................................................................................... 29\nFederal Computer Security Managers’ (FCSM) Forum..................................................................................................................30\nFederal Information Systems Security Educators’ Association (FISSEA)............................................................................................................31\nInformation Security and Privacy Advisory Board (ISPAB).......................................................................................................... 33\nSmall and Medium Size Business (SMB) Cybersecurity Outreach Workshop............................................................................. 35\nCRYPTOGRAPHIC STANDARDS PROGRAM.................................................................................................................................36\nSecure Hash Algorithm-3 (SHA-3) Derived Functions (NIST SP 800-185)................................................................................. 36\nRandom Number Generation (RNG)................................................................................................................................................. 36\nBlock Cipher Modes of Operation..................................................................................................................................................... 38\nKey Management................................................................................................................................................................................. 38\nTransport Layer Security....................................................................................................................................................................42\nElliptic Curve Cryptography...............................................................................................................................................................42\nPost-Quantum Cryptography............................................................................................................................................................43\nCircuit Complexity...............................................................................................................................................................................43\nLightweight Cryptography.................................................................................................................................................................45\nThe NIST Randomness Beacon..........................................................................................................................................................45\nTABLE OF CONTENTS\nT H I S  P U B L I C AT I O N  I S  AVA I L A B L E  F R E E  O F  C H A R G E  F R O M : \nh t t p : //d x . d o i . o r g / 1 0 . 6 0 2 8 / N I S T. S P. 8 0 0 - 1 9 5"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_7",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 7,
    "text": "V I I\nTA B L E  O F  C O N T E N T S   |   F Y  2 0 1 6\nV I I\nCryptography Applications in Wireless and Mobile Security........................................................................................................46\nBlockchains...........................................................................................................................................................................................46\nEntropy as a Service (EaaS)............................................................................................................................................................... 47\nAutomated Cryptographic Validation Testing.................................................................................................................................48\nVALIDATION PROGRAMS.............................................................................................................................................................50\nCryptographic Programs and Laboratory Accreditation...............................................................................................................50\nThe Cryptographic Algorithm Validation Program (CAVP)........................................................................................................... 52\nAutomated Security Testing and Test Suite Development............................................................................................................ 55\nSecurity Content Automation Protocol (SCAP) Validation Program........................................................................................... 57\nIDENTITY AND ACCESS MANAGEMENT......................................................................................................................................59\nNIST Personal Identity Verification Program (NPIVP)................................................................................................................... 59\nPersonal Identity Verification (PIV) and FIPS 201 Revision Efforts.............................................................................................60\nAuthentication......................................................................................................................................................................................61\nAccess Control and Privilege Management..................................................................................................................................... 62\nConformance Verification for Access Control Policies................................................................................................................... 63\nAttribute-Based Access Control........................................................................................................................................................ 65\nTrusted Identities Group (TIG)..........................................................................................................................................................66\nRESEARCH IN EMERGING TECHNOLOGIES.................................................................................................................................69\nSecure Development Toolchain Competitions................................................................................................................................69\nNetworks of “Things”..........................................................................................................................................................................69\nCloud Computing Security and Forensics........................................................................................................................................70\nCSD Role in the NIST Cloud Computing Program................................................................................................................................................71\nPolicy Machine – Next Generation Access Control..............................................................................................................................................72\nSecurity for a Virtualized Infrastructure..................................................................................................................................................................73\nCyber Threat Information Sharing.................................................................................................................................................... 73\nThe Ontology of Authentication....................................................................................................................................................... 74\nNATIONAL CYBERSECURITY CENTER OF EXCELLENCE............................................................................................................ 76\nINTERNET INFRASTRUCTURE PROTECTION.............................................................................................................................. 79\nADVANCED SECURITY TESTING AND MEASUREMENTS............................................................................................................ 82\nSecurity Automation and Continuous Monitoring.......................................................................................................................... 82\nSpecification, Standards, and Guidance Development.....................................................................................................................................82\nSecurity Content Automation Protocol (SCAP)...................................................................................................................................................83\nSoftware Asset Management Standards.................................................................................................................................................................85\nDevelopment of Security Automation Consensus Standards....................................................................................................................... 86\nSecurity Automation Reference Data............................................................................................................................................... 87\nNational Vulnerability Database (NVD)...................................................................................................................................................................87\nNational Checklist Program (NCP)............................................................................................................................................................................88\nApple OS X Security Configuration.......................................................................................................................................................................... 89\nTECHNICAL SECURITY METRICS..................................................................................................................................................91 \nSecurity Risk Analysis of Enterprise Networks Using Attack Graphs...........................................................................................91\nAlgorithms for Intrusion Measurement.............................................................................................................................................91\nAutomated Combinatorial Testing.................................................................................................................................................... 92\nRoots of Trust....................................................................................................................................................................................... 93\nUSABILITY AND SECURITY..........................................................................................................................................................94\nHONORS AND AWARDS............................................................................................................................................................... 97\nITL CYBERSECURITY PROGRAM PUBLICATIONS RELEASED IN FY 2016............................................................................... 103\nITL CYBERSECURITY PROGRAM RELATED PUBLICATIONS..................................................................................................... 109\nNIST Technical Series Publications and Other NIST Publications................................................................................................ 110\nAbstracts of Publications Released in FY 2016............................................................................................................................... 111\nNIST Technical Series Publications and Other NIST Publications................................................................................................127\nAPPENDIX A: ACRONYMS...........................................................................................................................................................137\nAPPENDIX B: NIST CYBERSECURITY EVENTS HELD D"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_8",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 7,
    "text": "............................................................................... 103\nITL CYBERSECURITY PROGRAM RELATED PUBLICATIONS..................................................................................................... 109\nNIST Technical Series Publications and Other NIST Publications................................................................................................ 110\nAbstracts of Publications Released in FY 2016............................................................................................................................... 111\nNIST Technical Series Publications and Other NIST Publications................................................................................................127\nAPPENDIX A: ACRONYMS...........................................................................................................................................................137\nAPPENDIX B: NIST CYBERSECURITY EVENTS HELD DURING FY 2016....................................................................................145\nAPPENDIX C: OPPORTUNITIES TO ENGAGE WITH ITL CYBERSECURITY PROGRAM AND NIST DURING FY 2017-2018......147\nTABLE OF CONTENTS\nT H I S  P U B L I C AT I O N  I S  AVA I L A B L E  F R E E  O F  C H A R G E  F R O M :  \nh t t p : //d x . d o i . o r g / 1 0 . 6 0 2 8 / N I S T. S P. 8 0 0 - 1 9 5"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_9",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 8,
    "text": "THIS PAGE IS LEFT INTENTIONALLY BLANK.\nT H I S  P U B L I C AT I O N  I S  AVA I L A B L E  F R E E  O F  C H A R G E  F R O M : \nh t t p : //d x . d o i . o r g / 1 0 . 6 0 2 8 / N I S T. S P. 8 0 0 - 1 9 5"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_10",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 9,
    "text": "W E L C O M E  L E T T E R   |   F Y  2 0 1 6\n1\nWELCOME LETTER\n  Awareness about the importance of strong cybersecurity for maintaining trust in the economy and protecting the \nnation is at an all-time high. So, too, are the challenges. When it comes to cybersecurity, the National Institute of Standards \nand Technology (NIST) has a long history of conducting path-breaking research and development, cultivating standards \nand best practices, and facilitating technology transitions. We rely on open, transparent, and collaborative processes that \nengage private and public sector participation and attract expertise from around the world. This 2016 report captures our \nmost noteworthy accomplishments.\nIn 2016, NIST continued to advance fundamental research to support security and interoperability standards and \nguidelines. This work was led by the Computer Security Division (CSD) in the NIST Information Technology Laboratory \n(ITL). Among other things, CSD is responsible for developing cybersecurity standards, guidelines, tests, and metrics for \nthe protection of non-national security federal information systems. Recognizing the agency’s need to respond to and \nanticipate increasing demands for its cybersecurity expertise, NIST established the Applied Cybersecurity Division (ACD) \nwithin ITL to support additional applied research and to transition effective cybersecurity technology approaches to \ngovernment and business sectors nationwide. ACD helps to drive the adoption of appropriate cybersecurity solutions by \ngovernment and commercial organizations – enabling solutions-oriented collaborative interactions and offering guidance \non the use of research results, standards, and best practices. Other parts of NIST also are key contributors to NIST’s \ncybersecurity portfolio.\nStrong partnerships with industry, academia and government are critical to NIST’s cybersecurity program. In 2016, \nNIST continued to collaborate with stakeholders from across the country and around the world to raise awareness and \nencourage use of the voluntary Cybersecurity Framework. In this spirit, NIST began to develop an update to the version first \npublished in 2014. NIST also prepared a draft Cybersecurity Framework profile aligned with manufacturing sector goals and \nindustry best practices. In addition, NIST developed the draft Baldrige Cybersecurity Excellence Builder self-assessment tool \nthat complements the Cybersecurity Framework and helps organizations to better understand the effectiveness of their \ncybersecurity risk management efforts.\nLooking ahead is vital in the realm of cybersecurity. Knowing that if large-scale quantum computers are ever built, \nthey will be able to break many of the public-key cryptosystems currently in use and compromise the confidentiality and \nintegrity of digital communication on the Internet and elsewhere, NIST is working closely with the academic community and \nindustry to develop protective cryptographic standards that we all rely upon. Building on its successful tradition of working \nopenly with the worldwide cryptographic community, in 2016 NIST called for submissions for quantum-resistant public-key \ncryptographic algorithms for standards. These algorithms must be secure against both quantum and classical computers, \nand should interoperate with existing communications protocols and networks. After submissions are received late in \n2017, NIST plans to spend 3-5 years working with the research community and industry to analyze the candidates before \nselecting algorithms for standardization.\nIdentity management is fundamental to security management. In 2016, NIST continued to advance solutions in identity \nmanagement through projects with partners who manage innovative but practical real-world solutions. Also in the past \nyear, NIST produced an introduction to the concepts of privacy engineering and risk management for federal information \nsystems. The goal is to help decrease privacy risks and enable organizations to make purposeful decisions about resource \nallocation and effective"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_11",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 9,
    "text": " and industry to analyze the candidates before \nselecting algorithms for standardization.\nIdentity management is fundamental to security management. In 2016, NIST continued to advance solutions in identity \nmanagement through projects with partners who manage innovative but practical real-world solutions. Also in the past \nyear, NIST produced an introduction to the concepts of privacy engineering and risk management for federal information \nsystems. The goal is to help decrease privacy risks and enable organizations to make purposeful decisions about resource \nallocation and effective implementation of controls in information systems. NIST also initiated an update to our Digital \nT H I S  P U B L I C AT I O N  I S  AVA I L A B L E  F R E E  O F  C H A R G E  F R O M :  \nh t t p : //d x . d o i . o r g / 1 0 . 6 0 2 8 / N I S T. S P. 8 0 0 - 1 9 5"
  },
  {
    "chunk_id": "2016 NIST_ITL Cybersecurity Program Annual Report_first10_chunk_12",
    "filename": "2016 NIST_ITL Cybersecurity Program Annual Report_first10.pdf",
    "page_num": 10,
    "text": "N I S T/ I T L  C Y B E R S E C U R I T Y  P R O G R A M  A N N U A L  R E P O R T  2 0 1 6\n2\n\t\nC Y E R S E C U R I T Y  O F  C Y B E R - P H Y S I C A L  S Y S T E M S  | C P S\nIdentity Guideline (Special Publication 800-63), which provides technical guidelines to agencies for the implementation \nof digital authentication. Building from these foundational resources, NIST’s efforts will focus on strengthening the \nsecurity, privacy, usability and interoperability of digital identity solutions that meet an organization’s identity and access \nmanagement needs throughout the system lifecycle.\nDuring 2016, NIST’s National Cybersecurity Center of Excellence (NCCoE) moved into a new permanent facility that \nexpanded the Center’s workspace from four to 23 separate, flexible laboratories—including two larger areas capable of \nsafely hosting large equipment, such as automobiles. This additional space allows NCCoE to increase its collaborations \nand projects. In 2016, the Center published draft practice guides to support industry sectors, including healthcare, financial \nservices, and energy; these guides are now beginning to be put to productive use. NCCoE also published draft documents \nto support security in key technology areas, such as cloud computing and mobile applications.\nThe National Initiative for Cybersecurity Education (NICE), led by NIST, is a partnership between government, academia, \nand the private sector that is focused on promoting a robust network and an ecosystem of cybersecurity education, \ntraining, and workforce development. In 2016, NIST released an update to the NICE Cybersecurity Workforce Framework \n(NCWF); it already is being used in the private and public sectors to more effectively identify, recruit, develop and maintain \ncybersecurity talent. The NICE framework provides a common language to categorize and describe cybersecurity work that \nhelps organizations to build a strong staff to protect systems and data.\nOur dedicated staff has accomplished a great deal in 2016, developing standards and working closely with scores \nof partners and drawing upon hundreds of private and public sector organizations and individuals. This is not a static \nendeavor. For example, NIST is fully aware of the urgent need to more aggressively address the security challenges of the \nInternet of Things and, more broadly, our connected world.\nWe welcome any and all suggestions about where and how we can better provide the nation with the kind of \ncybersecurity information and tools that it needs in order to advance and protect our economy and our country.\nDonna F. Dodson, \nChief Cybersecurity Advisor\nWELCOME LETTER\nT H I S  P U B L I C AT I O N  I S  AVA I L A B L E  F R E E  O F  C H A R G E  F R O M : \nh t t p : //d x . d o i . o r g / 1 0 . 6 0 2 8 / N I S T. S P. 8 0 0 - 1 9 5"
  },
  {
    "chunk_id": "2020 Cybersecurity and Privacy Annual Report_first10_chunk_0",
    "filename": "2020 Cybersecurity and Privacy Annual Report_first10.pdf",
    "page_num": 1,
    "text": "Cybersecurity and \nPrivacy Annual Report\nNIST SPECIAL PUBLICATION 800-214\n2020"
  },
  {
    "chunk_id": "2020 Cybersecurity and Privacy Annual Report_first10_chunk_1",
    "filename": "2020 Cybersecurity and Privacy Annual Report_first10.pdf",
    "page_num": 2,
    "text": "PATRICK O’REILLY, EDITOR\nComputer Security Division  \nInformation Technology Laboratory\n  CO-EDITORS:\nLarry Feldman\nGreg Witte\nHuntington Ingalls Industries\nAnnapolis Junction, Maryland\nU.S. DEPARTMENT OF COMMERCE\nGina M. Raimondo, Secretary\nNATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY\nJames K. Olthoff, Performing the Non-Exclusive Functions and Duties of the Under Secretary of Commerce\nfor Standards and Technology & Director, National Institute of Standards and Technology \nTHIS PUBLICATION IS AVAILABLE FREE OF CHARGE FROM \nhttps://doi.org/10.6028/NIST.SP.800-214\nSEPTEMBER 2021\nKRISTINA RIGOPOULOS, EDITOR\nApplied Cybersecurity Division  \nInformation Technology Laboratory\n2020 Cybersecurity and \nPrivacy Annual Report"
  },
  {
    "chunk_id": "2020 Cybersecurity and Privacy Annual Report_first10_chunk_2",
    "filename": "2020 Cybersecurity and Privacy Annual Report_first10.pdf",
    "page_num": 3,
    "text": "Table of Contents\nForeword..........................................................................................................................................................  1\nFocus Area 1: Cybersecurity Awareness and Education............................................................................  2\nFocus Area 2: Identity and Access Management........................................................................................  4\nFocus Area 3: Metrics and Measurement....................................................................................................  7\nFocus Area 4: Risk Management...................................................................................................................10\nFocus Area 5: Privacy Engineering...............................................................................................................14\nFocus Area 6: Emerging Technologies.........................................................................................................16\nFocus Area 7: Cryptographic Standards and Validation...........................................................................19\nFocus Area 8: Trustworthy Networks...........................................................................................................23\nFocus Area 9: Trustworthy Platforms...........................................................................................................27\nITL Leadership and Participation in National and International Standards Programs........................30\nOpportunities to Engage with the NIST Cybersecurity & Privacy Program..........................................31"
  },
  {
    "chunk_id": "2020 Cybersecurity and Privacy Annual Report_first10_chunk_3",
    "filename": "2020 Cybersecurity and Privacy Annual Report_first10.pdf",
    "page_num": 4,
    "text": "NIST CYBERSECURITY & PRIVACY ANNUAL REPORT - FY2020\nPAGE 1\nWith each day bringing new cybersecurity and privacy challenges and \nadvances, it is little wonder that many leaders feel as if they have been cast \nin the role of the Red Queen in Lewis Carroll’s “Through the Looking-Glass.” In \nthat classic, the Queen tells Alice: \"Now, here, you see, it takes all the running \nyou can do to keep in the same place. If you want to get somewhere else, you \nmust run at least twice as fast as that!\"\nIt is true that leaders need to be nimble and move quickly to avoid the \nconsequences of cybersecurity and privacy attacks that threaten \ntheir enterprises. That need extends to government agencies, like NIST, \nthat are trying to help meet those urgent challenges. \nAt NIST, we know that – in addition to current needs – we also have a responsibility to keep an \neye on the horizon, anticipating technology changes, threat environments, and cultural shifts \nthat could affect the ability of organizations to manage cybersecurity and privacy risks.\nWe've successfully carried out our work for nearly 50 years precisely because we not only \naddress near-term challenges but also spend time thinking, exploring, listening, and speaking \nwith others about the really big issues in store for all of us. We tackle current issues, but we \nalso play the long game – the infinite game, if you will. We are mindful of the reality that \ncybersecurity and privacy challenges are evolving. At NIST, we make it our business to help \nothers be prepared by anticipating needs and creating opportunities. We anchor our decisions \nwith our feet firmly planted in both the present and the future. As you read this report about our \nefforts and accomplishments in 2020, you will understand how we have been addressing both \nshort-term and long-term needs.\nFor example, in the cryptographic arena, we are not only providing and improving practical \ntools and services for today, we also are rapidly moving forward to ensure that Post-Quantum \nCryptography standards are ready when quantum computing becomes a real threat to \nthe protective algorithms that we all take for granted. We have been integrating privacy \nconsiderations into the basic control suites that so many organizations rely on now, and we are \nwidening our privacy focus to encompass the broader privacy concerns that arise as mobile \ncomputing, e-commerce, and the Internet of Things advance. The intentional addition of the \nword “privacy” in this report’s title reflects changing technological capabilities and society’s \nexpectations.\nThis year’s annual report is grouped into nine priority areas for NIST, with most – but not all \n– of the work being conducted by our Information Technology Laboratory (ITL) and in close\ncollaboration with the private and public sectors. While these represent areas that NIST believes\nmerit the bulk of our attention for the foreseeable future, the report also includes other specific\nprojects of importance that do not fit neatly into these buckets.\nAll of this work adds up to cultivating trust in information, systems, and technologies. That’s \nour charge. That’s our reason for being. I encourage you to review our recent progress and to \nhelp us look well beyond the here-and-now of technology, cybersecurity, and privacy; this will \nenable all of us to meet the future with confidence that we can manage the emerging risks and \nchange the world for the better for the next 50 years.\nKevin Stine\nNIST Chief Cybersecurity Advisor\nForeword"
  },
  {
    "chunk_id": "2020 Cybersecurity and Privacy Annual Report_first10_chunk_4",
    "filename": "2020 Cybersecurity and Privacy Annual Report_first10.pdf",
    "page_num": 5,
    "text": "NIST CYBERSECURITY & PRIVACY ANNUAL REPORT - FY2020\nPAGE 2\n1 | Cybersecurity Awareness and Education\nNIST continues to coordinate a National Cybersecurity Awareness and Education Program that \nincludes activities such as the widespread dissemination of cybersecurity technical standards \nand best practices; efforts to make cybersecurity best practices usable by a variety of individuals \nand stakeholders; increasing public awareness of cybersecurity, cyber safety, and cyber ethics; \nincreasing the understanding of the benefits of ensuring effective risk management of \ninformation technology and the methods to mitigate and to remediate vulnerabilities; \nsupporting formal cybersecurity education programs at all levels to prepare and improve a \nskilled cybersecurity workforce; and promoting initiatives to evaluate and forecast future \ncybersecurity workforce needs of the Federal Government and develop strategies for \nrecruitment, training, and retention. \nNational Initiative for Cybersecurity Education \nThe National Initiative for Cybersecurity Education (NICE) is a partnership among government, \nacademia, and the private sector. NICE is focused on cybersecurity education, training, \nand workforce development. NIST's leadership of the program helps position it to \nsupport the country’s ability to address current and future cybersecurity challenges through \nstandards and best practices.\nNICE's mission is to energize and promote a robust network and ecosystem of \ncybersecurity education, training, and workforce development. This mission supports the \nvision of helping to secure the nation by increasing the number of skilled cybersecurity \nprofessionals.\nCredit: Shutterstock"
  },
  {
    "chunk_id": "2020 Cybersecurity and Privacy Annual Report_first10_chunk_5",
    "filename": "2020 Cybersecurity and Privacy Annual Report_first10.pdf",
    "page_num": 6,
    "text": "NIST CYBERSECURITY & PRIVACY ANNUAL REPORT - FY2020\nPAGE 3\nIn Fiscal Year (FY) 2020, the National Initiative for Cybersecurity Education (NICE) finalized \ntwo publications. The first, NIST Interagency or Internal Report (NISTIR) 8287, A Roadmap for \nSuccessful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity \nWorkforce, provides a summary of how to create ecosystems and partnerships to stimulate \ncybersecurity education and workforce development.\nThe second, NIST Special Publication (SP) 1500-16, Improving Veteran Transitions to Civilian \nCybersecurity Roles: Workshop Report, presents the findings and recommendations from \na workshop on how to help transitioning military members discover opportunities in the \ncybersecurity workforce.\nNICE also curated a webpage for free and low-cost online cybersecurity learning content. At a \ntime when many are transitioning to remote learning or considering a job or career change, this \nresource provided links to training courses, labs, and curriculum for the purposes of progressing \ntoward new skills or credentials in cybersecurity.\nNICE hosted several events in FY 2020. In addition to monthly webinars, NICE held two annual \nconferences – the NICE Conference and Expo in Phoenix, Arizona, which had more than \n800 registrants; and the NICE K12 Cybersecurity Education Conference in Garden Grove, \nCalifornia, which had more than 450 registrants. NICE also conducted a workshop on Use \nCases for the NICE Framework and the annual National Cybersecurity Career Awareness \nWeek where organizations from around the world held virtual and in-person events to \nhelp inspire and promote awareness and exploration of cybersecurity careers.\nAdvancing Cybersecurity Usability\nNIST has popularized the “Phish Scale” as a method to better characterize an organization’s \nphishing risk. The scale considers phishing cues and user context to help Chief Information \nSecurity Officers and phishing training implementers rate the difficulty of their organizations’ \nphishing exercises and explain associated click rates. NIST’s Video and Digital Media Production \nGroup created a video for the Phish Scale, and research results were published in the Journal of \nCybersecurity and highlighted in a NIST article that garnered media attention across industry, \ngovernment, and academia.\nNIST also completed an in-depth interview study to understand consumers’ challenges, \nperceptions, and experiences related to smart home security and privacy. The results of the \nstudy inform the Internet of Things (IoT) security and privacy guidelines by identifying current \ngaps in users’ experiences and suggesting how smart home devices might be designed to \nbetter integrate usability, privacy, and security. The capstone paper describing the results will \nbe published in the proceedings of the 2021 USENIX Security Symposium.\nSmall Business Cybersecurity Corner\nIn FY 2020, the Small Business Cybersecurity Corner website organization and design were \nupdated based on the results of a usability study conducted by a set of small business owners.\nIn addition to facilitating access to many popular small business security resources, the \nlanguage of the site was updated to be more accessible and relatable to the small business \ncommunity. Training materials and accompanying resources continue to be expanded based \non cybersecurity resources and feedback received from NIST’s federal partners and the public."
  },
  {
    "chunk_id": "2020 Cybersecurity and Privacy Annual Report_first10_chunk_6",
    "filename": "2020 Cybersecurity and Privacy Annual Report_first10.pdf",
    "page_num": 7,
    "text": "NIST CYBERSECURITY & PRIVACY ANNUAL REPORT - FY2020\nPAGE 4\n2 | Identity and Access Management \nCredit: Shutterstock\nIdentity and Access Management (IdAM) is a fundamental and critical cybersecurity capability \nto ensure that the right people have the appropriate access to the proper resources at the right \ntime. To advance the state of identity and access management, NIST:\n•\nConducts focused research to better understand new and emerging technologies,\nimpacts on existing standards, and ways to implement IdAM solutions;\n•\nLeads in the development of national and international IdAM standards, guidance,\nbest practices, profiles, and frameworks to create an enhanced, interoperable suite of\nsecure, privacy-enhancing solutions;\n•\nEvolves its IdAM standards, guidelines, and resources; and\n•\nProduces example solutions that bring together the IdAM requirements needed to\naddress specific business cybersecurity challenges.\nIdAM is an important component of cloud computing security, and NIST publishes access control \ncharacteristics and general access control guidelines for various cloud service models.  NIST also \nperforms research and development regarding access control rules and methods.\nPersonal Identity Verification (PIV)\nAs required by Homeland Security Presidential Directive 12, NIST developed and maintains \nthe Federal Information Processing Standard (FIPS) for personal identity verification (PIV) of \nfederal employees and contractors (FIPS 201). In FY 2019, NIST initiated a revision of FIPS 201 \nto incorporate changing business requirements of federal departments and agencies and to \nadapt to an evolving technology environment. The revision also helps users to align with Office \nof Management and Budget (OMB) Policy Memorandum M-19-17. Revision activities began in \nFY 2019 with a business requirement meeting to engage with federal stakeholders about the \nrevision goals. In FY 2020, the PIV team updated the draft standard based on the revision goals"
  },
  {
    "chunk_id": "2020 Cybersecurity and Privacy Annual Report_first10_chunk_7",
    "filename": "2020 Cybersecurity and Privacy Annual Report_first10.pdf",
    "page_num": 8,
    "text": "NIST CYBERSECURITY & PRIVACY ANNUAL REPORT - FY2020\nPAGE 5\nand published public draft FIPS 201-3. The draft standard expands the set of PIV authenticators \nbeyond the current practices (including the current smart card form factor) while addressing \ninteragency use of new types of PIV authenticators (i.e., derived PIV credentials) via federation. \nThe revision also aims to facilitate the issuance of PIV cards by enabling remote identity proofing. \nThese changes closely align with M-19-17. For FY 2021, the PIV team will actively work on \nresolving comments on the public draft while continuing outreach to federal stakeholders.\nDigital Identity Guidelines\nThe four-volume set of NIST SP 800-63-3, Digital Identity Guidelines, was published in \nJune 2017. Following three years of federal agency experience implementing the controls \nand requirements and to help stay ahead of potential online identity attacks, the Information \nTechnology Laboratory (ITL) decided to revise and update all volumes of SP 800-63-3.\nNIST ITL published the pre-draft Request for Comments for the revision of SP 800-63-3 on \nJune 8, 2020. The Request for Comments identified nine topics for potential update. \nAdditionally, NIST ITL provided numerous virtual conferences and presentations on the \ntargeted topics for potential revision and other aspects of the Digital Identity Guidelines to \nimprove and focus the development and submission of comments. More than 40 federal \nagencies and industry organizations responded with over 300 comments. ITL published a \npublic roadmap for key activities, milestones, and target dates for the development of SP \n800-63, Revision 4, and published all comments received by the comment closing date. As\nindicated in the roadmap, ITL plans to complete adjudication of comments received in the first\nquarter of FY 2021 and will post issues for potential revision on GitHub in the second quarter.\nImplementation Resources for NIST SP 800-63, Digital Identity Guidelines\nIn June 2020, NIST ITL published resources for applying NIST SP 800-63. Based on requests \nfrom federal agencies and industry and on recommendations from the U.S. General \nAccountability Office (GAO), NIST developed and published materials to provide non-\nnormative guidance for the implementation of SP 800-63A, Enrollment and Identity \nProo ing; SP 800-63B, Authentication and Lifecycle Management; and SP 800-63C, \nFederation and Assertions. The guidance addresses key topics and aspects of each volume \nto facilitate the understanding and implementation of the requirements for all assurance \nlevels. ITL presented information for federal agencies and industry to promote the use of the \nimplementation resources and discuss key topics, requirements, and controls and how to \nproperly implement them.\nConformance Criteria for NIST SP 800-63A and 800-63B\nOMB Policy Memorandum M-19-17 updated federal identity, credentials, and access \nmanagement \npolicy \nand \nprovided \ndirection \nfor \nfederal \nagencies \nto \nenhance \nassociated capabilities. The OMB Policy Memo assigned NIST the responsibility for developing \nconformance criteria for accreditation of products and services to meet the designated levels \nof assurance in  SP 800-63-3. In response, NIST ITL developed the criteria for NIST SPs \n800-63A and 800-63B."
  },
  {
    "chunk_id": "2020 Cybersecurity and Privacy Annual Report_first10_chunk_8",
    "filename": "2020 Cybersecurity and Privacy Annual Report_first10.pdf",
    "page_num": 9,
    "text": "NIST CYBERSECURITY & PRIVACY ANNUAL REPORT - FY2020\nPAGE 6\nThe conformance criteria present all normative requirements and controls of SP 800-63-3 by \ndesignated assurance level, the control objectives for each criterion, recommended methods for \ndetermining conformity, and supplemental guidance to assist implementers and assessors. The \ncriteria are intended for federal agencies and industry service providers for the implementation \nof SP 800-63-3 and for conducting conformance and security assessments under the Federal \nInformation Security Modernization Act (FISMA). NIST provided virtual conferences and \npresentations to explain how to apply and use the conformance criteria for implementation and \nconformance assessment. Multiple federal agencies and industry organizations have developed \nprograms to incorporate the conformance criteria and take advantage of the guidance and \ntools presented in the document.\nAccess Control System Guidance and Research for Cloud Systems\nNIST developed SP 800-210, General Access Control Guide for Cloud Systems, to present \ncloud access control characteristics and general access control guidance for cloud service \nmodels: IaaS (Infrastructure as a Service), PaaS (Platform as a Service), and SaaS (Software \nas a Service). The main focus is on the technical aspects of access control without considering \ndeployment models (e.g., public, private, hybrid clouds). It also focuses on trust and risk \nmanagement issues, which require different layers of discussions that depend on the security \nrequirements of the business function or the organization of deployment for which the cloud \nsystem is implemented. NIST researched emerging technologies that can be applied to access \ncontrol mechanisms, such as the Natural Language Processing algorithm to automatically \ngenerate access control policy from natural language documentation. Currently, studies of \nexperiment tools, user cases, and language features are the focus of the research work.\nAccess Control Policy Verification and Development Tools\nAccess control systems are among the most critical network security components. Faulty \npolicies, misconfiguration, or flaws in software implementation can result in serious \nvulnerabilities. To address these issues, NIST developed and is improving the Access Control \nPolicy Tool (ACPT), which allows a user to compose, verify, test, and generate access control \npolicies. New user-interface features have been added to the improved version of ACPT. NIST \nhas also developed the Access Control Rule Logic Circuit (ACRLC) simulation technique, which \nenables access control policy authors to detect a fault when the fault-causing access control \nrule is added to the policy. This notification allows a fix to be implemented in real time before \nadding other rules that further complicate the detecting effort.\nIn addition to software simulation, NIST worked on hardware implementation of ACRLC with \nthe University of Arkansas Computer Science Department. The hardware version of ACRLC \nenables the study of performance and real-world applications. NIST also researched theories \nfor applying quantum algorithms to limited access control systems (such as IoT devices). The \nresearch results are presented in the paper Apply Quantum Search to the Safety Check for \nMono Operational Attribute Based Protection Systems, which will be published in the \ninternational \nConference \non \nSecurity, \nPrivacy, \nand \nAnonymity \nin \nComputation, \nCommunication, and Storage."
  },
  {
    "chunk_id": "2020 Cybersecurity and Privacy Annual Report_first10_chunk_9",
    "filename": "2020 Cybersecurity and Privacy Annual Report_first10.pdf",
    "page_num": 10,
    "text": "NIST CYBERSECURITY & PRIVACY ANNUAL REPORT - FY2020\nPAGE 7\n3 | Metrics and Measurement\nCybersecurity Metrics provide decision support, and they help to measure and \nimprove performance and accountability for cybersecurity activities. A mature metrics program \nis content-rich, supports a broader range of stakeholders, and provides greater value to the \norganization. More precise measurement data helps to focus on an actionable approach \nto improving cybersecurity. To support this effort, NIST has embarked on various initiatives, \nsome of which are highlighted here. Initiatives include research in new technology areas, \nrisk management tools and guidance, and ways for organizations to mature the use of \ncybersecurity metrics.\nMeasurements for Information Security\nEvery organization wants to gain maximum value and effect for its finite cybersecurity-related \ninvestments. This includes managing risk to the enterprise and optimizing the potential \nreward of cybersecurity policies, programs, and actions. Organizations frequently make \ndecisions by comparing scenarios of various projected costs with potential associated \nbenefits and risk reduction. Senior executives need accurate and quantitative methods to \nportray and assess these factors, their effectiveness and efficiency, and their effect on risk \nexposure. Providing reliable answers to these questions requires organizations to employ a \nsystematic approach to cybersecurity measurement that considers current knowledge limits.\nNIST’s \ncybersecurity \nmeasurements \nprogram \nenables \norganizations \nto \nmanage \ncybersecurity risks. NIST is undertaking a focused program on cybersecurity measurements \nto support the development and alignment of technical measures to determine the effect of \ncybersecurity risks and responses on an organization’s objectives. The initiative involves \ncollaboration with the research, business, and government sectors.\nCredit: Shutterstock"
  },
  {
    "chunk_id": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10_chunk_0",
    "filename": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10.pdf",
    "page_num": 1,
    "text": "NISTIR 7313\nISBN 1-886843-39-2\n \n \n \n5th Annual PKI R&D Workshop \n“Making PKI Easy to Use”\nProceedings\n \n \n \n \nWilliam T. Polk\nNelson E. Hastings\nKent Seamons"
  },
  {
    "chunk_id": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10_chunk_1",
    "filename": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10.pdf",
    "page_num": 3,
    "text": "NISTIR 7313\nISBN 1-886843-39-2\n \n \n \n \n \n \n \n \n \n \n \n \n \n5th Annual PKI R&D Workshop\n“Making PKI Easy to Use”\nProceedings\n \nWilliam T. Polk \nNelson E. Hastings\nComputer Security Division \nInformation Technology Laboratory \nNational Institute of Standards and Technology \n \nKent Seamons \nBrigham Young University \nJuly 2006\nU.S. DEPARTMENT OF COMMERCE \nCarlos M. Gutierrez, Secretary \nTECHNOLOGY ADMINISTRATION \n Robert Cresanti, Under Secretary of Commerce for Technology \nNATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY \nWilliam Jeffrey, Director"
  },
  {
    "chunk_id": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10_chunk_2",
    "filename": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10.pdf",
    "page_num": 4,
    "text": "Certain commercial entities, equipment, or materials may be identified in this \ndocument in order to describe an experimental procedure or concept adequately. \nSuch identification is not intended to imply recommendation or endorsement by \nthe National Institute of Standards and Technology, nor is it intended to imply \nthat the entities, materials, or equipment are necessarily the best available for the \npurpose."
  },
  {
    "chunk_id": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10_chunk_3",
    "filename": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10.pdf",
    "page_num": 5,
    "text": "5th Annual PKI R&D Workshop - Proceedings \nForeward  \n \nNIST hosted the fifth annual Public Key Infrastructure (PKI) R&D Workshop on April 4-6, \n2006. The two and a half day event brought together PKI experts from academia, \nindustry, and government to explore the current state of public key technology and \nemerging trust mechanisms, share lessons learned, and discuss complementary topics \nsuch as usability. The workshop also served as a forum to review continuing progress in \nfocus areas from previous workshops.  In addition to the seven refereed papers, this \nproceedings captures the essence of the workshop activities including the keynote \naddress, four invited talks, five panels, the work-in-progress session and, new to the \nworkshop this year, an informal rump session. \n \nThis workshop began with a variation on a familiar theme: usability.  Angela Sasse \npresented the keynote, “Has Jonny Learnt to Encrypt By Now?”, revisiting Alma \nWhitten’s keynote from the 2003 workshop.  Sasse’s approach emphasizes “value-\nbased design”: by understanding the users’ goals, and designing around them, we can \nbuild a more usable system.  Features and complexities not essential to the user \nexperience should be hidden by simplifying systems and hiding complexity.  Usability \nwas also addressed in a paper session on “Easy-to-Use Deployment Architectures” and \npanels on digital signatures and browser security interfaces.   \n \nImproving the security of infrastructure and applications was another recurring theme \nthroughout the workshop.  A presentation on trust infrastructures and DNSSEC by \nAllison Mankin was given on the first day of the workshop.  Although attacking DNS is \nstraightforward, there are few incentives for attackers so DNS poisoning is relatively \nrare.  The low threat level may be one reason that DNSSEC deployment has been slow.  \nA panel on Domain Keys Identified Mail (DKIM), which leverages the DNS for key \ndistribution, was held on the second day of the workshop.  DKIM would seem to provide \nthe incentive for attacking the DNS, so perhaps DNSSEC deployment will become a \nmore urgent requirement.  Phillip Hallam-Baker’s presentation on the DKIM panel, \n“Achieving Email Security Luxury” proposed leveraging DKIM, XKMS, and the PKIX \nlogotype extension to create a comprehensive and compelling solution for securing \napplications and the infrastructure. \n \nAnother theme of the workshop was the convergence of PKI and other technologies.  \nJeffrey Altman’s presentation highlighted progress in the convergence of PKI and \nKerberos.   A decade’s efforts have produced PK-INIT, PK-CROSS, and PK-APP, \nforming a comprehensive suite of standards.  PK-INIT and PK-APP allow users to \nleverage PKI certificates to obtain Kerberos credentials, and vice versa.  PK-CROSS \nsupports the establishment of Kerberos cross realm relationships with PKI credentials.   \nThe “Identity Federation and Attribute-based Authorization through the Globus Toolkit, \nShibboleth, GridShib, and MyProxy” presentation described the integration of the Grid \nPKIs, Security Assertion Markup Language (SAML), Kerberos, and one time passwords \nto support authorization decisions for Grid computing. \n \nIdentifying and resolving revocation issues continues to be a topic of critical interest.   \nThis year’s workshop featured two presentations at very different levels of abstraction.  \nKelvin Yiu’s invited talk focused on challenges that had to be faced and compromises \nrequired to make revocation usable for consumers in the forthcoming Vista operating \nsystem.  Sant"
  },
  {
    "chunk_id": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10_chunk_4",
    "filename": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10.pdf",
    "page_num": 5,
    "text": " of the Grid \nPKIs, Security Assertion Markup Language (SAML), Kerberos, and one time passwords \nto support authorization decisions for Grid computing. \n \nIdentifying and resolving revocation issues continues to be a topic of critical interest.   \nThis year’s workshop featured two presentations at very different levels of abstraction.  \nKelvin Yiu’s invited talk focused on challenges that had to be faced and compromises \nrequired to make revocation usable for consumers in the forthcoming Vista operating \nsystem.  Santosh Chokhani explored some of the more arcane nuances of the X.509 \niii"
  },
  {
    "chunk_id": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10_chunk_5",
    "filename": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10.pdf",
    "page_num": 6,
    "text": "5th Annual PKI R&D Workshop - Proceedings \n \nstandard, and their implications for real PKI deployments.  A less than cautious \napproach to CA key rollover or PKI architecture design can introduce circularities in trust \npaths when validating CRLs or OCSP responses. \n \nThe first two days of the workshop also included the ever-popular Works In Progress \nsession.  This session allowed presenters to obtain early feedback on ongoing work or \nprojects that are in the early conceptual stages.  Major WIP presentations addressed \ninteroperability results for the Suite B cipher suites, progress in the Global Grid, and \nexperiences with securing the DNS. In the rump session, brief presentations questioned \nold paradigms (e.g., are offline CAs really more secure?) and proposed novel \napplications of current technology (such as mobile phones as secure containers). \n  \nThe workshop closed with a half day devoted to PKI deployment issues.  The panel on \n“PKI in Higher Education” had an international flavor, featuring a presentation on the \nAustralian CAUDIT PKI Federation.  This was followed by a snapshot of U.S. \ngovernment PKI deployment activities in the “Federal PKI Update” panel.  The workshop \nended with a look at leading edge deployment activities in the “Bridge to Bridge \nInteroperations” panel.  Bridge-to-bridge cross certification will create policy and \ntechnology challenges, however the panel concluded that these challenges are not \ninsurmountable. \n \nThe 150 attendees represented a cross-section of the global PKI community, with \npresenters from the USA, United Kingdom, Britain, Israel, Australia, Norway, Sweden, \nGermany and Canada.  Due to the success of this event, a sixth workshop is planned for \nSpring 2007. \n \nWilliam T. Polk and Nelson E. Hastings \nNational Institute of Standards and Technology \nGaithersburg, MD USA \niv"
  },
  {
    "chunk_id": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10_chunk_6",
    "filename": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10.pdf",
    "page_num": 7,
    "text": "5th Annual PKI R&D Workshop - Proceedings \n \n2006 PKI R&D Workshop \nMaking PKI Easy to Use \nGaithersburg, Maryland USA \nApril 4-6, 2006 \nhttp://middleware.internet2.edu/pki06/\n \n(Pre-proceedings were distributed at the workshop) \n \n \n \nWORKSHOP SUMMARY \n     Provided by Ben Chinowsky, Internet2 \n1\n \n \nREFERRED PAPERS \nHow Trust Had a Hole Blown In It.  The Case of X.509 Name Constraints \n13\n \nDavid Chadwick \n \nUniversity of Kent, England  \n \nNavigating Revocation through Eternal Loops and Land Mines \n31\n \nSantosh Chokhani  \nCarl Wallace \n \nOrion Security Solutions, Inc. \nOrion Security Solutions, Inc.  \nSimplifying Public Key Credential Management through Online Certificate \nAuthorities and PAM \n46\n \nStephen Chan \nMatthew Andrews \n \nNERSC/Lawrence Berkeley National Lab  \nNERSC/Lawrence Berkeley National Lab \nIdentity Federation and Attribute-based Authorization through the Globus Toolkit, \nShibboleth, GridShib, and MyProxy \n54\n \nTom Barton \nJim Basney \nTim Freeman \nTom Scavo \nFrank Siebenlist \n \nVon Welch \nRachana Ananthakrishnan \nBill Baker \nMonte Goode \nKate Keahey  \n \nUniversity of Chicago \nNCSA/University of Illinois \nUniversity of Chicago \nNCSA/University of Illinois \nUniversity of Chicago &  \n   MCSD, Argonne National Lab \nNCSA/University of Illinois \nMCSD/Argonne National Lab \nNCSA/University of Illinois \nLawrence Berkeley National Lab \nUniversity of Chicago &    \n   MCSD/Argonne National Lab \n \nPKI Interoperability by an Independent, Trusted Validation Authority \n68\n \nJon Ølnes \nDNV Research; Norway \n \nAchieving Email Security Usability \n79\n \nPhillip Hallam-Baker  \n \nVeriSign Inc. \nv"
  },
  {
    "chunk_id": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10_chunk_7",
    "filename": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10.pdf",
    "page_num": 8,
    "text": "5th Annual PKI R&D Workshop - Proceedings \n \n \nCAUDIT PKI Federation - A Higher Education Sector Wide Approach \n92\n \nRodney McDuff  \nViviani Paz \n \nThe University of Queensland \nAustralian Computer Emergency \nResponse Team \n \nLIST OF ACRONYMS \n105\n \n \n \n \n \n \nvi"
  },
  {
    "chunk_id": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10_chunk_8",
    "filename": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10.pdf",
    "page_num": 9,
    "text": "5th Annual PKI R&D Workshop - Proceedings \n \nOrganizers \n \nGeneral Chair:  Ken Klingenstein, University of Colorado \nProgram Chair:  Kent Seamons, Brigham Young University \nSteering Committee Chair:  Neal McBurnett, Internet2 \nLocal Arrangements Chair:  Nelson Hastings, NIST \nScribe:  Ben Chinowsky, Internet2 \n \n \nProgram Committee \nKent Seamons, Brigham Young Univ. (chair) \nNeal McBurnett, Internet2 \nPeter Alterman, National Institutes of Health \nClifford Neuman, USC-ISI \nStefan Brands, Credentica and McGill Univ. \nEric Norman, University of Wisconsin \nBill Burr, NIST \nTim Polk, NIST \nDavid Chadwick, University of Kent \nRavi Sandhu, GMU and TriCipher \nYassir Elley, Forum Systems \nKrishna Sankar, Cisco Systems \nCarl Ellison, Microsoft \nFrank Siebenlist, Argonne Nat’l Laboratory \nStephen Farrell, Trinity College Dublin \nSean Smith, Dartmouth College \nRichard Guida, Johnson & Johnson \nVon Welch, NCSA \nJason Holt, Brigham Young Univ. \nStephen Whitlock, Boeing \nRuss Housley, Vigil Security, LLC \nMichael Wiener, Cryptographic Clarity \nKen Klingenstein, Internet2 \nWilliam Winsborough, Univ. of Texas at San \nAntonio \n \n \n \nArchival Sites \n \nPKI 2006: \n \n \nhttp://middleware.internet2.edu/pki06 \nPKI 2005: \n \n \nhttp://middleware.internet2.edu/pki05 \n \nPKI 2004: \n \n \nhttp://middleware.internet2.edu/pki04 \n \nPKI 2003: \n \n \nhttp://middleware.internet2.edu/pki03 \nPKI 2002: \n \n \nhttp://www.cs.dartmouth.edu/~pki02\n \n \nvii"
  },
  {
    "chunk_id": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10_chunk_9",
    "filename": "5th Annual PKI R&D Workshop _Making PKI Easy to Use_ Proceedings_first10.pdf",
    "page_num": 10,
    "text": "5th Annual PKI R&D Workshop - Proceedings \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nThis page has been left intentionally blank. \n \nviii"
  },
  {
    "chunk_id": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10_chunk_0",
    "filename": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10.pdf",
    "page_num": 1,
    "text": "NIST Special Publication 800-178 \nA Comparison of Attribute Based \nAccess Control (ABAC) Standards for \nData Service Applications \nExtensible Access Control Markup Language (XACML) and \nNext Generation Access Control (NGAC) \nDavid Ferraiolo \nRamaswamy Chandramouli \nVincent Hu \nRick Kuhn \nThis publication is available free of charge from: \nhttp://dx.doi.org/10.6028/NIST.SP.800-178 \nC  O  M  P  U  T  E  R      S  E  C  U  R  I  T  Y"
  },
  {
    "chunk_id": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10_chunk_1",
    "filename": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10.pdf",
    "page_num": 2,
    "text": "NIST Special Publication 800-178 \nA Comparison of Attribute Based \nAccess Control (ABAC) Standards for \nData Service Applications \nExtensible Access Control Markup Language (XACML) and \nNext Generation Access Control (NGAC) \nDavid Ferraiolo \nRamaswamy Chandramouli \nVincent Hu \nRick Kuhn \nComputer Security Division \nInformation Technology Laboratory \nThis publication is available free of charge from: \nhttp://dx.doi.org/10.6028/NIST.SP.800-178 \nOctober 2016 \nU.S. Department of Commerce \nPenny Pritzker, Secretary \nNational Institute of Standards and Technology \nWillie May, Under Secretary of Commerce for Standards and Technology and Director"
  },
  {
    "chunk_id": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10_chunk_2",
    "filename": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10.pdf",
    "page_num": 3,
    "text": "Authority \nThis publication has been developed by NIST in accordance with its statutory responsibilities under the \nFederal Information Security Modernization Act (FISMA) of 2014, 44 U.S.C. § 3551 et seq., Public Law \n(P.L.) 113-283. NIST is responsible for developing information security standards and guidelines, \nincluding minimum requirements for federal information systems, but such standards and guidelines shall \nnot apply to national security systems without the express approval of appropriate federal officials \nexercising policy authority over such systems. This guideline is consistent with the requirements of the \nOffice of Management and Budget (OMB) Circular A-130. \nNothing in this publication should be taken to contradict the standards and guidelines made mandatory \nand binding on federal agencies by the Secretary of Commerce under statutory authority. Nor should \nthese guidelines be interpreted as altering or superseding the existing authorities of the Secretary of \nCommerce, Director of the OMB, or any other federal official.  This publication may be used by \nnongovernmental organizations on a voluntary basis and is not subject to copyright in the United States. \nAttribution would, however, be appreciated by NIST.   \nNational Institute of Standards and Technology Special Publication 800-178 \nNatl. Inst. Stand. Technol. Spec. Publ. 800-178, 68 pages (October 2016) \nCODEN: NSPUE2 \nThis publication is available free of charge from: \nhttp://dx.doi.org/10.6028/NIST.SP.800-178\nCertain commercial entities, equipment, or materials may be identified in this document in order to describe an \nexperimental procedure or concept adequately. Such identification is not intended to imply recommendation or \nendorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best \navailable for the purpose.  \nThere may be references in this publication to other publications currently under development by NIST in accordance \nwith its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, \nmay be used by federal agencies even before the completion of such companion publications. Thus, until each \npublication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For \nplanning and transition purposes, federal agencies may wish to closely follow the development of these new \npublications by NIST.   \nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback to \nNIST. Many NIST cybersecurity publications, other than the ones noted above, are available at \nhttp://csrc.nist.gov/publications.\nComments on this publication may be submitted to: \nNational Institute of Standards and Technology \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 \nEmail: sp800-178@nist.gov \nAll comments are subject to release under the Freedom of Information Act (FOIA)."
  },
  {
    "chunk_id": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10_chunk_3",
    "filename": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10.pdf",
    "page_num": 4,
    "text": "NIST SP 800-178 \nCOMPARISON OF ABAC STANDARDS FOR \nDATA SERVICES: XACML AND NGAC \nii \nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.SP.800-178 \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test \nmethods, reference data, proof of concept implementations, and technical analyses to advance \nthe development and productive use of information technology. ITL’s responsibilities include the \ndevelopment of management, administrative, technical, and physical standards and guidelines for \nthe cost-effective security and privacy of other than national security-related information in \nfederal information systems. The Special Publication 800-series reports on ITL’s research, \nguidelines, and outreach efforts in information system security, and its collaborative activities \nwith industry, government, and academic organizations. \nAbstract \nExtensible Access Control Markup Language (XACML) and Next Generation Access Control \n(NGAC) are very different attribute based access control (ABAC) standards with similar goals \nand objectives. An objective of both is to provide a standardized way for expressing and \nenforcing vastly diverse access control policies on various types of data services. However, the \ntwo standards differ with respect to the manner in which access control policies are specified and \nimplemented. This document describes XACML and NGAC, and then compares them with \nrespect to five criteria. The goal of this publication is to help ABAC users and vendors make \ninformed decisions when addressing future data service policy enforcement requirements. \nKeywords \naccess control; access control mechanism; access control model; access control policy; attribute \nbased access control (ABAC); authorization; Extensible Access Control Markup Language \n(XACML); Next Generation Access Control (NGAC); privilege"
  },
  {
    "chunk_id": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10_chunk_4",
    "filename": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10.pdf",
    "page_num": 5,
    "text": "NIST SP 800-178 \nCOMPARISON OF ABAC STANDARDS FOR \nDATA SERVICES: XACML AND NGAC \niii \nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.SP.800-178 \nAcknowledgements \nThe authors, David Ferraiolo, Ramaswamy Chandramouli, Vincent C. Hu, and Rick Kuhn of the \nNational Institute of Standards and Technology (NIST), wish to thank their colleagues who \nreviewed drafts of this document, including the following: Karen Scarfone (Scarfone \nCybersecurity), Wayne Jansen (Bayview Behavioral Consulting), Serban Gavrila (NIST), \nIndrakshi Ray (Colorado State University), Duminda Wijesekera (George Mason University), \nand Ram Krishnan (University of Texas at San Antonio).  \nThe authors also gratefully acknowledge and appreciate the comments and contributions made \nby government agencies, private organizations, and individuals in providing direction and \nassistance in the development of this document. \nNote to Readers \nFor purposes of transparency, one of the authors of this document, David Ferraiolo, is a member \nof the American National Standards Institute/International Committee for Information \nTechnology (ANSI/INCITS) Next Generation Access Control (NGAC) working group. To \nmitigate the injection of bias, prior drafts have been circulated for review to multiple subject \nmatter experts, as well as formally to the public at large. In addition, prior to publication, the \nfinal draft of this document was reviewed by multiple independent entities in compliance with \nthe requirements of the NIST Editorial Review Board (ERB). Disposition and resolution of \ncomments were considered by the authors at large. \nTrademark Information  \nAll registered trademarks or trademarks belong to their respective organizations."
  },
  {
    "chunk_id": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10_chunk_5",
    "filename": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10.pdf",
    "page_num": 6,
    "text": "NIST SP 800-178 \nCOMPARISON OF ABAC STANDARDS FOR \nDATA SERVICES: XACML AND NGAC \niv \nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.SP.800-178 \nExecutive Summary \nExtensible Access Control Markup Language (XACML) and Next Generation Access Control \n(NGAC) are very different attribute based access control (ABAC) standards with similar goals \nand objectives. XACML, available since 2003, is an Extensible Markup Language (XML) based \nlanguage standard designed to express security policies, as well as the access requests and \nresponses needed for querying the policy system and reaching an authorization decision [1]. \nNGAC is a relations and architecture-based standard designed to express, manage, and enforce \naccess control policies through configuration of its relations.  \nWhat are the similarities and differences between these two standards? What are their \ncomparative advantages and disadvantages? These questions are particularly relevant because \nXACML and NGAC are different approaches to achieving a common access control goal—to \nallow applications with vastly different access policies to be expressed and enforced using the \nfeatures of the same underlying mechanism in diverse ways. These are also important questions, \ngiven the prevalence of data services in computing. Data services include computational \ncapabilities that allow the consumption, alteration, and management of data resources, and \ndistribution of access rights to data resources. Data services can take on many forms, to include \napplications such as time and attendance reporting, payroll processing, and health benefits \nmanagement, but also including system level utilities such as file management. \nTo answer these questions, this document first describes XACML and NGAC, then compares \nthem with respect to five criteria. The first criterion is the relative degree to which the access \ncontrol functionality of a data service can be separated from a proprietary operational \nenvironment. The other four criteria are derived from ABAC issues or considerations identified \nby NIST Special Publication (SP) 800-162 [2]: operational efficiency, attribute and policy \nmanagement, scope and type of policy support, and support for administrative review and \nresource discovery. \nAlthough NGAC is only now emerging as a national standard, it compares favorably in many \nrespects with XACML and should be considered, along with XACML, by both users and \nvendors in addressing future data service policy enforcement requirements. Below is a summary \nof this comparison.  \nSeparation of Access Control Functionality from Proprietary Operating Environments \nBoth XACML and NGAC achieve separation of access control functionality of data services \nfrom proprietary operating environments, but to different degrees. XACML’s separation is \npartial. XACML does not envisage the design of a Policy Enforcement Point (PEP) that is data \nservice agnostic. An XACML deployment consists of one or more data services, each with an \noperating environment-dependent PEP and operating environment-dependent operational \nroutines and resource types that share a common Policy Decision Point (PDP) and access control \ninformation consisting of policies and attributes.  \nThe degree of separation that can be achieved by NGAC is near complete. Although an NGAC \ndeployment could include a PEP with an application programming interface (API) that \nrecognizes operating environment-specific operations (e.g., send and forward operations for a"
  },
  {
    "chunk_id": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10_chunk_6",
    "filename": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10.pdf",
    "page_num": 7,
    "text": "NIST SP 800-178 \n \n \nCOMPARISON OF ABAC STANDARDS FOR \nDATA SERVICES: XACML AND NGAC \nv \nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.SP.800-178 \nmessaging system), it does not necessarily need to do so. NGAC includes a standard PEP with an \nAPI that supports a set of generic, operating environment-agnostic operations (read, write, create, \nand delete policy elements and relations). This API enables a common, centralized PEP to be \nimplemented to serve the requests of multiple applications.   \nOperational Efficiency \nAn XACML request is a collection of attribute name, value pairs for the subject (user), action \n(operation), resource, and environment. XACML identifies relevant policies and rules for \ncomputing decisions through a search for Targets (conditions that match the attributes of the \nrequest). Because multiple Policies in a PolicySet and/or multiple Rules in a Policy may produce \nconflicting access control decisions, XACML resolves these differences by applying a policy \ncombining algorithm from a set defined by the standard. The entire process includes collecting \nattributes, matching conditions, computing rules, and resolving conflicts involving at least two \ndata stores. There are two phases of policy evaluation that need to be considered. The first and \ncostliest is loading policy from disk to Policy Decision Point (PDP) main memory, and the \nsecond is request evaluation. In both phases, performance is directly related to the number of \npolicies considered.  \nAn NGAC request is composed of a process id, user id, operation, and a sequence of one or more \noperands mandated by the operation that affects either a resource or access control data. NGAC \nidentifies relevant Policies and attributes by reference when computing a decision. NGAC \ncomputes decisions by applying a single combining algorithm over applicable Policies that do \nnot conflict. Unlike XACML, NGAC does not need to load policy from disk into memory when \nevaluating a request. Instead, and as treated in NGAC reference implementation version 1.6 [11] \nall information necessary in computing an access decision can reside in memory. Memory is \ninitially loaded when the PDP is initialized, and is updated when an administrative change \noccurs. The NGAC specification describes what constitutes a valid implementation, but does not \nprovide implementation guidance, thereby leaving room for multiple competing approaches with \ndifferent efficiencies. A measure of the operational efficiency is the complexity of algorithm \nused for arriving at a policy decision. In its reference implementation Version 1. 6 on GitHub \n[11], the NGAC computes a decision through an algorithm [30] that is linear. Furthermore, it is \nnot linear in relation to the entire access control data set, but only to the portion relevant to a \nparticular user.   \nAttribute and Policy Management \nProper enforcement of data resource policies is dependent on administrative policies. This is \nespecially true in a federated or collaborative environment, where governance policies require \ndifferent organizational entities to have different responsibilities for administering different \naspects of policies and their dependent attributes. \nXACML and NGAC differ dramatically in their ability to impose policy over the creation and \nmodification of access control data (attributes and policies). NGAC manages attributes and \npolicies through a standard set of administrative operations, applying the same enforcement \ninterface and decision making function as it uses for accessing data resources. XACML does not \nrecognize administrative operations, but instead manages policy content through a Policy"
  },
  {
    "chunk_id": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10_chunk_7",
    "filename": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10.pdf",
    "page_num": 8,
    "text": "NIST SP 800-178 \n \n \nCOMPARISON OF ABAC STANDARDS FOR \nDATA SERVICES: XACML AND NGAC \nvi \nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.SP.800-178 \nAdministration Point (PAP) with an interface that is different from that for accessing data \nresources. XACML provides support for decentralized administration of some of its access \npolicies. However, the approach is only a partial solution in that it is dependent on trusted and \nuntrusted policies, where trusted policies are assumed valid, and their origin is established \noutside the delegation model. Furthermore, the XACML delegation model does not provide a \nmeans for imposing policy over modification of access policies, and offers no direct \nadministrative method for imposing policy over the management of its attributes.   \nNGAC enables a systematic and policy-preserving approach to the creation of administrative \nroles and delegation of administrative capabilities, beginning with a single administrator and an \nempty set of access control data, and ending with users with data service, policy, and attribute \nmanagement capabilities. NGAC provides users with administrative capabilities down to the \ngranularity of a single configuration element, and it can deny users administrative capabilities \ndown to the same granularity.  \nScope and Type of Policy Support \nAlthough resources may be protected under a wide variety of different access policies, these \npolicies can be generally categorized as either discretionary or mandatory controls. Discretionary \naccess control (DAC) is an administrative policy that permits system users to allow or disallow \nother users’ access to resources that are placed under their control. Although XACML can \ntheoretically provide users with administrative capabilities necessary to control and give away \naccess rights to other users, the approach is complicated by the need to create and maintain \nadditional metadata for each and every object/resource (e.g., Owner attribute). Conversely, \nNGAC has a flexible means of providing users with administrative capabilities to include those \nnecessary for the establishment of DAC policies.  \nIn contrast to DAC, mandatory access control (MAC) enables ordinary users’ capabilities to \nexecute operations on resources, but not administrative operations that may influence those \ncapabilities. MAC policies unavoidably impose rules on users in performing operations on \nresources. MAC policies can be further characterized as controls that accommodate confinement \nproperties to prevent indirect leakage of data to unauthorized users, and those that do not.  \nExpression of non-confinement MAC policies is perhaps XACML’s strongest suit. XACML can \nspecify rules and other conditions in terms of attribute values of varying types. There are \nundoubtedly certain policies that are expressible in terms of these rules that cannot be easily \naccommodated by NGAC. This is especially true when treating attribute values as integers. For \nexample, to approve a purchase request may involve adding a person’s credit limit to the \nperson’s account balance. Furthermore, XACML takes environmental attributes into \nconsideration in expressing policy, and NGAC does not. However, there are some non-\nconfinement MAC properties, including a variety of history-based policies, that NGAC can \nexpress but XACML cannot. \nIn contrast to NGAC, XACML does not recognize the capabilities of a process independent of \nthe capabilities of its user. Without such features, XACML is ill-equipped to support \nconfinement and as such is arguably incapable of enforcement of a wide variety of policies. \nThese confinement-dependent policies include some instances of role-based access control"
  },
  {
    "chunk_id": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10_chunk_8",
    "filename": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10.pdf",
    "page_num": 9,
    "text": "NIST SP 800-178 \n \n \nCOMPARISON OF ABAC STANDARDS FOR \nDATA SERVICES: XACML AND NGAC \nvii \nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.SP.800-178 \n(RBAC), e.g., “only doctors can read the contents of medical records,” originator control \n(ORCON) and Privacy, e.g., “I know who can currently read my data or personal information”, \nor conflict of interest, e.g., “a user with knowledge of information within one dataset cannot read \ninformation in another dataset”. Through imposing process level controls in conjunction with \nevent-response relations, NGAC has shown [3] support for these and other confinement-\ndependent MAC controls.  \nAdministrative Review and Resource Discovery \nA desired feature of access controls is review of capabilities of users and access control entries of \nobjects [4] [18]. These features are often referred to as “before the fact audit” and resource \ndiscovery. “Before the fact audit” is one of RBAC’s most prominent features [5]. Being able to \ndiscover or see a newly accessible resource is an important feature of any access control system. \nNGAC supports efficient algorithms for both per-user and per-object review. Per-object review \nof access control entries is not as efficient as a pure access control list (ACL) mechanism, and \nper-user review of capabilities is not as efficient as that of RBAC. However, this is due to \nNGAC’s consideration of conducting review in a multi-policy environment. NGAC can \nefficiently support both per-object and per-user reviews of combined policies [30], where RBAC \nand ACL mechanisms can do only one type of review efficiently, and logical formula-based \nmechanisms such as XACML, although able to combine policies, cannot do either type of review \nefficiently [6]."
  },
  {
    "chunk_id": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10_chunk_9",
    "filename": "A Comparison of Attribute Based Access Control (ABAC) Standards for Data Service Applications_ Extensible Access Control Markup Language (XACML) and N_first10.pdf",
    "page_num": 10,
    "text": "NIST SP 800-178 \n \n \nCOMPARISON OF ABAC STANDARDS FOR \nDATA SERVICES: XACML AND NGAC \nviii \nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.SP.800-178 \n \nTable of Contents \nExecutive Summary ..................................................................................................... iv \n1 \nIntroduction ............................................................................................................ 1 \n1.1 Purpose and Scope ........................................................................................ 1 \n1.2 Audience ......................................................................................................... 1 \n1.3 Document Structure ........................................................................................ 1 \n2 \nBackground ............................................................................................................ 2 \n2.1 XACML ........................................................................................................... 4 \n2.2 NGAC ............................................................................................................. 5 \n2.3 Comparison of XACML and NGAC’s Origins .................................................. 6 \n3 \nXACML Specification ............................................................................................. 8 \n3.1 Attributes and Policies .................................................................................... 8 \n3.2 Combining Algorithms ................................................................................... 10 \n3.3 Obligation and Advice Expressions............................................................... 10 \n3.4 Example Policies........................................................................................... 11 \n3.5 XACML Access Request ............................................................................... 13 \n3.6 Delegation ..................................................................................................... 15 \n3.6.1 Delegation Chain – An Example ......................................................... 16 \n3.6.2 Access Request Processing in Delegation Chains ............................. 17 \n3.7 XACML Reference Architecture .................................................................... 21 \n4 \nNGAC Specification ............................................................................................. 23 \n4.1 Basic Policy and Attribute Elements ............................................................. 23 \n4.2 Relations ....................................................................................................... 24 \n4.2.1 Assignments and Associations ........................................................... 24 \n4.2.2 Derived Privileges............................................................................... 25 \n4.2.3 Prohibitions (Denies) .......................................................................... 28 \n4.2.4 Obligations ......................................................................................... 28 \n4.3 NGAC Decision Function .............................................................................. 29 \n4.4 Administrative Considerations ...................................................................... 29 \n4.4.1 Administrative Associations ................................................................ 30 \n4.4.2 Delegation .......................................................................................... 30 \n4.4.3 NGAC Administrative Commands and Routines ................................ 31"
  },
  {
    "chunk_id": "A Data Structure for Integrity Protection with Erasure Capability_chunk_0",
    "filename": "A Data Structure for Integrity Protection with Erasure Capability.pdf",
    "page_num": 1,
    "text": "NIST CYBERSECURITY WHITE PAPER \nNIST CSWP 25 \nA Data Structure for Integrity Protection \nwith Erasure Capability \nD. Richard Kuhn \nComputer Security Division \nInformation Technology Laboratory \nMay 20, 2022 \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.CSWP.25 \nThis publication is a final version of a draft cybersecurity white paper originally published on May 31, \n2018: https://csrc.nist.gov/publications/detail/white-paper/2018/05/31/data-structure-for-integrity­\nprotection-with-erasurecapability/draft."
  },
  {
    "chunk_id": "A Data Structure for Integrity Protection with Erasure Capability_chunk_1",
    "filename": "A Data Structure for Integrity Protection with Erasure Capability.pdf",
    "page_num": 2,
    "text": "NIST CSWP 25 \nA DATA STRUCTURE FOR INTEGRITY PROTECTION\nWITH ERASURE CAPABILITY\nAbstract \nThis document describes a data structure, referred to as a data block matrix, that supports the \nongoing addition of hash-linked records while also allowing for the deletion of arbitrary records, \nthereby preserving hash-based integrity assurance that other blocks are unchanged. The block \nmatrix data structure may have utility for incorporation into applications requiring integrity \nprotection that currently use permissioned blockchains. This capability could for example be \nuseful in meeting privacy requirements such as the European Union General Data Protection \nRegulation (GDPR), which requires that organizations make it possible to delete all information \nrelated to a particular individual, at that person’s request. \nKeywords \nblockchain; computer security; data structure; distributed ledger; hash; integrity protection. \nPatent and Licensing \nThe data block matrix technology (US Patent #11,175,826) is available to be licensed. For \ninformation on patent and licensing see NIST Technology Partnerships Office (TPO). Parties \ninterested in licensing a NIST-owned invention may contact TPO, or may complete a research \nlicense application or commercial use license application. Instructions on how to submit the \nlicense application are provided at the end of each application. When a license application is \nreceived, TPO will contact you regarding the licensing process and to obtain additional \ninformation that may be necessary for the application process. A license application should \ninclude the prospective licensee’s intentions for research and development of the invention(s) \nand a description of the resources and technical capabilities of the prospective licensee to bring \nthe invention to practical application. \nDisclaimer \nAny mention of commercial products or reference to commercial organizations is for information \nonly; it does not imply recommendation or endorsement by NIST, nor does it imply that the \nproducts mentioned are necessarily the best available for the purpose. \nAdditional Information \nFor additional information on NIST’s Cybersecurity programs, projects and publications, visit the \nComputer Security Resource Center. Information on other efforts at NIST and in the Information \nTechnology Laboratory (ITL) is also available. \nSubmit comments on this publication to: block-matrix@nist.gov \nNational Institute of Standards and Technology \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 \nAll comments are subject to release under the Freedom of Information Act (FOIA). \nii"
  },
  {
    "chunk_id": "A Data Structure for Integrity Protection with Erasure Capability_chunk_2",
    "filename": "A Data Structure for Integrity Protection with Erasure Capability.pdf",
    "page_num": 3,
    "text": "NIST CSWP 25 \nA DATA STRUCTURE FOR INTEGRITY PROTECTION \nWITH ERASURE CAPABILITY \nI. BACKGROUND \nThis document describes a data structure, referred to as \na data block matrix, that supports the ongoing addition of \nhash-linked records while also allowing for the deletion \nof arbitrary records, thereby preserving hash-based in­\ntegrity assurance that other blocks are unchanged. (This \npublication is a fnal version of [1].) \nII. DATA STRUCTURE \nFig. 1 shows a matrix with numbered data blocks, \nwhere a block may contain a single record or multiple \ntransactions. Every row or column is terminated with \na block containing a hash of that row or column (e.g., \nH0,− is the hash of row 0). Various forms of the hash \nstructure are also possible. For example, the hash value \ncan be stored in the last block of the row or column \ninstead of a separate hash block. Another alternative \nis to concatenate hashes of each block in a row or \ncolumn, similar to the blockchain process. The hash of \nthis concatenation would then serve as the hash value \nfor that row or column. \nFigure 1. Basic block matrix \nAs an example of the process, the block labeled “X” \nmay be deleted by writing all zeroes to that block, or \nrevised with different values. Either of these changes will \naffect the hash values of H3,− and H−,2 for row 3 and \ncolumn 2. However, the integrity of all blocks except \nthe one containing “X” is still ensured by the other hash \nvalues. That is, other blocks of row 3 are included in \nthe hashes for columns 0, 1, 3, and 4. Similarly, other \nblocks of column 2 are included in the hashes for rows \n0, 1, 2, and 4. Thus, the integrity of blocks that have not \nbeen deleted is assured. An algorithm to maintain this \nstructure is given below and its properties described. \nWithin the data structure, blocks are numbered 1..k, \nand are added to the data structure starting with cell \n0, 1. (It is desirable to keep cells on the diagonal null, \nfor reasons explained later.) Variables i, j are column \nindices, and swap(i, j) exchanges the values of i and j, \ni.e., i ′ = j and j ′ = i. With this algorithm, cells are \nflled as shown in Algorithm 1. \nAlgorithm 1 Data block matrix construction \nloop invariant: i < j ∧ odd(Bi,j ) ∨i > j ∧ even(Bi,j ) \ni ← 0 \nj ← 1 \nB ← 1 \nwhile new blocks do \nif i = j then \nadd null block Bi,j \n// diagonal \ni ← 0 \nj ← j + 1 \nelse if i < j then \nadd block Bi,j \n// upper half \nB ← B + 1 \nswap(i, j) \nelse if i > j then \nadd block Bi,j \n// lower half \nB ← B + 1 \nj ← j + 1 \nswap(i, j) \nend if \nend while \nFigure 2. Block matrix with numbered cells \nIII. PROPERTIES \nCertain desirable properties are maintained with this \ndata structure. These features allow for the effcient \nstorage and retrieval of data blocks (results originally \nintroduced in [1]). \nTheorem 1 (Balance property). Cells are fl"
  },
  {
    "chunk_id": "A Data Structure for Integrity Protection with Erasure Capability_chunk_3",
    "filename": "A Data Structure for Integrity Protection with Erasure Capability.pdf",
    "page_num": 3,
    "text": " j then \nadd block Bi,j \n// lower half \nB ← B + 1 \nj ← j + 1 \nswap(i, j) \nend if \nend while \nFigure 2. Block matrix with numbered cells \nIII. PROPERTIES \nCertain desirable properties are maintained with this \ndata structure. These features allow for the effcient \nstorage and retrieval of data blocks (results originally \nintroduced in [1]). \nTheorem 1 (Balance property). Cells are flled in a \nbalanced manner so that the upper half (above diagonal) \ncontains at most one additional cell more than the lower \nhalf. \nProof. The following invariant implies the property, and \nfor each iteration of the loop, the invariant is maintained, \n(i = j ∨ i < j) ∧ u = l ∨ i > j ∧ u = l + 1 \nwhere u = number of cells above diagonal, and l = \nnumber of cells below diagonal. Initially, i = j = 0 \nand u = l = 0. If i = j, then u, l are unchanged, so \nthe invariant remains true. If i < j, then u = l. A \n′\nblock is then added to the upper half and u = l + 1 \n1"
  },
  {
    "chunk_id": "A Data Structure for Integrity Protection with Erasure Capability_chunk_4",
    "filename": "A Data Structure for Integrity Protection with Erasure Capability.pdf",
    "page_num": 4,
    "text": "NIST CSWP 25 \nA DATA STRUCTURE FOR INTEGRITY PROTECTION \nWITH ERASURE CAPABILITY \nand i ′ = j, j ′ = i so that i ′ > j ′ and the invariant is \nmaintained. If i > j, then u = l +1 and a block is added \n′ \nto the lower half such that u = l ′ and i ′ = j + 1, j ′ = i, \nso that i ′ < j ′ , maintaining the invariant. \nTheorem 2 (Hash chain length). The number of blocks \nin a row or column hash chain is proportional to N for \na matrix with N blocks. \nProof. The balance property ensures flling in a square \nform. \nTheorem 3 (Block numbering). All even-numbered \nblocks are placed below the diagonal and all odd-\nnumbered blocks are placed above the diagonal. \nProof. The following invariant implies the property. \ni < j ∧ odd(Bi,j ) ∨ i > j ∧ even(Bi,j ) \nInitially, i < j and B = 1, so the invariant holds, and \nfor each iteration of the loop, the invariant is maintained. \nTheorem 4 (Block dispersal). No consecutive blocks \nappear in the same row or column. That is, for any two \nblocks numbered a, b, where b = a+1, in rows ia and ib, \nand columns ja and jb respectively, ia ̸= ib and ja ̸= jb. \nProof. This can be shown by considering cases below. \n1. If i < j, then block a will be written to cell (ia, ja) \nand then i and j swapped, so that in the next iteration, \ni > j, and block b written to cell (ib, jb). Since ib = ja \nand jb = ia, and i ̸= j, ia ̸= ib and ja ≠ \njb. \n2. If i > j, then block a will be written to cell (ia, ja), \nj incremented, and then i and j swapped. Then either \nthe relationship is unchanged, with i > j, or i = j. \n2(a). If i = j, then no data block will be written in \nthe next iteration, but i will be set to 0 and j will be \nincremented such that i < j, and the next data block \nwritten with ib = 0 and jb = ja +1, ensuring that ia ̸= ib \nand ja ̸= jb. \n2(b). if i > j, then on the next iteration, block b will \nbe written with ib = ja and jb = ia, and i ≠ \nj, so that \nia ̸= ib and ja ̸= jb. \nIV. BLOCK LOCATION \nWith the relations above, one can derive expressions \nto locate a given block within the matrix. The following \nrelations are clear (see Fig. 2 for example) where N = \nnumber of columns = number of rows; row and column \nindexes range from 0 to N − 1. \n• The total number of data blocks in the matrix is \nN2 − N since the diagonal is null. Thus, the last \nnumbered block in a flled matrix of N rows and \ncolumns is number N2 − N. \n• Lower half: Numbered from 0, with no data blocks \non the diagonal, the total of blocks for"
  },
  {
    "chunk_id": "A Data Structure for Integrity Protection with Erasure Capability_chunk_5",
    "filename": "A Data Structure for Integrity Protection with Erasure Capability.pdf",
    "page_num": 4,
    "text": " N = \nnumber of columns = number of rows; row and column \nindexes range from 0 to N − 1. \n• The total number of data blocks in the matrix is \nN2 − N since the diagonal is null. Thus, the last \nnumbered block in a flled matrix of N rows and \ncolumns is number N2 − N. \n• Lower half: Numbered from 0, with no data blocks \non the diagonal, the total of blocks for i rows in the \nlower half (below diagonal) is (i + 1)2 − (i + 1) = \ni2 + i, with the last data block in the lower half \nnumbered as i2 + i, and because the diagonal is \nempty, j = i − 1. The frst data block in row i is \ni2 − i + 2, with j = 0. \n• Upper half: the last upper half data block in column \nj is j2 + j − 1, with i = j − 1. \nFor a block B in the lower half (B is even), i, j indices \ncan be computed as: \n√ \n√\n√ \ni = ⌊ B⌋ + [B > ⌊ B⌋(⌊ B⌋ + 1)] \nj = (B − (i2 − i + 2))/2 \nand for block B in the upper half (B is odd), i, j indices can \nbe computed as: : \np \np\np\nj = ⌊ (B + 1)⌋ + [B ≥⌊ (B + 1)⌋(⌊ (B + 1)⌋ + 1)] \ni = (B − (j2 − j + 1))/2 \nNote: [ϵ] is the Iverson bracket where [ϵ] = 1 if expression ϵ \nevaluates to true, and 0 otherwise. \nBlocks can now be deleted by overwriting with zeroes, \nwith one row and one column hash recalculated. Specifcally, \nafter deleting block i, j, row i and column j hash values \nare recalculated. The block matrix data structure may have \nutility for incorporation into applications requiring integrity \nprotection that currently use permissioned blockchains. This \ncapability could for example be useful in meeting privacy \nrequirements such as the European Union General Data Pro­\ntection Regulation (GDPR), which requires that organizations \nmake it possible to delete all information related to a particular \nindividual, at that person’s request. This requirement may be \nincompatible with current blockchain data structures, including \npermissioned blockchains [2] [3] [4], because blockchains are \ndesigned to ensure that block contents are immutable. Any \nchange in a blockchain will invalidate subsequent hashes in \nfollowing blocks, losing integrity protection. The data block \nmatrix structure retains integrity protection of non-deleted \nblocks. Note that this data structure could also be extended \nbeyond two dimensions to an arbitrary number of dimensions, \nwith extensions to the algorithms above. \nACKNOWLEDGMENTS \nMany thanks to Lee Badger, Jeff Voas, Sandy Ressler, \nDylan Yaga, and Peter Mell for review and discussion of the \noriginal paper on this work. Thanks to Peter for suggesting \nthe alternative of hashing a concatenation of block hashes. \nREFERENCES \n[1] D Richard Kuhn. A data structure for integrity protection with erasure \n"
  },
  {
    "chunk_id": "A Data Structure for Integrity Protection with Erasure Capability_chunk_6",
    "filename": "A Data Structure for Integrity Protection with Erasure Capability.pdf",
    "page_num": 4,
    "text": "beyond two dimensions to an arbitrary number of dimensions, \nwith extensions to the algorithms above. \nACKNOWLEDGMENTS \nMany thanks to Lee Badger, Jeff Voas, Sandy Ressler, \nDylan Yaga, and Peter Mell for review and discussion of the \noriginal paper on this work. Thanks to Peter for suggesting \nthe alternative of hashing a concatenation of block hashes. \nREFERENCES \n[1] D Richard Kuhn. A data structure for integrity protection with erasure \ncapability. NIST Cybersecurity Whitepaper, 2018. \n2"
  },
  {
    "chunk_id": "A Data Structure for Integrity Protection with Erasure Capability_chunk_7",
    "filename": "A Data Structure for Integrity Protection with Erasure Capability.pdf",
    "page_num": 5,
    "text": "NIST CSWP 25 \nA DATA STRUCTURE FOR INTEGRITY PROTECTION \nWITH ERASURE CAPABILITY \n[2] Matthias Berberich and Malgorzata Steiner. Blockchain technology and \nthe gdpr-how to reconcile privacy and distributed ledgers. Eur. Data Prot. \nL. Rev., 2:422, 2016. \n[3] Henry Chang. Blockchain: Disrupting data protection? Privacy Law and \nBusiness International Report, November, 2017. \n[4] O. Kharif. Is your blockchain doomed? Bloomberg Business Week, Mar. \n22, 2018. \n3"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_0",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 1,
    "text": "NISTIR 7849 \n \n \nA Methodology for Developing \nAuthentication Assurance Level \nTaxonomy for Smart Card-based \nIdentity Verification \n \n \nRamaswamy Chandramouli \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nhttp://dx.doi.org/10.6028/NIST.IR.7849"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_1",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 2,
    "text": "NISTIR 7849 \n \n \nA Methodology for Developing \nAuthentication Assurance Level \nTaxonomy for Smart Card-based \nIdentity Verification \n \nRamaswamy Chandramouli \nComputer Security Division \nInformation Technology Laboratory \n \n \n \n \n \n \n \n \n \n \n \nMarch 2014 \n \n \n \n \n \n \nU.S. Department of Commerce \nPenny Pritzker, Secretary \n \nNational Institute of Standards and Technology \nPatrick D. Gallagher, Under Secretary of Commerce for Standards and Technology and Director \nhttp://dx.doi.org/10.6028/NIST.IR.7849"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_2",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 3,
    "text": "ii \nNational Institute of Standards and Technology Interagency or Internal Report 7849 \n40 pages (March 2014) \n \nCertain commercial entities, equipment, or materials may be identified in this document in order to describe an \nexperimental procedure or concept adequately. Such identification is not intended to imply recommendation or \nendorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best \navailable for the purpose.  \nThere may be references in this publication to other publications currently under development by NIST in \naccordance with its assigned statutory responsibilities. The information in this publication, including concepts and \nmethodologies, may be used by Federal agencies even before the completion of such companion publications. Thus, \nuntil each publication is completed, current requirements, guidelines, and procedures, where they exist, remain \noperative. For planning and transition purposes, Federal agencies may wish to closely follow the development of \nthese new publications by NIST.   \nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback \nto NIST. All NIST Computer Security Division publications, other than the ones noted above, are available at \nhttp://csrc.nist.gov/publications. \n \n \n \n \n \n \n \n \n \n \n \nComments on this publication may be submitted to: \nNational Institute of Standards and Technology \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_3",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 4,
    "text": "iii \nReports on Computer Systems Technology \n \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and Technology \n(NIST) promotes the U.S. economy and public welfare by providing technical leadership for the Nation’s \nmeasurement and standards infrastructure. ITL develops tests, test methods, reference data, proof of \nconcept implementations, and technical analyses to advance the development and productive use of \ninformation technology. ITL’s responsibilities include the development of management, administrative, \ntechnical, and physical standards and guidelines for the cost-effective security and privacy of other than \nnational security-related information in Federal information systems. \n \nAbstract \n \nSmart cards (smart identity tokens) are now being extensively deployed for identity verification for \ncontrolling access to Information Technology (IT) resources as well as physical resources. Depending \nupon the sensitivity of the resources and the risk of wrong identification, different authentication use \ncases are being deployed. Assignment of authentication strength for each of the use cases is often based \non: (a) the total number of three common orthogonal authentication factors – What You Know, What You \nHave and What You are, and (b) the entropy associated with each factor chosen. The objective of this \npaper is to analyze the limitation of this approach and present a methodology for assigning authentication \nstrengths based on the strength of pair wise bindings between the five entities involved in smart card \nbased authentications – the card (token), the token secret, the card holder, the card issuer, and the person \nidentifier stored in the card. The rationale for the methodology is based on the following three \nobservations: (a) The form factor of the smart identity token introduces some threats of misuse; (b) the \ncommon set of credentials objects provisioned to a smart card embody bindings to address those threats \nand (c) the strength of an authentication use case should therefore be based on the number and type of \nbinding verifications that are performed in the constituent authentication mechanisms.The use of the \nmethodology for developing an authentication assurance level taxonomy for two real world smart identity \ntoken deployments is also illustrated. \n \nKeywords \n \ncard issuer; cardholder trait (biometric); person identifier; smart identity token; token secret."
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_4",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 5,
    "text": "iv \nAcknowledgements \n \nThe author, Ramaswamy Chandramouli (Mouli), would like to thank his colleagues Hildegard Ferraiolo \nand Patrick Grother for serving as reviewers for this document. The author also acknowledges Elizabeth \nLennon for her technical editing and administrative support. \n \nAudience \n \nThis document analyzes the authentication mechanisms used with smart identity tokens based on some \nfundamental principles in order to derive a metric for assigning appropriate authentication strengths to \nthem. The potential audiences that could benefit from this document are: \n• \nPublic and Private Sector communities seeking to deploy smart cards for identity verification \n(smart identity tokens) for various access control applications; \n• \nVendor communities seeking to personalize smart identity tokens; and \n• \nTesting communities seeking to evaluate smart identity token deployments for required \nauthentication strengths."
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_5",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 6,
    "text": "v \nTABLE OF CONTENTS \n1. Introduction ......................................................................................................................... 1 \n2. Limitations of Authentication Factor-Based Approach .................................................... 2 \n3. Anatomy of Smart Card-Based Identity Verification ......................................................... 3 \n3.1 \nTrust Creation in Identity Token Eligibility Determination Phase ................................................ 4 \n3.2 \nCreation of Trust Bindings in the Identity Token Issuance Phase .............................................. 4 \n3.3 \nVerification of Trust Bindings in Identity Token Usage Phase .................................................... 5 \n4. Smart Cards – Common Credential Objects, Embodied Bindings and Verifying \nPrimitive Authentication Mechanisms ............................................................................... 6 \n4.1 \nObjects on Smart Identity Tokens ............................................................................................... 6 \n4.2 \nDigitally Signed Cardholder Unique Identifier (CHUID) Object .................................................. 7 \n4.3 \nCard Authentication Certificate Object ........................................................................................ 8 \n4.4 \nPersonal Authentication Certificate Object ................................................................................. 8 \n4.5 \nDigitally Signed Biometric Record Object ................................................................................... 9 \n4.6 \nPhysical Token-exclusive Secret Object ..................................................................................... 9 \n4.6.1 \nAuthenticating the Physical Token ...................................................................................... 9 \n4.6.2 \nAuthenticating the Association of Person Identifier to the Physical Token ......................... 9 \n4.7 \nSecret Shared Betwen Physical Token and Cardholder .......................................................... 10 \n4.8 \nSecret Shared Between Card Issuer and Physical Token........................................................ 10 \n4.9 \nThreat Coverage of Primitive Authentication Mechanisms ....................................................... 12 \n5. Development of Authentication Assurance Level Taxonomy for Canonical \nAuthentication Use Cases .................................................................................................15 \n6. Conclusions and Benefits..................................................................................................20 \nBibliography ............................................................................................................................21 \nAppendix A— Case Study: PIV Authentication Use Cases ..................................................22 \nA.1 \nOverview of PIV Program ......................................................................................................... 22 \nA.2 \nBrief Description of PIV Authentication Use Cases & Specified Assurance Levels ................. 22 \nA.3 \nSCIV-ALM Assigned Intrinsic Authentication Strengths for PIV Authentication Use Cases .... 24 \nA.4 \nSCIV-ALM Authentication Assurance Level Taxonomy for PIV Authentication Use Cases ..... 27 \nA.5 \nComparison of Assigned Authentication Assurance Levels in PIV Specification and SCIV-ALM28 \nA.5.1 \nHierarchical Authentication Assurance Levels between PKI-CAK and BIO ..................... 28 \nA.5.2 \nIdentical Authentication Assurance Levels to BIO-A and PKI-AUTH ............................... 28 \nA.5.3 \nIdentical Authentication Assurance Level to BIO-A and OCC-AUTH ............................... 29 \nAppendix B— Case Study: TWIC Authentication Use Cases...............................................30 \nB.1 \nGeneral Overview of the TWIC Program .................................................................................. 30 \nB.2 \nBrief Description of TWIC Authentication Use Cases and Specified Assurance Levels .......... 30 \nB.3 \nSCIV-ALM Assigned Intrinsic Authentication Strengths for TWIC Authentication Use Cases . 32 \nB.4 \nSCIV-ALM Authentication Assurance Level Taxonomy for TWIC Authentication Use Cases . 34 \nB.5 \nComparison of Assigned Authentication Levels in TWIC Specification and SCIV-ALM .......... 35 \nB.5.1 \nDirect Traceability to Trust Link established during Card Issuance in SCIV-ALM ............ 35 \nB.5.2 \nProviding Distinguishing Criteria for choosing between two Use Cases at the same \nAssurance Level in SCIV"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_6",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 6,
    "text": "SCIV-ALM Authentication Assurance Level Taxonomy for TWIC Authentication Use Cases . 34 \nB.5 \nComparison of Assigned Authentication Levels in TWIC Specification and SCIV-ALM .......... 35 \nB.5.1 \nDirect Traceability to Trust Link established during Card Issuance in SCIV-ALM ............ 35 \nB.5.2 \nProviding Distinguishing Criteria for choosing between two Use Cases at the same \nAssurance Level in SCIV-ALM .......................................................................................... 35"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_7",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 7,
    "text": "A  METHODOLOGY FOR DEVELOPMENT OF AUTHENTICATION ASSURANCE TAXONOMY FOR SMART CARD BASED IDENTITY VERIFICATION    \n \n 1 \n \n1. \nIntroduction \nWith the proliferation of web-based applications and e-commerce transactions, the field of identity verification or \nauthentication of humans has evolved from the concept of using identities tied to a specific entitlement (e.g., a \ndriver’s license or passport) to the concept of using generic trusted digital identities that can be relied upon and \nconsumed by multiple types of service providers. Another evolutionary trend is the use of multiple form factors to \ncarry or support these trusted identities. Smart cards and Smart phones are two such form factors. \n \nSmart cards are now being extensively deployed for identity verification for controlling access to Information \nTechnology (IT) resources as well as physical resources [Ham2001, Kum2008, TWIC2008].We refer to those \ntypes of cards as Smart Identity Tokens and use the two terms interchangeably throughout this paper. These types \nof smart cards generally carry: (a) A Person Identifier (PI), (b) A Secret (TS) usually in the form of a \ncryptographic key [EAG2013], (c) A Credential linking the Secret and the Identifier (CR) and (d) A Credential \nlinking the Identifier with a Personal Trait of the Cardholder (e.g., biometric) (BR). Along with these data, \nanother secret, a PIN (a combination of numbers) is often used for: (a) Activating the card (token) and for (b) \nRestricting access to certain data objects and operations. In some instances, presentation of a live biometric data \n(such as a fingerprint) is used to enable the above functions instead of a PIN. In any enterprise deploying smart \ncards, there may be different types of resources that may have to be protected by restricting access to only those \nwhose identity is verified through a smart card based authentication mechanism. Depending upon the sensitivity \nof the resource and the risk associated with wrong identification of the entity requesting access to those resources, \nauthentication mechanisms use different combinations of the four data types enumerated above (i.e., PI, TS, CR \nor BR) along with/without an activation data. One or more of authentication mechanisms in turn constitute an \nauthentication use case and a typical identification verification deployment instance uses multiple authentication \nuse cases to cover access to resources of multiple sensitivity levels. \n \nThe choice of an authentication use case (irrespective of whether a smart identity token is used or not) in any \ndeployment instance, therefore, depends upon the overall authentication assurance level provided by the \ncombination of constituent authentication mechanisms.The usage of a token by a claimant during an \nauthentication event results in a value called Authenticator that is generated by the token and is transmitted from \nthe token to the authentication module or the verifier. The basis for designating an authentication strength \nassociated with a token is a fundamental unit called “Authentication Factor”. There are three main authentication \nfactors [OMB2003]: \n \n• \nWhat the Entity Knows (e.g., Password, PIN, etc) \n• \nWhat the Entity Has (e.g., possession of a token that generates one-time passwords) \n• \nWhat the Entity Is (e.g., inherent physiological characteristic such as a fingerprint) \n \nA token that uses one of the above three factors is called a single factor token (e.g., a password that belongs to \n“What the Entity Knows” factor). A token that uses a combination of two or more of the above factors is called a \nmulti-factor token. A smart card that contains an embedded private cryptographic"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_8",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 7,
    "text": " Has (e.g., possession of a token that generates one-time passwords) \n• \nWhat the Entity Is (e.g., inherent physiological characteristic such as a fingerprint) \n \nA token that uses one of the above three factors is called a single factor token (e.g., a password that belongs to \n“What the Entity Knows” factor). A token that uses a combination of two or more of the above factors is called a \nmulti-factor token. A smart card that contains an embedded private cryptographic key (thus using  “What the \nEntity Has” authentication factor) that can be used to generate an authenticator when it is activated by a PIN, \n(using the “What the Entity Knows” authentication factor) is deemed a two-factor token. An authentication use \ncase may use one or more tokens and hence may involve the use of one or more authentication factors. In general, \nthe authentication strength associated with an authentication use case is determined based on the combination of \nthe following metrics: \n \n• \nThe number of authentication factors used in the authentication use case \n• \nThe Entropy associated with each of the authenticator factors used"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_9",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 8,
    "text": "A  METHODOLOGY FOR DEVELOPMENT OF AUTHENTICATION ASSURANCE TAXONOMY FOR SMART CARD BASED IDENTITY VERIFICATION    \n \n 2 \nIn this publication, we argue that the logic for assigning authentication strength based on the number of \nauthentication factors in an authentication use case is valid only under certain limiting conditions and that these \nconditions do not hold in the case of authentication use cases using smart cards as identity tokens. This is the \nrationale for proposing a new methodology for: (a) Assigning authentication strengths or levels for various \nauthentication use cases involving smart identity tokens and (b) Deriving an authentication assurance taxonomy \nusing the relative strengths of all authentication use cases specified for the deployment. \n \nThe limitations of the authentication factor-based approach for determining authentication assurance level and \njustifications for a new methodology are outlined in Sec. 2. The overall anatomy of smart card-based identity \nverification is analyzed in Sec. 3. The analysis leads to the identification of bindings established in the initial \nphases of smart card-based identity verification deployment which then forms the foundational concept for our \nmethodology. The next two sections (Sec. 4 and 5) describe the core steps of our methodology. In Sec. 4, we \nenumerate the typical set of data objects found in smart cards used in identity verification, the trust bindings each \nof those objects embodies and the primitive authentication mechanisms that verify those bindings. Section 5 goes \non to demonstrate the process of deriving an authentication strength (based on the composition of verified \nbindings as well as their number and type) for any authentication use case constructed using the primitive \nauthentication mechanisms discussed in Sec. 4. By examining the composition of the “set of verified bindings” in \nvarious authentication use cases, it is possible to derive partial orderings among those use cases. These partial \norderings, in turn, are used to develop the authentication assurance taxonomy for the total set of authentication use \ncases specified for a smart identity token deployment. Section 6 provides the conclusions and benefits of our \nmethodology. \n \nIn Appendices A and B we demonstrate the use of our methodology to real-world smart identity token \ndeployments. The deployments are: (a) Personal Identity Verification (PIV) program of the US Government and \n(b) Transporation Worker Identification program (TWIC) of the Department of Homeland Security. More \nspecifically, Appendix A describes the application of our methodology to PIV authentication use cases while \nAppendix B illustrates our methodology for TWIC authentication use cases. The outcome of the assignment of \nauthentication assurance levels based on our methodology to the complete set of authentication use cases in these \ntwo deployments results in an authentication assurance taxonomy for each of them.  \n  \n2. \nLimitations of Authentication Factor-Based Approach \nIn identity verification schemes where trusted identities are provisioned to devices with various form factors (e.g., \nsmart cards, smart phones etc), the authentication factor-based approach for determining authentication strengths \n(for authentication mechanisms) does not provide the right measure of identity assurance. This is due to the fact \nthat the form factor of the devices introduces some threats of misuse which may not be adequately detected by \nsome authentication mechanisms used in those devices-based identity verification deployments. These threats are \nbriefly described here below. We use the abbreviation convention FF-Tx to designate each threat (FF stands for \nForm Factor and Tx is the sequence number for the threat) \n \n• \nFF-T1: STOLEN DEVICE (with unaltered credentials): The person trying to obtain authentication using \nthe device is not the owner of the device/legitimate holder of the credential. This results in \n“Imperson"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_10",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 8,
    "text": " authentication mechanisms used in those devices-based identity verification deployments. These threats are \nbriefly described here below. We use the abbreviation convention FF-Tx to designate each threat (FF stands for \nForm Factor and Tx is the sequence number for the threat) \n \n• \nFF-T1: STOLEN DEVICE (with unaltered credentials): The person trying to obtain authentication using \nthe device is not the owner of the device/legitimate holder of the credential. This results in \n“Impersonation” threat. \n• \nFF-T2: CLONED DEVICE (with unaltered credentials): The device containing the credential could be a \nclone of the device where the original credentials had been provisioned by the legitimate identity \nprovider/credential issuer/authorized device issuer. The threat here is “Unauthorized Proliferation of \nCredentials and Resulting Misuse.” \n• \nFF-T3: FORGED CREDENTIAL: The credential on the device has not originated from an authorized \nissuer/identity provider. Specifically it does not carry the proof that it was created/assigned by an \nauthorized identity provider and has not been tampered with after issuance."
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_11",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 9,
    "text": "A  METHODOLOGY FOR DEVELOPMENT OF AUTHENTICATION ASSURANCE TAXONOMY FOR SMART CARD BASED IDENTITY VERIFICATION    \n \n 3 \nThus we see that there is a need for an authentication assurance methodology that takes into account inherent \ncharacteristics of the device supporting the trusted identities. Since smart card is the most prevalent device used \nfor provisioning of credentials, we now proceed to analyze the anatomy of smart card-based identity verification \nin the next section. \n \n3. \nAnatomy of Smart Card-Based Identity Verification \nSmart card-based identity verification is the most widely deployed form of device-based authentication scheme \nwhere trusted identities are provisioned to credit card-sized plastic cards embedded with an Integrated Circuit \nChip (ICC). A deployment instance may use multiple authentication use cases depending upon the sensititivity of \nthe various resources that are sought to be protected in its environment. An authentication use case in turn will \nconsist of one or more authentication mechanisms. Every authentication mechanism, in this context, will involve \nuse of the device (the smart card or smart identity token1 in our context) but some of them may not require \nparticipation of the user/bearer of the device since the underlying protocol may not call for the bearer input (e.g., a \nPIN or biometric sample). \n \nIn order to assess the authentication strengths associated with authentication mechanisms using a smart card, we \nneed to look at the typical phases involved in any smart card-based identity verification scheme (smart identity \ntoken) deployment. They are: \n \n• \nIdentity Token Eligibility Determination Phase \n• \nIdentity Token Issuance Phase \n• \nIdentity Token Usage Phase \n \nOut of the three phases above, the authentication mechanisms and by extension the authentication use cases come \ninto the picture only in the Identity Token Usage Phase. Since the objective of this paper is a methodology for \nassignment of authentication assurance level/strength for authentication use cases, our focus should be on the \nIdentity Token Usage phase. However, we find that in order to arrive at a meaningful authentication strength \nmetric, we need to examine all three phases because of the following rationale. \n \n• \nThe overall authentication strength in authentication use cases deployed in the Identity Token Usage \nphase is derived from the combination of trust levels in its constitutent authentication mechanisms. The \ntrust level of an authentication mechanism, in turn, is based on the number of trust bindings (embedded in \ncredential objects) it verifies. \n \n• \nThe trust in the set of credential objects that are provisioned to the smart identity token during the Identity \nToken Issuance phase comes from the bindings it embodies and from the overall security of the system \nprocesses used in their generation – security for the data repositories holding the enrollment records, trust \nin attestion authority that is vouching for credential bindings (e.g., Certificate Authorities (CAs) for \ndigital certificates). \n \n• \nThe basis for creation of credential objects in turn is the “Proofed Identity” which is embodied in the set \nof data records called enrollment records that are created after a successful “Identity Proofing” process in \nthe Identity Token Eligibility Determination phase. \n \nThus we see that the trust marker or “Proofed Identity” for the individual being authenticated is established in the \nToken Eligibility Determination Phase which together with other data in the enrollment records forms the basis \nfor creation of credential objects in the Token Issuance phase. The credential objects by definition embody a \n“stamp of authority” or trust binding in each of them. Since the purpose of any authentication mechanism is to \n                                                     \n1  We will the two terms interchangeably in this document"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_12",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 10,
    "text": "A  METHODOLOGY FOR DEVELOPMENT OF AUTHENTICATION ASSURANCE TAXONOMY FOR SMART CARD BASED IDENTITY VERIFICATION    \n \n 4 \nverify/validate those bindings, any assessment of its strength should involve the set of bindings it verifies as a \nprime metric. Hence identification of the verified bindings of an authentication mechanism logically forms the \nfirst step of our methodology. Before we proceed to that step, we take a look at the various activities leading up to \nthe creation of those credential objects and the issuance of the smart identity token in order to fully understand the \nnature of the trust chain. \n \n3.1 \nTrust Creation in Identity Token Eligibility Determination Phase \nThe primary processes in this phase are identity proofing and enrollment/registration. The “identity proofing” \nstarts with verification of one or more source documents attesting to the identity of the intended card/credential \nholder together with/without consultation of authoritative data repositories (e.g., use of credit history records and \nthe use of Criminal History database for background verification). The degree of trust in the identity of the \nindividual undergoing identity proofing process is determined by the nature and number of source documents \nused. This trust is then concretized in an artifact called \"proofed identity\" in order to be carried over to the next \nphase of the smart identity token deployment. The most common artifact is usually a set of fingerprints \n[NSTC2008] which are collected at the conclusion of a successful identity proofing process. This artifact thus \ncreates the “binding” between the person who has undergone identity proofing and the \"prospective credential \nholder/identity token holder\" since the tokens are going to carry the provisioned credentials.The biographical \ndetails gathered from the source documents together with the proofed identity are stored in a formal system of \nrecords (called the enrollment records) during the enrollment/registration process of this phase. \n \n3.2 \nCreation of Trust Bindings in the Identity Token Issuance Phase \nThe processes in this phase include the following: \n \n• \nAssignment of a unique person identifier to the token holder: The person identifier can either be: (a) \nlocally unique (e.g., employee number in an organization) or (b) globally unique (i.e., UUID). \n \n• \nCreation of credentials that embody various types of “trust bindings” and provisioning them to the \ntoken/smart card: The choice of a trust binding and by extension the choice of a credential that embodies \nthat binding is based on the degree of assurance it provides against exploitation of threats EF-T1, EF-T2 \nand EF-T3 described in section 2. The required assurance, at the minimum, are: \n \n(a) The assigned person identifier has originated from an authorized credential/token issuer  \n      (assurance against the threat of faked or forged credential –FF-T3); \n \n(b) The assigned person identifier pertains to the person who has been successfully “identity proofed”.It \nis for this purpose that the “proofed identity” created in the token eligibility determination phase is \nused (assurance that the token recipient is the person who has undergone “identity proofing”); \n \n(c) The token instance carrying the person identifier is the physical copy to which the identifier was \nprovisioned by the authorized token issuer (assurance against the threat of cloned token-FF-T2); and \n \n(d) The person presenting the token (token holder or cardholder) is the person to whom the token was \nissued by the authorized token issuer. (assurance against the threat of stolen card/impersonation –FF-\nT1). \n \n• \nThe physical"
  },
  {
    "chunk_id": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10_chunk_13",
    "filename": "A Methodology for Developing Authentication Assurance Level Taxonomy for Smart Card-based Identity Verification_first10.pdf",
    "page_num": 10,
    "text": "”); \n \n(c) The token instance carrying the person identifier is the physical copy to which the identifier was \nprovisioned by the authorized token issuer (assurance against the threat of cloned token-FF-T2); and \n \n(d) The person presenting the token (token holder or cardholder) is the person to whom the token was \nissued by the authorized token issuer. (assurance against the threat of stolen card/impersonation –FF-\nT1). \n \n• \nThe physical handover of the smart identity token to the legitimate credential owner: Here we need the \ntrust (or assurance) that the person receiving the physical token is the same person for whom identity \nproofing was done and whose credentials are now provisioned to the token. This assurance is obtained by \nmaking the token recipient authenticate against the proofed identity created during the token eligibility \nphase and now provisioned to the token. For example if a set of fingerprints collected during enrollment is"
  },
  {
    "chunk_id": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10_chunk_0",
    "filename": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10.pdf",
    "page_num": 1,
    "text": "NIST Special Publication 800-152 \n \nA Profile for U.S. Federal \nCryptographic Key \nManagement Systems \n \n \nElaine Barker \nMiles Smid \nDennis Branstad  \n \n \n \n \n \nThis publication is available free of charge from: \nhttp://dx.doi.org/10.6028/NIST.SP.800-152 \n \n \n \n \n \n \n \n \n \n \n \n \nC  O  M  P  U  T  E  R      S  E  C  U  R  I  T  Y"
  },
  {
    "chunk_id": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10_chunk_1",
    "filename": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10.pdf",
    "page_num": 2,
    "text": "NIST Special Publication 800-152 \n \n \nA Profile for U. S. Federal \nCryptographic Key \nManagement Systems \nElaine Barker \nComputer Security Division \nInformation Technology Laboratory  \n \nMiles Smid  \nG2, Inc.  \nAnnapolis Junction, MD   \n \nDennis Branstad  \nNIST Consultant  \nAustin, TX \n \nThis publication is available free of charge from: \nhttp://dx.doi.org/10.6028/NIST.SP.800-152 \n \n \nOctober 2015 \n \n \n \nU.S. Department of Commerce  \nPenny Pritzker, Secretary \n \nNational Institute of Standards and Technology  \nWillie May, Under Secretary of Commerce for Standards and Technology and Director"
  },
  {
    "chunk_id": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10_chunk_2",
    "filename": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10.pdf",
    "page_num": 3,
    "text": "ii\nAuthority \nThis publication has been developed by NIST to further its statutory responsibility under the \nFederal Information Security Modernization Act (FISMA) of 2014, 44 U.S.C. § 3541 et seq., \nPublic Law (P.L.) 113-283. NIST is responsible for developing information-security standards and \nguidelines, including minimum requirements for Federal information systems, but such standards \nand guidelines shall not apply to national security systems without the express approval of \nappropriate Federal officials exercising policy authority over such systems. This guideline is \nconsistent with the requirements of the Office of Management and Budget (OMB) Circular \nA-130. \nNothing in this publication should be taken to contradict the standards and guidelines made \nmandatory and binding on Federal agencies by the Secretary of Commerce under statutory \nauthority. Nor should these guidelines be interpreted as altering or superseding the existing \nauthorities of the Secretary of Commerce, Director of the OMB, or any other Federal official.  \nThis publication may be used by nongovernmental organizations on a voluntary basis and is not \nsubject to copyright in the United States. Attribution would, however, be appreciated by NIST.  \nNational Institute of Standards and Technology Special Publication 800-152 \nNatl. Inst. Stand. Technol. Spec. Publ. 800-152, 146 pages (October 2015) \nCODEN: NSPUE2 \nThis publication is available free of charge from: \nhttp://dx.doi.org/10.6028/NIST.SP.800-152  \nCertain commercial entities, equipment, or materials may be identified in this document in order to describe an \nexperimental procedure or concept adequately. Such identification is not intended to imply recommendation or \nendorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best \navailable for the purpose.  \nThere may be references in this publication to other publications currently under development by NIST in \naccordance with its assigned statutory responsibilities. The information in this publication, including concepts and \nmethodologies, may be used by federal agencies even before the completion of such companion publications. Thus, \nuntil each publication is completed, current requirements, guidelines, and procedures, where they exist, remain \noperative. For planning and transition purposes, federal agencies may wish to closely follow the development of \nthese new publications by NIST.   \nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback \nto NIST. All NIST Computer Security Division publications, other than the ones noted above, are available at \nhttp://csrc.nist.gov/publications. \nComments on this publication may be submitted to: \nNational Institute of Standards and Technology \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 \nEmail: FederalCKMSProfile@nist.gov"
  },
  {
    "chunk_id": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10_chunk_3",
    "filename": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10.pdf",
    "page_num": 4,
    "text": "iii \n \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test \nmethods, reference data, proof-of-concept implementations, and technical analyses to advance \nthe development and productive use of information technology. ITL’s responsibilities include the \ndevelopment of management, administrative, technical, and physical standards and guidelines for \nthe cost-effective security and privacy of other than national security-related information in \nfederal information systems. The Special Publication 800-series reports on ITL’s research, \nguidelines, and outreach efforts in information system security, and its collaborative activities \nwith industry, government, and academic organizations. \n \nAbstract \nThis Profile for U. S. Federal Cryptographic Key Management Systems (FCKMSs) contains \nrequirements for their design, implementation, procurement, installation, configuration, \nmanagement, operation, and use by U. S. Federal organizations. The Profile is based on NIST \nSpecial Publication (SP) 800-130, A Framework for Designing Cryptographic Key Management \nSystems (CKMS). \n \n \nKeywords \naccess control; confidentiality; cryptographic key management system; disaster recovery; federal \ncryptographic key management system; integrity; metadata; security assessment; security \nfunctions; security policies; source authentication. \n \n \n \nAcknowledgements \n \nThe National Institute of Standards and Technology (NIST) acknowledges and greatly \nappreciates contributions by all those who participated in the creation, review, and publication of \nthis document. NIST also thanks the many public and private sector contributors whose \nconstructive comments significantly improved its quality and usefulness. Many useful \nsuggestions on Cryptographic Key Management that were made during the workshops held at \nNIST in 2009, 2010, 2012, and 2014 have been incorporated into this document."
  },
  {
    "chunk_id": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10_chunk_4",
    "filename": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10.pdf",
    "page_num": 5,
    "text": "SP 800-152 \n \nA Profile for U.S. Federal CKMS \niv \n \n \nExecutive Summary \nThe National Institute of Standards and Technology (NIST) Cryptographic Key Management \nproject covers major aspects of managing the cryptographic keys that protect sensitive, \nunclassified federal information.  Associated with each key is specific information (e.g., the \nidentifier associated with its owner, its length, and acceptable uses) called metadata.  The \ncomputers, software, modules, communications, and roles assumed by one or more authorized \nindividuals when managing and using cryptographic key management services are collectively \ncalled a Cryptographic Key Management System (CKMS). \nThis Profile for U. S. Federal Cryptographic Key Management Systems (FCKMSs) has been \nprepared to assist CKMS designers and implementers in selecting the features to be provided in \ntheir “products,” and to assist federal organizations and their contractors when procuring, \ninstalling, configuring, operating, and using FCKMSs. Other organizations may use this Profile \nas desired. \nAn FCKMS can be owned and operated by a federal organization or by a private contractor that \nprovides key management services for federal organizations or other contractors performing \nfederal information-processing services. \nThis Profile can also be used by agencies and organizations to understand their FCKMSs, and to \nadopt, adapt and migrate their FCKMSs to comply with the Profile requirements over time.  \nNIST does not expect that these requirements would be implemented immediately, but that \nagencies would use these requirements when creating or procuring FCKMSs or FCKMS services \nfor their Enterprise Architectures. \nThis Profile is based on NIST Special Publication 800-130, A Framework for Designing \nCryptographic Key Management Systems. The Framework specifies topics that should be \nconsidered by a CKMS designer when selecting the capabilities that a CKMS will have and the \ncryptographic key management services it will support.  This Profile replicates all of the \nFramework requirements that must be satisfied in a CKMS and its design documentation, and \nincludes additional information about installing, configuring, operating and maintaining an \nFCKMS. \nThe Framework and this Profile could be used by other organizations that have security \nrequirements similar to those specified in these documents or could be used as a model for the \ndevelopment of other profiles."
  },
  {
    "chunk_id": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10_chunk_5",
    "filename": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10.pdf",
    "page_num": 6,
    "text": "SP 800-152 \n \nA Profile for U.S. Federal CKMS \nv \n \nTable of Contents \n1 \nIntroduction .............................................................................................................. 1 \n1.1 Profile Terminology ......................................................................................... 2 \n1.2 Scope of this Profile ........................................................................................ 3 \n1.3 Audience ......................................................................................................... 4 \n1.4 Organization .................................................................................................... 4 \n2 \nProfile Basics ........................................................................................................... 6 \n2.1 Profile Topics and Requirements, Augmentations, and Features ................... 6 \n2.2 Rationale for Cryptographic Key Management ............................................... 7 \n2.3 Keys, Metadata, Trusted Associations, and Bindings ..................................... 8 \n2.4 FCKMS Functions ........................................................................................... 9 \n2.5 CKMS Design ................................................................................................. 9 \n2.6 CKMS Profile ................................................................................................ 10 \n2.7 FCKMS Profile .............................................................................................. 10 \n2.8 Differences between the Framework and This Profile ................................... 10 \n2.9 Example of a Distributed CKMS Supporting a Secure E-Mail Application .... 10 \n2.10 Modules, Devices, and Components ............................................................ 11 \n3 \nFederal CKMS Goals ............................................................................................. 13 \n3.1 Providing Key Management to Networks, Applications, and Users ............... 13 \n3.2 Maximize the Use of COTS Products in an FCKMS ..................................... 13 \n3.3 Conformance to Standards ........................................................................... 14 \n3.4 Ease-of-use ................................................................................................... 14 \n3.4.1 Accommodate User Ability and Preferences ...................................... 15 \n3.4.2 Design Principles of the User Interface .............................................. 15 \n3.5 Performance and Scalability ......................................................................... 16 \n3.6 Intellectual Property Rights ........................................................................... 17 \n4 \nSecurity Policies .................................................................................................... 18 \n4.1 Information Management Policy .................................................................... 18 \n4.2 Information Security Policy............................................................................ 19 \n4.3 CKMS and FCKMS Security Policies ............................................................ 19 \n4.4 FCKMS Module Security Policy .................................................................... 23 \n4.5 Cryptographic Module Security Policy .......................................................... 24 \n4.6 Other Related Security Policies .................................................................... 25"
  },
  {
    "chunk_id": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10_chunk_6",
    "filename": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10.pdf",
    "page_num": 7,
    "text": "SP 800-152 \n \nA Profile for U.S. Federal CKMS \nvi \n \n4.7 Interrelationships among Policies ................................................................. 25 \n4.8 Personal Accountability ................................................................................. 26 \n4.9 Anonymity, Unlinkability, and Unobservability ............................................... 27 \n4.9.1 Anonymity ........................................................................................... 28 \n4.9.2 Unlinkability ........................................................................................ 28 \n4.9.3 Unobservability ................................................................................... 29 \n4.10 Laws, Rules, and Regulations ....................................................................... 29 \n4.11 Security Domains .......................................................................................... 29 \n4.11.1 \nConditions for Data Exchange .................................................... 30 \n4.11.2 \nAssurance of Protection .............................................................. 30 \n4.11.3 \nEquivalence and Compatibility of FCKMS Security Policies ....... 31 \n4.11.4 \nThird-Party Sharing ..................................................................... 32 \n4.11.5 \nMulti-level Security Domains ....................................................... 32 \n4.11.6 \nUpgrading and Downgrading ...................................................... 33 \n4.11.7 \nChanging FCKMS Security Policies ............................................ 34 \n5 \nRoles and Responsibilities ................................................................................... 35 \n6 \nCryptographic Algorithms, Keys, and Metadata ................................................. 37 \n6.1 Cryptographic Algorithms and Keys .............................................................. 37 \n6.1.1 Key Types, Lengths and Strengths..................................................... 37 \n6.1.2 Key Protections .................................................................................. 38 \n6.1.3 Key Assurance ................................................................................... 38 \n6.2 Key Metadata ................................................................................................ 39 \n6.2.1 Metadata Elements............................................................................. 39 \n6.2.2 Required Key and Metadata Information ............................................ 43 \n6.3 Key Lifecycle States and Transitions ............................................................ 44 \n6.4 Key and Metadata Management Functions................................................... 45 \n6.4.1 Generate a Key .................................................................................. 46 \n6.4.2 Register an Owner.............................................................................. 47 \n6.4.3 Activate a Key .................................................................................... 47 \n6.4.4 Deactivate a Key ................................................................................ 48 \n6.4.5 Revoke a Key ..................................................................................... 48 \n6.4.6 Suspend and Re-Activate a Key ......................................................... 49 \n6.4.7 Renew a Public Key Certificate .......................................................... 49"
  },
  {
    "chunk_id": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10_chunk_7",
    "filename": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10.pdf",
    "page_num": 8,
    "text": "SP 800-152 \n \nA Profile for U.S. Federal CKMS \nvii \n \n6.4.8 Key Derivation or Key Update ............................................................ 51 \n6.4.9 Destroy a Key and Metadata .............................................................. 51 \n6.4.10 \nAssociate a Key with its Metadata .............................................. 52 \n6.4.11 \nModify Metadata ......................................................................... 52 \n6.4.12 \nDelete Metadata .......................................................................... 53 \n6.4.13 \nList Key Metadata ....................................................................... 53 \n6.4.14 \nStore Operational Key and Metadata Outside a \nCryptographic Module ................................................................. 54 \n6.4.15 \nBackup of a Key and its Metadata .............................................. 54 \n6.4.16 \nArchive Key and/or Metadata ...................................................... 54 \n6.4.17 \nRecover a Key and/or Metadata ................................................. 55 \n6.4.18 \nEstablish a Key ........................................................................... 56 \n6.4.19 \nEnter a Key and Associated Metadata into a Cryptographic \nModule ........................................................................................ 56 \n6.4.20 \nOutput a Key and Associated Metadata from a \nCryptographic Module ................................................................. 57 \n6.4.21 \nValidate Public-Key Domain Parameters .................................... 58 \n6.4.22 \nValidate a Public Key .................................................................. 58 \n6.4.23 \nValidate a Public Key Certification Path ...................................... 58 \n6.4.24 \nValidate a Symmetric Key ........................................................... 59 \n6.4.25 \nValidate Possession of a Symmetric Key .................................... 59 \n6.4.26 \nValidate a Private Key (or Key Pair) ............................................ 59 \n6.4.27 \nValidate the Possession of a Private Key ................................... 59 \n6.4.28 \nPerform a Cryptographic Function using the Key ........................ 60 \n6.4.29 \nManage the Trust Anchor Store .................................................. 60 \n6.5 Cryptographic Key and/or Metadata Security: In Storage ............................. 61 \n6.6 Cryptographic Key and Metadata Security: During Key Establishment ......... 62 \n6.6.1 Key Transport ..................................................................................... 62 \n6.6.2 Key Agreement ................................................................................... 63 \n6.6.3 Key Confirmation ................................................................................ 63 \n6.6.4 Key-Establishment Protocols .............................................................. 64 \n6.7 Restricting Access to Key and Metadata Management Functions ................ 64 \n6.7.1 The Access Control System (ACS)..................................................... 64"
  },
  {
    "chunk_id": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10_chunk_8",
    "filename": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10.pdf",
    "page_num": 9,
    "text": "SP 800-152 \n \nA Profile for U.S. Federal CKMS \nviii \n \n6.7.2 Restricting Cryptographic Module Entry and Output of Plaintext \nKeys ............................................................................................ 65 \n6.7.3 Controlling Human Input ..................................................................... 65 \n6.7.4 Multiparty Control ............................................................................... 66 \n6.7.5 Key Splitting ....................................................................................... 66 \n6.8 Compromise Recovery ................................................................................. 67 \n6.8.1 Key Compromise ................................................................................ 67 \n6.8.2 Metadata Compromise ....................................................................... 69 \n6.8.3 Key and Metadata Revocation ........................................................... 70 \n6.8.4 Cryptographic Module Compromise ................................................... 70 \n6.8.5 Computer System Compromise Recovery ......................................... 71 \n6.8.6 Network Security Controls and Compromise Recovery ...................... 72 \n6.8.7 Personnel Security Compromise Recovery ........................................ 73 \n6.8.8 Physical Security Compromise Recovery ........................................... 74 \n7 \nInteroperability and Transitioning ........................................................................ 76 \n8 \nSecurity Controls ................................................................................................... 81 \n8.1 Physical Security Controls ............................................................................ 81 \n8.2 Operating System and Device Security Controls .......................................... 82 \n8.2.1 Operating System Security ................................................................. 82 \n8.2.2 Individual FCKMS Device Security ..................................................... 85 \n8.2.3 Malware Protection ............................................................................. 85 \n8.2.4 Auditing and Remote Monitoring ........................................................ 87 \n8.3 Network Security Control Mechanisms ......................................................... 89 \n8.4 Cryptographic Module Controls ..................................................................... 91 \n8.5 Federal CKMS Security-Control Selection and Assessment Process ........... 91 \n9 \nTesting and System Assurances ......................................................................... 94 \n9.1 CKMS and FCKMS Testing .......................................................................... 94 \n9.2 Third-Party Testing ....................................................................................... 94 \n9.3 Interoperability Testing .................................................................................. 95 \n9.4 Self-Testing ................................................................................................... 96 \n9.5 Scalability Testing ......................................................................................... 96 \n9.6 Functional and Security Testing .................................................................... 96 \n9.7 Environmental Testing .................................................................................. 98"
  },
  {
    "chunk_id": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10_chunk_9",
    "filename": "A Profile for U.S. Federal Cryptographic Key Management Systems (CKMS)_first10.pdf",
    "page_num": 10,
    "text": "SP 800-152 \n \nA Profile for U.S. Federal CKMS \nix \n \n9.8 Ease-of-Use Testing ..................................................................................... 98 \n9.9 Development, Delivery, and Maintenance Assurances ................................. 99 \n9.9.1 Configuration Management ................................................................ 99 \n9.9.2 Secure Delivery ................................................................................ 100 \n9.9.3 Development and Maintenance Environmental Security .................. 100 \n9.9.4 Flaw Remediation Capabilities ......................................................... 101 \n10 Disaster Recovery ............................................................................................... 103 \n10.1 Facility Damage .......................................................................................... 103 \n10.2 Utility Service Outage ................................................................................. 106 \n10.3 Communication and Computation Outage .................................................. 106 \n10.4 FCKMS Hardware Failure ........................................................................... 107 \n10.5 System Software Failure ............................................................................. 108 \n10.6 Cryptographic Module Failure ..................................................................... 109 \n10.7 Corruption and Loss of Keys and Metadata ................................................ 110 \n11 Security Assessment .......................................................................................... 112 \n11.1 Full Security Assessment ............................................................................ 112 \n11.1.1 \nReview of Third-Party Testing and Verification of Test \nResults ...................................................................................... 113 \n11.1.2 \nArchitectural Review of System Design .................................... 114 \n11.1.3 \nFunctional and Security Testing ................................................ 115 \n11.1.4 \nPenetration Testing ................................................................... 115 \n11.2 Periodic Security Review ............................................................................ 116 \n11.3 Incremental Security Assessment ............................................................... 116 \n11.4 Security Maintenance ................................................................................. 117 \n12 Technological Challenges .................................................................................. 119 \nAppendix A: References ........................................................................................... 121 \nAppendix B: Glossary ............................................................................................... 125 \n \nList of Figures \nFigure 1: FCKMS and its FCKMS Modules .............................................................................. 11 \nFigure 2: CKMS Security Policy Configurations........................................................................ 20 \nFigure 3: An FCKMS Network .................................................................................................. 24"
  },
  {
    "chunk_id": "A Report on the Privilege (Access) Management Workshop_first10_chunk_0",
    "filename": "A Report on the Privilege (Access) Management Workshop_first10.pdf",
    "page_num": 1,
    "text": "NISTIR 7657  \nA Report on the \nPrivilege (Access) \nManagement Workshop \nNIST/NSA \nPrivilege Management Conference Collaboration Team"
  },
  {
    "chunk_id": "A Report on the Privilege (Access) Management Workshop_first10_chunk_1",
    "filename": "A Report on the Privilege (Access) Management Workshop_first10.pdf",
    "page_num": 2,
    "text": "NIST IR 7657  \nA Report on the \nPrivilege (Access) \nManagement Workshop \nNIST/NSA \nPrivilege (Access) Management Workshop Collaboration Team \nMarch 2010 \nU. S. Department of Commerce \nGary Locke, Secretary \nNational Institute of Standards and Technology \nPatrick D. Gallagher, Director \nii"
  },
  {
    "chunk_id": "A Report on the Privilege (Access) Management Workshop_first10_chunk_2",
    "filename": "A Report on the Privilege (Access) Management Workshop_first10.pdf",
    "page_num": 3,
    "text": "Certain commercial entities, equipment, or materials may be identified \nin this document in order to describe an experimental procedure or \nconcept adequately. Such identification is not intended to imply \nrecommendation or endorsement by the National Institute of Standards \nand Technology, nor is it intended to imply that the entities, materials, \nor equipment are necessarily the best available for the purpose. \ni"
  },
  {
    "chunk_id": "A Report on the Privilege (Access) Management Workshop_first10_chunk_3",
    "filename": "A Report on the Privilege (Access) Management Workshop_first10.pdf",
    "page_num": 4,
    "text": "Preface \nThis document is based on the discussions and conclusions of the Privilege (Access) \nManagement Workshop held on 1-3 September 2009 at the Gaithersburg, Maryland, facilities of \nthe National Institute of Standards and Technology (NIST), sponsored by NIST and the National \nSecurity Agency (NSA). This document includes additional material resulting from in-scope \ncomments made by workshop participants and the public during the review periods for this \ndocument. An overview of the workshop is available in the published proceedings of the \nworkshop. [NISTIR 7665 - Proceedings of the Privilege Management Workshop, September 1-3, \n2009] \nParticipants at the workshop generally agreed that access management is the umbrella under \nwhich to consider privilege management. At the same time, many workshop participants felt that \nthe term “privilege management” was not needed at all, since all aspects of the discussions held \nin the various tracks could be described without use of the term. Yet, the term “privilege \nmanagement” was being used in several contexts, with differing meanings, and there was a \nstrong desire to clarify its meaning. Contributing to the reason to use the term was the definition \nof “privilege management” that appeared in the draft document1 produced by the Identity, \nCredential, and Access Management (ICAM) Subcommittee just months earlier [FICAM-09 - \nFederal Identity, Credential, and Access Management.] That proposed definition seemed to be \nclosely related to the area being examined at the workshop. Also, the view of privilege \nmanagement expressed in this document generally aligns with the architectural and service \nframework for privilege management presented in the FICAM document. Both the FICAM \ndocument and this report treat privilege management as a subset of access management. \nThe results of the workshop, as described in this report, show that the central topic of the \nworkshop turned out to be attribute and policy management. Whether attribute and policy \nmanagement should be called “privilege management” is an open question at this point. Looking \nat the definitions of “privilege management” in the FICAM document and in this report, it \nappears that they address different levels of concern in the area of identity, credential, and access \nmanagement. The FICAM definition appears to view privilege management as a governance and \nbusiness process, while this report’s definition focuses on computer-based management of \nattributes and policies. As the reader can easily discover, it is possible to substitute “attribute and \npolicy management” for “privilege management” throughout this report without damage to the \ncontent. The question arises, then, as to whether a definition of “privilege management” as found \nin the FICAM extends to the area of access management covered in this report or should be \nlimited to the governance and business process level. It remains for future deliberations, such as \na follow-on workshop, to examine the issues involved and resolve such questions. \nThe discussion in this document is not comprehensive, dealing principally with those ideas, \npoints, gaps, and concerns derived from presentations and discussions at the workshop. In \nparticular, it does not address assurance issues associated with the topics covered because the \nworkshop’s scope specifically excluded assurance considerations, in order to achieve a useful \nfirst step in exploring privilege management. We believe, however, that this report provides a \ngood basis for further exploration of the topics and issues and, in particular, for a follow-on \nworkshop. \n1 Federal Identity, Credential, and Access Management (FICAM) Roadmap and Implementation Guidance \nii"
  },
  {
    "chunk_id": "A Report on the Privilege (Access) Management Workshop_first10_chunk_4",
    "filename": "A Report on the Privilege (Access) Management Workshop_first10.pdf",
    "page_num": 5,
    "text": "Table of Contents  \nIntroduction................................................................................................................................... 1  \nA Context for Thinking About Privilege Management............................................................. 2  \nDefinitions and Standards.......................................................................................................... 12  \nAccess Control Methods............................................................................................................. 14  \nBasic Methods .......................................................................................................................................14  \nEnhancements .......................................................................................................................................15  \nState of the Practice..............................................................................................................................15  \nConsiderations for Implementing Access Control.............................................................................16  \nPolicies and Requirements ......................................................................................................... 19  \nResearch Agenda......................................................................................................................... 21  \nConclusion ................................................................................................................................... 25  \nSummary ...............................................................................................................................................25  \nRecommendations.................................................................................................................................26  \nA Way Forward ....................................................................................................................................26  \nBibliography ................................................................................................................................ 28  \nAnnex A: Authorization and Attributes Glossary ................................................................... 30  \nAnnex B: A Survey of Access Control Methods....................................................................... 32  \nAnnex C: Authoritative Attribute Source and Attribute Service Guidelines ....................... 33  \nAnnex D: Advanced Capabilities for Privilege Management................................................. 34  \nAnnex E: The Policy Machine ................................................................................................... 35  \nAnnex F: Security Framework for Privilege Management..................................................... 36  \niii"
  },
  {
    "chunk_id": "A Report on the Privilege (Access) Management Workshop_first10_chunk_5",
    "filename": "A Report on the Privilege (Access) Management Workshop_first10.pdf",
    "page_num": 6,
    "text": "List of Figures and Tables  \nFigure 1. High-Level View of Access Control ............................................................................ 3  \nFigure 2. High-Level View of Real-Time Access Control ......................................................... 3  \nFigure 3. Authentication Management and Privilege Management ........................................ 5  \nFigure 4. High-Level View of Relationships as a Venn Diagram ............................................. 6  \nFigure 5. Information Managed by Privilege Management...................................................... 7  \nFigure 6. Interfaces of Privilege Management – View One ...................................................... 9  \nFigure 7. Interfaces of Privilege Management – View Two.................................................... 10  \nTable 1. Factors to Consider for the Selection of an Access Control System........................ 16  \niv"
  },
  {
    "chunk_id": "A Report on the Privilege (Access) Management Workshop_first10_chunk_6",
    "filename": "A Report on the Privilege (Access) Management Workshop_first10.pdf",
    "page_num": 7,
    "text": "National Institute of Standards and Technology \nInteragency Report on the Privilege (Access) \nManagement Workshop \nIntroduction \nThis National Institute of Standards and Technology (NIST) Interagency Report (NISTIR) on the \nPrivilege (Access) Management Workshop is organized as follows: \n  A Context for Thinking About Privilege Management: This section describes the full \nscope of enterprise-level access control and management, showing how privilege \nmanagement fits under the umbrella of access management. \n Definitions and Standards: This section examines the need for definitions and standards, \nwith a focus on eXtensible Access Control Markup Language (XACML). \n Access Control Methods: This section identifies current, distinguishable access control \nmethods and focuses on the attribute-based access control method. \n Policies and Requirements: This section presents considerations about digital policy \nmanagement. \n Research Agenda: This section identifies issues in several topical areas of privilege \nmanagement, including policy and attribute management, standards, and several others. \n Conclusion: This section gives a brief summary of the document and provides a list of \nrecommendations. \n Bibliography: This section provides references and other recommended reading. \n Annex A: Authorization and Attributes Glossary \n Annex B: A Survey of Access Control \n Annex C: Authoritative Attribute Source and Attribute Service Guidelines \n Annex D: Advanced Capabilities for Privilege Management \n Annex E: The Policy Machine \n Annex F: An Alternate View \n1"
  },
  {
    "chunk_id": "A Report on the Privilege (Access) Management Workshop_first10_chunk_7",
    "filename": "A Report on the Privilege (Access) Management Workshop_first10.pdf",
    "page_num": 8,
    "text": "A Context for Thinking About Privilege Management \nThis section describes enterprise-level access control and privilege management, both of which \ncome under the umbrella of access management. At the enterprise level, access management \nencompasses all the practices, policies, procedures, data, metadata, and technical and \nadministrative mechanisms used to manage access to the resources of an organization. Access \nmanagement includes access control and privilege management as well as other related \ncapabilities such as identity management. Considering things at the enterprise level ensures that \nall elements of privilege management are included so that the needs of all organizations, large \nand small, can be met. \nPrivilege management at the enterprise level is usefully viewed in relation to enterprise-level \naccess control. Access control ensures that resources are made available only to authorized users, \nprograms, processes, or systems by reference to rules of access that are defined by attributes and \npolicies. Privilege management is the definition and management of attributes and policies that \nare used to decide whether a user’s request for access to some resource should be granted. In this \ncontext, resources can be both computer-based entities (files, Web pages, and so on) and \nphysical entities (buildings, safes, and so on), and users requesting access to resources can be \npeople, processes running on a computer, or devices. Please note that this description of privilege \nmanagement is a working definition for the purposes of this report. Any definition, to be an \napproved, agreed-upon term, must go through a formal review process by bodies such as the \nAuthorization and Attribute Services Committee (AASC) and NIST. As noted in the Preface of \nthis report, work needs to be done to formalize any terminology beyond that being proposed by \norganized committees such as the Identity, Credential, and Access Management (ICAM) \nSubcommittee and the AASC. \n2"
  },
  {
    "chunk_id": "A Report on the Privilege (Access) Management Workshop_first10_chunk_8",
    "filename": "A Report on the Privilege (Access) Management Workshop_first10.pdf",
    "page_num": 9,
    "text": "To have a clear notion of the meaning and scope of privilege management, we start by \nconsidering how access control works at a high level, as shown in Figure 1. \nFigure 1. High-Level View of Access Control \nFigure 2 depicts the real-time framework for access control in more detail, introducing \nterminology that is used in this report. \nFigure 2. High-Level View of Real-Time Access Control \n3"
  },
  {
    "chunk_id": "A Report on the Privilege (Access) Management Workshop_first10_chunk_9",
    "filename": "A Report on the Privilege (Access) Management Workshop_first10.pdf",
    "page_num": 10,
    "text": "In Figure 2, the Access Controller of Figure 1 is split into two parts—Policy Enforcement Point \nand Policy Decision Point—and Attribute and Policy Information replaces Access Control Data. \nThe meanings of the Policy Enforcement Point and Policy Decision Point (as described in Annex \nA: Authorization and Attributes Glossary) are as follows: \n Policy Decision Point (PDP): A system entity that makes authorization decisions for \nitself or for other system entities that request such decisions. \n Policy Enforcement Point (PEP): A system entity that requests and subsequently \nenforces authorization decisions. \n “Attribute and policy information” is being used in a very general sense and is intended to have \nthe same scope as access control data. Thus, it includes any form of information that can be used \nfor access control. For example, it includes traditional access control lists (ACLs.)  For an ACL, \nthe attribute might be a group or user name while the policy2 is implicit. In this context, “policy” \ndenotes digital policy—policy that can be processed by computer. The rationale for this scope of \nthe terminology is to enable discussion without having to deal with the details of the many forms \nof access control data, while at the same time distinguishing the main categories of access \ncontrol data—attributes and policies. \nA user is a person, process, or device. The term “user” is defined for the context of this report, as \nsuggested by RFC 4949, and shares connotations of meaning with the terms “subject,” “system \nentity,” and “system user” as defined in RFC 4949 and with the terms “subject” and “user” as \ndefined in CNSSI-4009. Attributes are distinguishable characteristics of users or resources, \nconditions defined by an authority, or aspects of the environment. Attributes might provide, \ndescribe, or be contact information, membership in communities of interest, roles within a \ncommunity of interest, sensitivity of data, permission bits, location of the user or the resource, \nproperties of the user session, conditions in the enterprise network or in the environment, \npriorities associated with individuals, status of resources, current bank account balance, and so \non. Policies are rules that specify how to use attributes to render an access decision. A policy \nmight specify that a user’s signature authority must equal or exceed signature-level-two in order \nfor the user to authorize a monetary account withdrawal. \nThe view of real-time access shown in Figure 2 does not reflect assurance mechanisms and other \nentities that might enter into the activity, except for the high-level reference to credentials. So, \nfor example, in a real system, the policy enforcement point might use a credential validation \nservice to convert authorization credentials3 into attributes that it then provides to the policy \ndecision point. As noted in the Preface, however, assurance is not being addressed in this \ndocument. \nAs suggested in Figure 2, the Access Request Provider uses identity and credential information \nthat is relevant to the context in which the request is being made. The level of trust associated \nwith the identity’s credentials can vary widely as can the form of the credentials, and the same \nholds true for attribute and policy information. In addition, the policy enforcement point may \n2 Policy: The process requesting access to the resource is allowed read access if the “read” permission bit is enabled. \n3 Authorization credential is an attribute assertion digitally signed by the issuer so that it can be cryptographically \nvalidated. An attribute assertion is a statement made by an attribute authority that an entity possesses a particular set \nof attributes. \n4"
  },
  {
    "chunk_id": "A Review of U.S. and European Security Evaluation Criteria_first10_chunk_0",
    "filename": "A Review of U.S. and European Security Evaluation Criteria_first10.pdf",
    "page_num": 1,
    "text": "NAT L INST. OF STAND & TECH\nR.I.C.\nA Review of U.S. and European\nSecurity Evaiuation\nCriteria\nNISTIR 4774\nChaiies\nR.\nDinkel\nU.S. DEPARTMENT OF COMMERCE\nTechnology Administration\nNational\nInstitute\nof Standards\nand Technology\nComputer Systems\nLaboratory\nComputer Security\nDivision\nGaithersburg, MD 20899\n-QC—\n100\n.056\n/M774\n1992\nU.S. DEPARTMENT OF COMMERCE\nRockwell\nA. Schnabel, Acting Secretary\nNATIONAL INSTITUTE OF STANDARDS\nAND TECHNOLOGY\nJohn W.\nLyons,\nDirector\nNIST"
  },
  {
    "chunk_id": "A Review of U.S. and European Security Evaluation Criteria_first10_chunk_1",
    "filename": "A Review of U.S. and European Security Evaluation Criteria_first10.pdf",
    "page_num": 2,
    "text": "i'i\n«("
  },
  {
    "chunk_id": "A Review of U.S. and European Security Evaluation Criteria_first10_chunk_2",
    "filename": "A Review of U.S. and European Security Evaluation Criteria_first10.pdf",
    "page_num": 3,
    "text": "NISTIR 4774\nA Review of U.S. and European\nSecurity Evaluation Criteria\nCharles\nR.\nDinkel\nU.S. DEPARTMENT OF COMMERCE\nTechnology Administration\nNational\nInstitute\nof Standards\nand Technology\nComputer Systems Laboratory\nComputer Security\nDivision\nGaithersburg, MD\n20899\nMarch 1992\nU.S. DEPARTMENT OF COMMERCE\nRockwell A Schnabel, Acting Secretary\nNATIONAL INSTITUTE OF STANDARDS\nAND TECHNOLOGY\nJohn W.\nLyons,\nDirector"
  },
  {
    "chunk_id": "A Review of U.S. and European Security Evaluation Criteria_first10_chunk_3",
    "filename": "A Review of U.S. and European Security Evaluation Criteria_first10.pdf",
    "page_num": 5,
    "text": "TABLE OF CONTENTS\nABSTRACT\n1\nKEY WORDS\n1\n1\n. 0\nINTRODUCTION\n1\n2\n. 0\nTRUSTED COMPUTER SYSTEM EVALUATION CRITERIA\n2\n3\n. 0\nTRUSTED NETWORK INTERPRETATION\n6\n4\n. 0\nTRUSTED DATABASE MANAGEMENT SYSTEM INTERPRETATION\n...\n8\n5.0\nIT SECURITY CRITERIA\n- CRITERIA FOR THE EVALUATION OF THE\nTRUSTWORTHINESS OF INFORMATION TECHNOLOGY\n(IT)\nSYSTEMS\n9\n6\n. 0\nDRAFT\nINFORMATION\nTECHNOLOGY\nSECURITY\nEVALUATION\nCRITERIA\n11\n7.0\nANALYSIS AND COMPARISON OF SECURITY CRITERIA SETS\n...\n13\n7.1\nU.S.\nSECURITY\nEVALUATION\nCRITERIA\n-\nORANGE\nBOOK,\nRED\nBOOK,\nTDI\n14\n7.2\nU.S.\nvs.\nEUROPEAN SECURITY EVALUATION CRITERIA\n16\n8.0\nTRUSTED SYSTEM TECHNOLOGY\n19\n9.0\nFUTURE\nU.S.\nEFFORTS\nIN\nTHE\nDEVELOPMENT\nOF\nSECURITY\nCRITERIA\n2 0\n10.0 CONCLUSIONS\n2 2\n11.0 EPILOGUE\n24\n12.0 REFERENCES\n2 4\n13.0 LIST OF ACRONYMS\n25\niii"
  },
  {
    "chunk_id": "A Review of U.S. and European Security Evaluation Criteria_first10_chunk_4",
    "filename": "A Review of U.S. and European Security Evaluation Criteria_first10.pdf",
    "page_num": 6,
    "text": "-\n''\n--:.\ni^*\nI\n.\n~\n|'.*'‘*^‘^.\n'\n~‘t\n•iV\n'\n'‘r^\n..\n’jp^\n^\n^\n-\n.\n’\n- '-rr\nij,\n.\n-'.\n'\n-\n•^’\n.V'\ny\n••\ncyrati\n•\n-\n-'\n'.\naif\n'.;\nn';'V'-'^“'i?*V> 'i-'*^^\nh.£H!S'Vf%:fft«?>S\n_\n.'\n,\n«r,.Trt-i''i\nVT'\n' &3j»»ife-\nV\nI'lO r-i;\nVTX\n**•\n-\n‘\nI\n.\n-\n,ui\nyi07‘-^ :-JS^‘J^-\nrq\n-; S^;/: <:\n:_vr-\ntygaovi^O'^' wt^'E^S-.\n^'SG^ai\n• G\n- yi^- ^' 4^%V\n‘^''•‘\n‘*y\n.\n-'\n.\n;\n-2%*\n,aE»\n'^1"
  },
  {
    "chunk_id": "A Review of U.S. and European Security Evaluation Criteria_first10_chunk_5",
    "filename": "A Review of U.S. and European Security Evaluation Criteria_first10.pdf",
    "page_num": 7,
    "text": "A Review of U.S. and European Security Evaluation Criteria\nCharles Dinkel\nNational\nInstitute\nof\nStandards and Technology\nComputer Systems Laboratory\nComputer Security Division\nABSTRACT\nSeveral\nUnited States\nand\nEuropean\ndocuments\ndescribing\ncriteria\nfor\nspecifying\nand evaluating\nthe\ntrust\nof\ncomputer products\nand\nsystems\nhave\nbeen\nwritten.\nThis\nreport\nreviews\nfive\nof\nthese\ndocuments\nand\ndiscusses the approach each one uses\nto provide criteria for specifying\nand evaluating the trust\nof computer products\nand systems.\nKEY WORDS\nComputers,\ncomputer\nsecurity,\nITSEC,\nOrange\nBook,\nRed\nBook,\nsecurity\nevaluation criteria,\ntrust,\ntrusted computer system\n1\n. 0\nINTRODUCTION\nUsers of systems need confidence in the security of the system they\nare\nusing.\nThey\nalso\nneed\na\nmetric\nto\ncompare\nthe\nsecurity\ncapabilities\nof\nproducts\nthey\nare\nthinking\nof\npurchasing.\nUsers\nhave several options\nfor dealing with this\nissue:\nthey could trust\nthe\nword\nof\nthe\nmanufacturers\nor\nvendors\nof\nthe\nsystems\nand\nproducts\nin question;\nthey could test the systems themselves;\nthey\ncould\nrely\non\nthe\nresults\nof\nsome\nimpartial\nassessment\nby\nan\nindependent body.\nEvaluating a system or product using the latter\napproach\nrequires\nobjective\nand well\ndefined\nsecurity\nevaluation\ncriteria\n.\nSeveral\nUnited\nStates\nand European\ndocuments\ndescribing\ncriteria\nfor\nspecifying\nand evaluating\nthe\ntrust\nof\ncomputer products\nand\nsystems have been written.\nAmong these are the\nfollowing:\n1.\nDepartment of Defense Trusted Computer System Evaluation\nCriteria\n(TCSEC)\n;\nDoD\n5200.28-STD;\nDecember\n1985;\nalso\nknown\nas\nthe Orange Book.^\n^The term \"Rainbow Series\" refers to the publications of the National\nComputer Security Center\n(NCSC)\n.\nEach book\nis printed with\na different\ncolor cover.\n1"
  },
  {
    "chunk_id": "A Review of U.S. and European Security Evaluation Criteria_first10_chunk_6",
    "filename": "A Review of U.S. and European Security Evaluation Criteria_first10.pdf",
    "page_num": 8,
    "text": "2.\nTrusted Network Interpretation\n(TNI);\nNCSC-TG-005;\nJuly\n1987;\nalso known\nas\nthe Red Book\n.\n3.\nTrusted Database Management System Interpretation\n(TDI)\n;\nNCSC-TG-021;\nAugust\n1990.\n4\n.\nIT\nSecurity\nCriteria\n-\nCriteria\nfor\nthe\nEvaluation\nof\nTrustworthiness of Information Technology\n(IT)\nSystems;\nGerman\nInformation\nSecurity Agency\n(GISA)\n;\n1st\nVersion\n1989.\n(Included\nin the\nITSEC;\nsee\n#5\nbelow)\n5\n.\nDraft\nInformation\nTechnology\nSecurity\nEvaluation\nCriteria,\n(ITSEC);\nHarmonized\nCriteria\nof\nFrance\nGermany\n- the Netherlands\n- the United Kingdom; May 1990.\nThis\nreport\nreviews\nand\nprovides\nNIST's\nviews\non\neach\nof\nthese\ndocuments and discusses the approach each uses\nto provide criteria\nfor\nspecifying\nand evaluating\nthe\ntrust\nof\ncomputer products\nand\nsystems\n.\n2.0\nTRUSTED COMPUTER SYSTEM EVALUATION CRITERIA\nThe\ntrusted\ncomputer\nsystem\nevaluation\ncriteria\ndefined\nin\nthe\nOrange\nBook\nclassify operating\nsystem.s\ninto\nfour broad divisions\nof security protection:\nA,B,C,D.\nThese divisions\nform a hierarchy\nwith\nthe highest\ndivision\n(A)\nreserved\nfor\nsystems\nproviding\nthe\nmost\ncomprehensive\nsecurity.\nEach\ndivision\nrepresents\na\nmajor\nimprovement\nin\nthe\noverall\nconfidence\nthat\ncan\nbe placed\nin\nthe\nsystem\nfor\nthe\nprotection\nof\nsensitive\ninformation.\nIt\nis\nimportant\nto\nnote\nthat\nthis\nguide\ndoes\nnot\napply\nto\nnetworks\nor\ncomponents.\nThe Orange Book defines\nsecurity levels\nas\nfollows:\n*\nDivision D;\nMinimal Protection\n-\nThis division contains\nonly one\nclass.\nIt\nis\nreserved\nfor\nthose\nsystems\nthat\nhave\nbeen\nevaluated\nbut\nthat\nfail\nto\nmeet\nthe\nrequirements\nfor\na higher evaluation class.\n*\nDivision\nC:\nDiscretionary Protection\n-\nClasses\nin\nthis\ndivision provide discretionary\n(need-to-know) protection\nand,\nthrough\nthe\ninclusion\nof\naudit\ncapabilities,\naccountability of subjects and the actions they initiate.\n*\nDivision\nB;\nMandatory\nProtection\n-\nThe\nconcept\nof\na\nsecurity\nrelevant\nor\nTrusted Computing Base\n(TCB)\nthat\npreserves\nthe\nintegrity\nof\nsensitivity\nlabels\nand uses\nthem to enforce\na\nset\nof mandatory access\ncontrol\nrules\n2"
  },
  {
    "chunk_id": "A Review of U.S. and European Security Evaluation Criteria_first10_chunk_7",
    "filename": "A Review of U.S. and European Security Evaluation Criteria_first10.pdf",
    "page_num": 9,
    "text": "is a major requirement of this division.\nSystems in this\ndivision\nmust\ncarry\nthe\nsensitivity\nlabels\nwith\nmajor\ndata structures in the system.\nThe system developer also\nprovides\nthe\nsecurity policy model\non which\nthe\nTCB\nis\nbased and furnishes a specification of the TCB.\nEvidence\nmust\nbe\nprovided\nto\ndemonstrate\nthat\nthe\nreference\nmonitor,\nan\naccess\ncontrol\nconcept\nthat\nrefers\nto\nan\nabstract\nmachine\nthat\nmediates\nall\naccesses\nto\nobjects\nby subjects,\nhas been implemented.\nThe security kernel,\nthe\nhardware,\nsoftware\nand\nfirmware\nelements\nof\na\nTCB,\nmust\nmediate\nall\naccesses\nto\ndata,\nbe\nprotected\nfrom\nmodification,\nand be verifiable\nas\ncorrect.\nDivision\nA:\nVerified\nProtection\n-\nThis\ndivision\nis\ncharacterized by the use\nof\nformal verification methods\nto assure\nthat\nthe mandatory and discretionary security\ncontrols employed\nin the system can effectively protect\nclassified\nor\nother\nsensitive\ninformation\nstored\nor\nprocessed\nby\nthe\nsystem.\nExtensive\ndocumentation\nis\nrequired\nto demonstrate\nthat\nthe TCB meets\nthe security\nrequirements\nin\nall\naspects\nof\ndesign,\ndevelopment\nand\nimplementation\n.\nThe\nfour divisions\nof criteria provide\na basis\nfor the evaluation\nof\neffectiveness\nof\nsecurity\ncontrols\nbuilt\ninto\ntrusted,\ncommercially\navailable\nautomatic\ndata\nprocessing\n(ADP)\nsystem\nproducts.\nThey are also applicable\nto the evaluation\nof existing\nsystems and to\nthe specification of\nsecurity requirements\nfor ADP\nsystem acquisition.\nWithin divisions\nC and\nB there are\na number\nof subdivisions known\nas\nclasses.\nThe\nclasses\nare\nalso\narranged\nin\nan\nhierarchical\norder.\nAssurance of correct and complete design and implementation\nof\ndivision\nC\nand\nlower\nclasses\nof\ndivision\nB\nis\ngained\nmostly\nthrough\ntesting\nof\nthe\nsecurity\nrelevant\nportions\nor\nTCB\nof\nthe\nsystems\n.\nHigher classes\nin division\nB and division A derive their security\nattributes more from their design and implementation structure than\nthe\nset\nof\nsecurity mechanisms\nthey\npossess.\nRigorous\nanalysis\nduring\nthe\ndesign\nstages\nprovides\nincreased\nassurance\nthat\nthe\nrequired security features are operative,\ncorrect and tamperproof.\nWithin each class,\nfour major sets of criteria\nfirst\nthree\nrepresent\nfeatures\nnecessary\nto\nobjectives of Security Policy,\nAccountability,\nfourth\nset.\nDocumentation,\ndescribes\nthe type\nare addressed.\nThe\nsatisfy\nthe\nbroad\nand Assurance.\nThe\nof written evidence\n3"
  },
  {
    "chunk_id": "A Review of U.S. and European Security Evaluation Criteria_first10_chunk_8",
    "filename": "A Review of U.S. and European Security Evaluation Criteria_first10.pdf",
    "page_num": 10,
    "text": "in\nthe\nform\nof\nuser\nguides,\nmanuals,\nand\nthe\ntest\nand\ndesign\ndocumentation required\nfor each class.\nThe criteria described in the Orange Book were developed with three\nobjectives\nin mind:\n1\n.\nTo\nprovide\na\nstandard\nto\nmanufacturers\nas\nto\nwhat\nsecurity\nfeatures\nto build\ninto\ntheir new and planned,\ncommercial products\nin order to provide widely available\nsystems that satisfy trust requirements\n(with particular\nemphasis\non\npreventing\nthe\ndisclosure\nof\ndata)\nfor\nsensitive applications.\n2.\nTo provide DoD organizations with a metric with which to\nevaluate\nthe\ndegree\nof\ntrust\nthat\ncan\nbe\nplaced\nin\ncomputer systems\nfor the secure processing of classified\nand other sensitive information.\n3.\nTo provide\na basis\nfor specifying security requirements\nin acquisition specifications.\nTwo types of requirements are delineated for secure processing:\n(1)\nspecific\nsecurity\nfeature\nrequirements\nand;\n(2)\nassurance\nrequirements.\nThe latter enable evaluation personnel\nto determine\nif\nthe required features\nare present\nand functioning as\nintended.\nThe\nOrange\nBook\ncriteria\nare\napplied\nto\nthe\nset\nof\nsecurity\nrelevant\nsoftware\nmodules\ncomprising\na\ntrusted\ncomputing\nbase\n(TCB)\n.\nFor upper end secure systems\n(B2-A1),\nthe TCB\nis\na subset\nof\nthe\nentire\noperating\nsystem;\nie.\nthe\nTCB\nis\nmade\nup\nof\nthe\nhardware\nand\nsoftware\nthat\nis\nsecurity\nrelevant\nand\nresponsible\nfor\nenforcing\na\nsecurity\npolicy.\nFor\nCl-Bl\nlevel\nsystems\nthe\noperating system interface and the TCB are one and the\nsame.\nIt\nis\nnot\nnecessairy\nto\napply\nthe\nOrange\nBook\ncriteria\nto\neach\nsystem module individually.\nThus\nsome modules\nof\na system may be\ncompletely\nuntrusted,\nwhile\nothers\nmay\nbe\nindividually\nevaluated\nto\na\nhigher\nor\nlower\nevaluation\nclass\nthan\nthe\ntrusted\nproduct\nconsidered as\na whole\nsystem.\nIn trusted products\nat\nthe high end of\nthe\nrange,\nthe strength of\nthe reference monitor\nis\nsuch that most\nof\nthe system modules\ncan\nbe\ncompletely\nuntrusted.\nAt\nthe\nB3\nlevel\nthe\nreference monitor\nconcept\nresults\nin\na\nsecurity\nkernel\nthat\ncontrols\nthe\naccess\nof\nusers\nto\ninformation.\nThe\nkernel\nmust\nmediate\nall\naccesses,\nbe\nprotected from modification,\nand be verifiable as\ncorrect.\n4"
  },
  {
    "chunk_id": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10_chunk_0",
    "filename": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10.pdf",
    "page_num": 1,
    "text": "NISTIR 8287 \n \nA Roadmap for Successful Regional \nAlliances and Multistakeholder \nPartnerships to Build the \nCybersecurity Workforce  \n \nDanielle Santos \nSanjay Goel \nJohn Costanzo \nDebbie Sagen \nPatty Buddelmeyer \n \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8287"
  },
  {
    "chunk_id": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10_chunk_1",
    "filename": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10.pdf",
    "page_num": 2,
    "text": "NISTIR 8287 \n \nA Roadmap for Successful Regional \nAlliances and Multistakeholder \nPartnerships to Build the \nCybersecurity Workforce \n \nDanielle Santos \nDebbie Sagen \n \nApplied Cybersecurity Division  \nPikes Peak Community College \n \nInformation Technology Laboratory \nColorado Springs, CO \n \n \nSanjay Goel \nPatty Buddelmeyer \n \nDept. of Info. Security & Digital Forensics \nSouthwestern Ohio Council \n \nUniversity at Albany, SUNY \nfor Higher Education \n \nAlbany, NY \nDayton, OH \n \n \nJohn Costanzo \n \nVirginia Cyber Alliance and HRCyber Alliance \n \nOld Dominion University \n \nNorfolk, VA \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8287 \n \nFebruary 2020 \n \n \n \nU.S. Department of Commerce \nWilbur L. Ross, Jr., Secretary \n \nNational Institute of Standards and Technology  \nWalter Copan, NIST Director and Under Secretary of Commerce for Standards and Technology"
  },
  {
    "chunk_id": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10_chunk_2",
    "filename": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10.pdf",
    "page_num": 3,
    "text": "National Institute of Standards and Technology Interagency or Internal Report 8287 \n32 pages (February 2020) \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8287 \nCertain commercial entities, equipment, or materials may be identified in this document in order to describe an \nexperimental procedure or concept adequately. Such identification is not intended to imply recommendation or \nendorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best \navailable for the purpose.  \nThere may be references in this publication to other publications currently under development by NIST in accordance \nwith its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, \nmay be used by federal agencies even before the completion of such companion publications. Thus, until each \npublication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For \nplanning and transition purposes, federal agencies may wish to closely follow the development of these new \npublications by NIST.   \nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback to \nNIST. Many NIST cybersecurity publications, other than the ones noted above, are available at \nhttps://csrc.nist.gov/publications. \nComments on this publication may be submitted to: \nNational Institute of Standards and Technology \nAttn: Applied Cybersecurity Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 2000) Gaithersburg, MD 20899-0003 \nEmail: nice.nist@nist.gov \nAll comments are subject to release under the Freedom of Information Act (FOIA)."
  },
  {
    "chunk_id": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10_chunk_3",
    "filename": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10.pdf",
    "page_num": 4,
    "text": "NISTIR 8287 \n \nPARTNERSHIPS TO BUILD THE \n \n \nCYBERSECURITY WORKFORCE  \nii \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8287 \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test \nmethods, reference data, proof of concept implementations, and technical analyses to advance the \ndevelopment and productive use of information technology. ITL’s responsibilities include the \ndevelopment of management, administrative, technical, and physical standards and guidelines for \nthe cost-effective security and privacy of other than national security-related information in federal \ninformation systems. \nAbstract \nIn September 2016, the National Initiative for Cybersecurity Education, led by the National \nInstitute of Standards and Technology in the U.S. Department of Commerce, awarded funding for \nfive pilot programs for Regional Alliances and Multistakeholder Partnerships to Stimulate \n(RAMPS) Cybersecurity Education and Workforce Development. The document that follows \nprovides a summary of the five pilot programs and outlines a roadmap for building similar \nprograms based on the best practices found and lessons learned.  \nThe roadmap for successful alliances to build the cybersecurity workforce requires four primary \ncomponents: 1) establishing program goals and metrics, 2) developing strategies and tactics, 3) \nmeasuring impact and results, and 4) sustaining the effort. Each section of the roadmap provides \nspecific examples and activities that the pilot programs found to be successful and repeatable in \nother efforts.  \nKeywords \nalliance; collaboration; cybersecurity; education; partnership; RAMPS; stakeholder; workforce."
  },
  {
    "chunk_id": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10_chunk_4",
    "filename": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10.pdf",
    "page_num": 5,
    "text": "NISTIR 8287 \n \nPARTNERSHIPS TO BUILD THE \n \n \nCYBERSECURITY WORKFORCE  \niii \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8287 \nSupplemental Content \nRAMPS Web Page with additional information on the five projects: \nhttps://www.nist.gov/itl/applied-cybersecurity/nice/regional-alliances-and-multistakeholder-\npartnerships-stimulate-ramps \n \nAcknowledgments \nThe authors would like to thank Cassie Barlow and Sean Creighton of the Southwestern Ohio \nCouncil for Higher Education and Tina Slankas of the Cyber Security Canyon for their \ncontributions to this document. The authors also thank those contributors who reviewed drafts of \nthis document: Marian Merritt, Rodney Petersen, Davina Pruitt-Mentle, Kevin Stine, Shannan \nWilliams, Donna Dodson, Jim St. Pierre, and Jeff Marron."
  },
  {
    "chunk_id": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10_chunk_5",
    "filename": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10.pdf",
    "page_num": 6,
    "text": "NISTIR 8287 \n \nPARTNERSHIPS TO BUILD THE \n \n \nCYBERSECURITY WORKFORCE  \niv \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8287 \n \nTable of Contents \n1 \nIntroduction ............................................................................................................ 1 \n1.1  Background ..................................................................................................... 1 \n1.2  Purpose and Scope of Document ................................................................... 3 \n2 \nKey Challenges and Strategies to Address Them ............................................... 5 \n2.1 Determining Workforce Needs .......................................................................... 5 \n2.2 Connecting Workforce Supply and Demand ..................................................... 5 \n2.3 Creating Synergy Amongst Existing Programs ................................................. 6 \n2.4 Retaining Talent ................................................................................................ 6 \n3 \nRoadmap ................................................................................................................. 8 \n3.1 Getting Started .................................................................................................. 8 \n3.2 Identifying Stakeholders .................................................................................... 9 \n3.3 Building Relationships ..................................................................................... 11 \n3.4 Establishing Program Goals ............................................................................ 11 \n3.4.1 Make a Realistic Plan ........................................................................... 12 \n3.4.2 Start the Documentation Processes ..................................................... 12 \n3.5 Developing Strategies and Tactics .................................................................. 12 \n3.5.1 Establish Mechanisms for Collaboration .............................................. 12 \n3.5.2 Host Events and Activities .................................................................... 12 \n3.6 Measuring Impact and Results ........................................................................ 14 \n3.7 Sustaining the Effort ........................................................................................ 17 \n4 \nConclusions and Other Considerations ............................................................. 18 \nReferences ................................................................................................................... 19 \n \nList of Appendices \nAppendix A— Acronyms ............................................................................................ 20 \nAppendix B— Best Practices and Example Activities ............................................. 21"
  },
  {
    "chunk_id": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10_chunk_6",
    "filename": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10.pdf",
    "page_num": 7,
    "text": "NISTIR 8287 \n \nPARTNERSHIPS TO BUILD THE \n \n \nCYBERSECURITY WORKFORCE  \n1 \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8287 \n \n1 \nIntroduction \nThe cybersecurity workforce shortfall is well documented. According to CyberSeek.org1, there \nwere 313 735 open cybersecurity-related positions from September 2017 through August 2018. \nThe 2017 Global Information Security Workforce Study states that 1.8 million more \ncybersecurity professionals will be needed to accommodate the predicted global shortfall by \n2022 [1]. The National Initiative for Cybersecurity Education (NICE) is addressing this critical \nissue by energizing and promoting a robust network and ecosystem of cybersecurity education, \ntraining, and workforce development. Supporting this mission, objective 3.3 of the NICE \nStrategic Plan emphasizes guiding career development and workforce planning by facilitating \nstate and regional consortia to identify cybersecurity pathways addressing local workforce needs \n[2].  \nBy fostering regional alliances: \n● workforce needs of local business and non-profit organizations are better aligned with the \nlearning objectives of education and training providers conforming to the NICE \nCybersecurity Workforce Framework,  \n● the pipeline of students pursuing cybersecurity careers is enlarged,  \n● more Americans are upskilled and moved into middle-class jobs in cybersecurity, and \n● local economic development to stimulate job growth is supported. \n \n1.1  Background  \nIn September 2016, NICE, led by the National Institute of Standards and Technology (NIST) in \nthe U.S. Department of Commerce, awarded funding for five pilot programs for Regional \nAlliances and Multistakeholder Partnerships to Stimulate (RAMPS) Cybersecurity Education \nand Workforce Development. These programs focused on bringing together employers who have \ncybersecurity skill shortages with educators to focus on developing a skilled workforce to meet \nindustry needs within local or regional economies. Awards were provided to universities, a \nconsortium, and a community college who pre-identified partnerships with at least one of each of \nthe following:  \n● K-12 school or Local Education Agency \n● Institution of higher education or college/university system \n● Local employer \n \nEach of the five programs had unique approaches to addressing the cybersecurity workforce \nneeds in their region. These efforts included building interest in and pathways to become a \ncybersecurity professional. Programs also focused on encouraging more employer engagement in \nlocal communities in order to influence education and training providers to develop job-driven \n \n1 CyberSeek.org is an online tool that provides detailed, actionable data about supply and demand in the U.S. cybersecurity job \nmarket."
  },
  {
    "chunk_id": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10_chunk_7",
    "filename": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10.pdf",
    "page_num": 8,
    "text": "NISTIR 8287 \n \nPARTNERSHIPS TO BUILD THE \n \n \nCYBERSECURITY WORKFORCE  \n2 \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8287 \ntraining that provides the skills that businesses need. Brief descriptions2 of each program are as \nfollows:  \nArizona Statewide Cyber Workforce Consortium \nState of Arizona Region; based in Phoenix, Arizona \nArizonaCyber.org  \nThe Arizona Statewide Cyber Workforce Consortium, led by Chicanos Por La Causa and Cyber \nSecurity Canyon, developed a unified approach to creating cybersecurity resources from a \nnumber of existing efforts. The partnership was used to provide a unity of vision, bridging \ntraditional and non-traditional educational pathways to create cybersecurity talent.  It also \nenabled the alignment of employers’ efforts through the Greater Phoenix Chamber of Commerce \nFoundation. Assistance was provided to help align job descriptions to the NICE Cybersecurity \nWorkforce Framework, review curriculum for greater relevance that adheres to program \nrequirements of the National Security Agency and Department of Homeland Security designated \ntwo-year National Centers of Academic Excellence programs, and create job experiences for \nstudents interested in learning more about the field of cybersecurity. The partnership connected \napplicants from traditional and nontraditional backgrounds to employers to provide skilled \nworkers for the growing number of cybersecurity positions in state government and the region’s \ncritical infrastructure segments, including manufacturing, health care, and the defense industrial \nbase. \nCincinnati-Dayton Cyber Corridor (Cin-Day Cyber)  \nSouthwestern Ohio Region, including Northern Kentucky; based in Dayton, Ohio \ncindaycyber.org  \nCin-Day Cyber RAMPS Final Report \nLed by the Southwestern Ohio Council for Higher Education (SOCHE), Cin-Day Cyber focused \non strengthening cybersecurity education to support the growth of a highly-skilled cybersecurity \nworkforce. Working closely with secondary schools, higher education, industry, and \ngovernment, Cin-Day Cyber researched local current and future job demand, developed and \ndelivered workshops to build career interest in cybersecurity, created and managed cyber-related \ninternships, and facilitated industry and higher education roundtables to develop partnerships that \naddressed the challenges of the cybersecurity workforce supply and demand in the Cincinnati-\nDayton region. \nCyber Prep Program \nSouthern Colorado Region; based in Colorado Springs, Colorado \nppcc.edu/cyberprep \nCyber Prep Program RAMPS Final Report \nThe Cyber Prep Program at Pikes Peak Community College established a formal, sustainable \n \n2 In-depth program outcomes can be found in each of the programs’ final reports. An overview of highlighted activities, sorted by \ntopic area, can be found in Appendix B."
  },
  {
    "chunk_id": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10_chunk_8",
    "filename": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10.pdf",
    "page_num": 9,
    "text": "NISTIR 8287 \n \nPARTNERSHIPS TO BUILD THE \n \n \nCYBERSECURITY WORKFORCE  \n3 \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8287 \npartnership between secondary-school districts, employers, and the college. The program built \ncybersecurity workforce development pathways to address local workforce needs and supported \nthe development of cybersecurity programs in area high schools and in the college’s area \nvocational program. The program created a summer cybersecurity work experience for high \nschool students and provided opportunities for registered apprenticeships to ensure a sustainable \ncybersecurity workforce for the future. \nIt is demonstrated through data collected from each of these programs that regional alliances \nhave a positive effect on educational and workforce pathways. Many examples can be provided \nto support this, including university and community college articulation agreements that helped \nsave students approximately 50 credit hours or 1.5 years of study, internship partnerships that \nhelped place over 100 students with local employers, and several workshops, trainings, career \nfairs, camps, and forums held. These activities build bridges between higher education and \nemployers looking for current and future employees in cybersecurity. \nHampton Roads Cybersecurity Education, Workforce and Economic Development \nAlliance \nSoutheast Virginia Region, including Hampton Roads and Tidewater Regions; based in Norfolk, \nVirginia \nsecuritybehavior.com/hrcyber \nHR Cyber RAMPS Final Report \nOld Dominion University’s Center for Cybersecurity Education and Research coordinated the \nHampton Roads Cybersecurity Education, Workforce and Economic Development Alliance \n(HRCyber). HRCyber is a partnership of educational institutions, government agencies, non-\nprofit organizations, and private employers focused on developing educational pathways from \nhigh school through community college to four-year institutions and continued professional \ndevelopment, providing a capable and fully trained cybersecurity workforce for the region. The \nspecific goal of supporting local economic development and job growth was achieved by \naligning regional educational and skills development offerings to the workforce practices and \nactivities of business and non-profit organizations within the Hampton Roads region. \nPartnership to Advance Cybersecurity Education and Training \nCapital District and New York City Region; based in Albany, New York \nalbany.edu/facets \nPartnership to Advance Cybersecurity Education and Training Final Report \nThe Partnership to Advance Cybersecurity Education and Training was led by the State \nUniversity of New York at Albany. New York’s Capital Region has a unique workforce \npotential, with its range of higher education institutions and Science, Technology, Engineering, \nand Math (STEM) graduates and a growing advanced technology sector. The project built clear \neducational paths and increased regional workforce capacity for a range of potential careers in \ncybersecurity based on industry needs. \n1.2  Purpose and Scope of Document \nAs a result of the outcomes and accomplishments of the RAMPS pilot programs, this document"
  },
  {
    "chunk_id": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10_chunk_9",
    "filename": "A Roadmap for Successful Regional Alliances and Multistakeholder Partnerships to Build the Cybersecurity Workforce_first10.pdf",
    "page_num": 10,
    "text": "NISTIR 8287 \n \nPARTNERSHIPS TO BUILD THE \n \n \nCYBERSECURITY WORKFORCE  \n4 \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8287 \nprovides a record of the methods and best practices used and presents a roadmap for \ncommunities interested in building similar regional alliances. It describes the essential \ncomponents of a successful alliance and provides examples of activities that can be \naccomplished by having such partnerships.  \nThis publication was created for those seeking guidance on how to organize and facilitate \nregional efforts to enhance cybersecurity education and workforce development. While this \ndocument explores some elements for consideration when forming alliances, it is not intended to \nbe a how-to guide that gives specific instructions. NIST believes that this is best left to the local \nor regional experts who are familiar with the needs of their specific community."
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_0",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 1,
    "text": "Special Publication 800-22 \nRevision 1a \nA Statistical Test Suite for \nRandom and Pseudorandom \nNumber Generators for \nCryptographic Applications \nAndrewRukhin,JuanSoto,JamesNechvatal,Miles \nSmid,ElaineBarker,Stefan Leigh,MarkLevenson,Mark \nVangel,DavidBanks,AlanHeckert,JamesDray,SanVo \nRevised:April2010 \nLawrenceEBasshamIII"
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_1",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 3,
    "text": "NIST Special Publication 800-22 \nRevision 1a \nA Statistical Test Suite for Random and \nPseudorandom Number Generators for \nCryptographic Applications \nAndrew Rukhin1, Juan Soto2, James \nNechvatal2, Miles Smid2, Elaine \nBarker2, Stefan Leigh1, Mark \nLevenson1, Mark Vangel1, David \nBanks1, Alan Heckert1, James Dray2 , \nSan Vo2 \nRevised: April 2010 \nLawrence E Bassham III2 \nC  O  M  P  U  T  E  R \nS  E  C  U  R  I  T  Y  \n1Statistical Engineering Division\n2Computer Security Division \nInformation Technology Laboratory \nNational Institute of Standards and Technology \nGaithersburg, MD 20899-8930 \nRevised: April 2010 \nU.S. Department of Commerce \nGary Locke, Secretary \nNational Institute of Standards and Technology \nPatrick Gallagher, Director"
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_2",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 4,
    "text": "A STATISTICAL TEST SUITE FOR RANDOM AND PSEUDORANDOM NUMBER GENERATORS FOR CRYPTOGRAPHIC APPLICATIONS \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and Technology \n(NIST) promotes the U.S. economy and public welfare by providing technical leadership for the nation’s \nmeasurement and standards infrastructure. ITL develops tests, test methods, reference data, proof of \nconcept implementations, and technical analysis to advance the development and productive use of \ninformation technology. ITL’s responsibilities include the development of technical, physical, \nadministrative, and management standards and guidelines for the cost-effective security and privacy of \nsensitive unclassified information in Federal computer systems. This Special Publication 800-series \nreports on ITL’s research, guidance, and outreach efforts in computer security and its collaborative \nactivities with industry, government, and academic organizations. \nNational Institute of Standards and Technology Special Publication 800-22 revision 1a  \nNatl. Inst. Stand. Technol. Spec. Publ. 800-22rev1a, 131 pages (April 2010)  \nCertain commercial entities, equipment, or materials may be identified in this \ndocument in order to describe an experimental procedure or concept adequately. \nSuch identification is not intended to imply recommendation or endorsement by the \nNational Institute of Standards and Technology, nor is it intended to imply that the \nentities, materials, or equipment are necessarily the best available for the purpose. \nii"
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_3",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 5,
    "text": "A STATISTICAL TEST SUITE FOR RANDOM AND PSEUDORANDOM NUMBER GENERATORS FOR CRYPTOGRAPHIC APPLICATIONS \nTable of Contents \nAbstract ....................................................................................................................................... 1  \n1. \nIntroduction to Random Number Testing.......................................................................1-1  \n1.1 \nGeneral Discussion.................................................................................................. 1-1  \n1.1.1 \nRandomness ................................................................................................1-1  \n1.1.2 \nUnpredictability.............................................................................................1-1  \n1.1.3 \nRandom Number Generators (RNGs)..........................................................1-2  \n1.1.4 \nPseudorandom Number Generators (PRNGs) ............................................1-2  \n1.1.5 \nTesting .........................................................................................................1-2  \n1.1.6 \nConsiderations for Randomness, Unpredictability and Testing ...................1-5  \n1.2 \nDefinitions ................................................................................................................ 1-5  \n1.3 \nAbbreviations ........................................................................................................... 1-8  \n1.4 \nMathematical Symbols............................................................................................. 1-8  \n2. \nRandom Number Generation Tests.................................................................................2-1  \n2.1 \nFrequency (Monobit) Test........................................................................................ 2-2  \n2.1.1 \nTest Purpose................................................................................................2-2  \n2.1.2 \nFunction Call ................................................................................................2-2  \n2.1.3 \nTest Statistic and Reference Distribution .....................................................2-2  \n2.1.4 \nTest Description ...........................................................................................2-2  \n2.1.5 \nDecision Rule (at the 1% Level)...................................................................2-3  \n2.1.6 \nConclusion and Interpretation of Results .....................................................2-3  \n2.1.7 \nInput Size Recommendation ........................................................................2-3  \n2.1.8 \nExample .......................................................................................................2-3  \n2.2 \nFrequency Test within a Block................................................................................. 2-4  \n2.2.1 \nTest Purpose................................................................................................2-4  \n2.2.2 \nFunction Call ................................................................................................2-4  \n2.2.3 \nTest Statistic and Reference Distribution .....................................................2-4  \n2.2.4 \nTest Description ...........................................................................................2-4  \n2.2.5 \nDecision Rule (at the 1% Level)...................................................................2-5  \n2.2.6 \nConclusion and Interpretation of Results .....................................................2-5  \n2.2.7 \nInput Size Recommendation ........................................................................2-5  \n2.2.8 \nExample .......................................................................................................2-5  \n2.3 \nRuns Test................................................................................................................. 2-5  \n2.3.1 \nTest Purpose................................................................................................2-5  \n2.3.2 \nFunction Call ................................................................................................2-6  \n2.3.3 \nTest Statistic and Reference Distribution .....................................................2-6  \n2.3.4 \nTest Description ...........................................................................................2-6  \n2.3.5 \nDecision Rule (at the 1% Level)...................................................................2-7  \n2.3.6 \nConclusion and Interpretation of Results .....................................................2-7  \n2.3.7 \nInput Size Recommendation ........................................................................2-7  \n2.3.8 \nExample .......................................................................................................2-7  \n2.4 \nTest for the Longest Run of Ones in a Block ........................................................... 2-7  \n2.4.1 \nTest Purpose................................................................................................2-7  \n2.4.2 \nFunction Call ................................................................................................2-8  \n2.4.3 \nTest Statistic and Reference Distribution ....................................................."
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_4",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 5,
    "text": ".....2-7  \n2.3.7 \nInput Size Recommendation ........................................................................2-7  \n2.3.8 \nExample .......................................................................................................2-7  \n2.4 \nTest for the Longest Run of Ones in a Block ........................................................... 2-7  \n2.4.1 \nTest Purpose................................................................................................2-7  \n2.4.2 \nFunction Call ................................................................................................2-8  \n2.4.3 \nTest Statistic and Reference Distribution .....................................................2-8  \n2.4.4 \nTest Description ...........................................................................................2-8  \n2.4.5 \nDecision Rule (at the 1% Level)...................................................................2-9  \niii"
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_5",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 6,
    "text": "A STATISTICAL TEST SUITE FOR RANDOM AND PSEUDORANDOM NUMBER GENERATORS FOR CRYPTOGRAPHIC APPLICATIONS \n2.4.6 \nConclusion and Interpretation of Results .....................................................2-9  \n2.4.7 \nInput Size Recommendation ........................................................................2-9  \n2.4.8 \nExample .......................................................................................................2-9  \n2.5 \nBinary Matrix Rank Test......................................................................................... 2-10  \n2.5.1 \nTest Purpose..............................................................................................2-10  \n2.5.2 \nFunction Call ..............................................................................................2-10  \n2.5.3 \nTest Statistic and Reference Distribution ...................................................2-10  \n2.5.4 \nTest Description .........................................................................................2-10  \n2.5.5 \nDecision Rule (at the 1% Level).................................................................2-11  \n2.5.6 \nConclusion and Interpretation of Results ...................................................2-12  \n2.5.7 \nInput Size Recommendation ......................................................................2-12  \n2.5.8 \nExample .....................................................................................................2-12  \n2.6 \nDiscrete Fourier Transform (Spectral) Test ........................................................... 2-12  \n2.6.1 \nTest Purpose..............................................................................................2-12  \n2.6.2 \nFunction Call ..............................................................................................2-12  \n2.6.3 \nTest Statistic and Reference Distribution ...................................................2-13  \n2.6.4 \nTest Description .........................................................................................2-13  \n2.6.5 \nDecision Rule (at the 1% Level).................................................................2-14  \n2.6.6 \nConclusion and Interpretation of Results ...................................................2-14  \n2.6.7 \nInput Size Recommendation ......................................................................2-14  \n2.6.8 \nExample .....................................................................................................2-14  \n2.7 \nNon-overlapping Template Matching Test............................................................. 2-14  \n2.7.1 \nTest Purpose..............................................................................................2-14  \n2.7.2 \nFunction Call ..............................................................................................2-14  \n2.7.3 \nTest Statistic and Reference Distribution ...................................................2-15  \n2.7.4 \nTest Description .........................................................................................2-15  \n2.7.5 \nDecision Rule (at the 1% Level).................................................................2-16  \n2.7.6 \nConclusion and Interpretation of Results ...................................................2-16  \n2.7.7 \nInput Size Recommendation ......................................................................2-16  \n2.7.8 \nExample .....................................................................................................2-16  \n2.8 \nOverlapping Template Matching Test.................................................................... 2-17  \n2.8.1 \nTest Purpose..............................................................................................2-17  \n2.8.2 \nFunction Call ..............................................................................................2-17  \n2.8.3 \nTest Statistic and Reference Distribution ...................................................2-17  \n2.8.4 \nTest Description .........................................................................................2-17  \n2.8.5 \nDecision Rule (at the 1% Level).................................................................2-19  \n2.8.6 \nConclusion and Interpretation of Results ...................................................2-19  \n2.8.7 \nInput Size Recommendation ......................................................................2-19  \n2.8.8 \nExample .....................................................................................................2-19  \n2.9 \nMaurer’s “Universal Statistical” Test ...................................................................... 2-20  \n2.9.1 \nTest Purpose..............................................................................................2-20  \n2.9.2 \nFunction Call ..............................................................................................2-20  \n2.9.3 \nTest Statistic and Reference Distribution ..................................................."
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_6",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 6,
    "text": "...................2-19  \n2.8.7 \nInput Size Recommendation ......................................................................2-19  \n2.8.8 \nExample .....................................................................................................2-19  \n2.9 \nMaurer’s “Universal Statistical” Test ...................................................................... 2-20  \n2.9.1 \nTest Purpose..............................................................................................2-20  \n2.9.2 \nFunction Call ..............................................................................................2-20  \n2.9.3 \nTest Statistic and Reference Distribution ...................................................2-20  \n2.9.4 \nTest Description .........................................................................................2-20  \n2.9.5 \nDecision Rule (at the 1% Level).................................................................2-23  \n2.9.6 \nConclusion and Interpretation of Results ...................................................2-23  \n2.9.7 \nInput Size Recommendation ......................................................................2-23  \n2.9.8 \nExample .....................................................................................................2-23  \n2.10 Linear Complexity Test .......................................................................................... 2-24  \n2.10.1 Test Purpose..............................................................................................2-24  \n2.10.2 Function Call ..............................................................................................2-24  \niv"
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_7",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 7,
    "text": "A STATISTICAL TEST SUITE FOR RANDOM AND PSEUDORANDOM NUMBER GENERATORS FOR CRYPTOGRAPHIC APPLICATIONS \n2.10.3 Test Statistic and Reference Distribution ...................................................2-24  \n2.10.4 Test Description .........................................................................................2-24  \n2.10.5 Decision Rule (at the 1% Level).................................................................2-26  \n2.10.6 Conclusion and Interpretation of Results ...................................................2-26  \n2.10.7 Input Size Recommendation ......................................................................2-26  \n2.10.8 Example .....................................................................................................2-26  \n2.11 Serial Test.............................................................................................................. 2-26  \n2.11.1 Test Purpose..............................................................................................2-26  \n2.11.2 Function Call ..............................................................................................2-26  \n2.11.3 Test Statistic and Reference Distribution ...................................................2-27  \n2.11.4 Test Description .........................................................................................2-27  \n2.11.5 Decision Rule (at the 1% Level).................................................................2-28  \n2.11.6 Conclusion and Interpretation of Results ...................................................2-28  \n2.11.7 Input Size Recommendation ......................................................................2-28  \n2.11.8 Example .....................................................................................................2-28  \n2.12 Approximate Entropy Test ..................................................................................... 2-29  \n2.12.1 Test Purpose..............................................................................................2-29  \n2.12.2 Function Call ..............................................................................................2-29  \n2.12.3 Test Statistic and Reference Distribution ...................................................2-29  \n2.12.4 Test Description .........................................................................................2-29  \n2.12.5 Decision Rule (at the 1% Level).................................................................2-30  \n2.12.6 Conclusion and Interpretation of Results ...................................................2-30  \n2.12.7 Input Size Recommendation ......................................................................2-30  \n2.12.8 Example .....................................................................................................2-31  \n2.13 Cumulative Sums (Cusum) Test............................................................................ 2-31  \n2.13.1 Test Purpose..............................................................................................2-31  \n2.13.2 Function Call ..............................................................................................2-31  \n2.13.3 Test Statistic and Reference Distribution ...................................................2-31  \n2.13.4 Test Description .........................................................................................2-31  \n2.13.5 Decision Rule (at the 1% Level).................................................................2-33  \n2.13.6 Conclusion and Interpretation of Results ...................................................2-33  \n2.13.7 Input Size Recommendation ......................................................................2-33  \n2.13.8 Example .....................................................................................................2-33  \n2.14 Random Excursions Test....................................................................................... 2-33  \n2.14.1 Test Purpose..............................................................................................2-33  \n2.14.2 Function Call ..............................................................................................2-34  \n2.14.3 Test Statistic and Reference Distribution ...................................................2-34  \n2.14.4 Test Description .........................................................................................2-34  \n2.14.5 Decision Rule (at the 1% Level).................................................................2-37  \n2.14.6 Conclusion and Interpretation of Results ...................................................2-37  \n2.14.7 Input Size Recommendation ......................................................................2-37  \n2.14.8 Example .....................................................................................................2-37  \n2.15 Random Excursions Variant Test .......................................................................... 2-38  \n2.15.1 Test Purpose..............................................................................................2-38  \n2.15.2 Function Call ..............................................................................................2-38  \n2.15.3 Test Stat"
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_8",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 7,
    "text": "2-37  \n2.14.6 Conclusion and Interpretation of Results ...................................................2-37  \n2.14.7 Input Size Recommendation ......................................................................2-37  \n2.14.8 Example .....................................................................................................2-37  \n2.15 Random Excursions Variant Test .......................................................................... 2-38  \n2.15.1 Test Purpose..............................................................................................2-38  \n2.15.2 Function Call ..............................................................................................2-38  \n2.15.3 Test Statistic and Reference Distribution ...................................................2-38  \n2.15.4 Test Description .........................................................................................2-38  \n2.15.5 Decision Rule (at the 1% Level).................................................................2-39  \n2.15.6 Conclusion and Interpretation of Results ...................................................2-39  \n2.15.7 Input Size Recommendation ......................................................................2-40  \n2.15.8 Example .....................................................................................................2-40  \nv"
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_9",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 8,
    "text": "A STATISTICAL TEST SUITE FOR RANDOM AND PSEUDORANDOM NUMBER GENERATORS FOR CRYPTOGRAPHIC APPLICATIONS \n3. \nTechnical Description of Tests........................................................................................3-1  \n3.1 \nFrequency (Monobits) Test ...................................................................................... 3-1  \n3.2 \nFrequency Test within a Block................................................................................. 3-1  \n3.3 \nRuns Test................................................................................................................. 3-2  \n3.4 \nTest for the Longest Run of Ones in a Block ........................................................... 3-3  \n3.5 \nBinary Matrix Rank Test........................................................................................... 3-5  \n3.6 \nDiscrete Fourier Transform (Specral) Test .............................................................. 3-6  \n3.7 \nNon-Overlapping Template Matching Test .............................................................. 3-9  \n3.8 \nOverlapping Template Matching Test.................................................................... 3-12  \n3.9 \nMaurer’s “Universal Statistical” Test ...................................................................... 3-13  \n3.10 Linear Complexity Test .......................................................................................... 3-15  \n3.11 Serial Test.............................................................................................................. 3-18  \n3.12 Approximate Entropy Test ..................................................................................... 3-19  \n3.13 Cumulative Sums (Cusum) Test............................................................................ 3-21  \n3.14 Random Excursions Test....................................................................................... 3-22  \n3.15 Random Excursions Variant Test .......................................................................... 3-24  \n4. \nTesting Strategy and Result Interpretation ....................................................................4-1  \n4.1 \nStrategies for the Statistical Analysis of an RNG..................................................... 4-1  \n4.2 \nThe Interpretation of Empirical Results.................................................................... 4-2  \n4.2.1 \nProportion of Sequences Passing a Test.....................................................4-2  \n4.2.2 \nUniform Distribution of P-values...................................................................4-3  \n4.3 \nGeneral Recommendations and Guidelines ............................................................ 4-3  \n4.4 \nApplication of Multiple Tests .................................................................................... 4-6  \n5. \nUser’s Guide......................................................................................................................5-1  \n5.1 \nAbout the Package................................................................................................... 5-1  \n5.2 \nSystem Requirements.............................................................................................. 5-1  \n5.3 \nHow to Get Started .................................................................................................. 5-2  \n5.4 \nData Input and Output of Empirical Results............................................................. 5-3  \n5.4.1 \nData Input.....................................................................................................5-3  \n5.4.2 \nOutput of Empirical Results..........................................................................5-3  \n5.4.3 \nTest Data Files .............................................................................................5-3  \n5.5 \nProgram Layout ....................................................................................................... 5-3  \n5.5.1 \nGeneral Program..........................................................................................5-3  \n5.5.2 \nGlobal Parameters .......................................................................................5-4  \n5.5.3 \nMathematical Software.................................................................................5-4  \n5.6 \nRunning the Test Code............................................................................................ 5-5  \n5.7 \nInterpretation of Results........................................................................................... 5-7  \nList of Appendices \nAppendix A— Source Code ................................................................................................... A-1  \nA.1 \nHierarchical Directory Structure...............................................................................A-1  \nA.2 \nConfiguration Information ........................................................................................A-3  \nAppendix B— Empirical Results for Sample Data............................................................... B-1  \nvi"
  },
  {
    "chunk_id": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10_chunk_10",
    "filename": "A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications_first10.pdf",
    "page_num": 9,
    "text": "A STATISTICAL TEST SUITE FOR RANDOM AND PSEUDORANDOM NUMBER GENERATORS FOR CRYPTOGRAPHIC APPLICATIONS \nAppendix C— Extending the Test Suite ............................................................................... C-1  \nC.1 Incorporating Additional Statistical Tests................................................................ C-1  \nC.2 Incorporating Additional PRNGs............................................................................. C-2  \nAppendix D— Description of Reference Pseudorandom Number Generators................. D-1  \nD.1 Linear Congruential Generator (LCG) .................................................................... D-1  \nD.2 Quadratic Congruential Generator I (QCG-I).......................................................... D-1  \nD.3 Quadratic Congruential Generator II (QCG-II)........................................................ D-1  \nD.4 Cubic Congruential Generator II (CCG).................................................................. D-2  \nD.5 Exclusive OR Generator (XORG) ........................................................................... D-2  \nD.6 Modular Exponentiation Generator (MODEXPG) ................................................... D-2  \nD.7 Secure Hash Generator (G-SHA1) ......................................................................... D-3  \nD.8 Blum-Blum-Shub (BBSG) ....................................................................................... D-3  \nD.9 Micali-Schnorr Generator (MSG) ............................................................................ D-4  \nD.10 Test Results............................................................................................................ D-5  \nAppendix E— Numerical Algorithm Issues...........................................................................E-1  \nAppendix F— Supporting Software .......................................................................................F-1  \nF.1 \nRank Computation of Binary Matrices .....................................................................F-1  \nF.2 \nConstruction of Aperiodic Templates.......................................................................F-4  \nF.3 \nGeneration of the Binary Expansion of Irrational Numbers .....................................F-7  \nAppendix G— References...................................................................................................... G-1  \nvii"
  },
  {
    "chunk_id": "A Study of OSI Key Management_first10_chunk_0",
    "filename": "A Study of OSI Key Management_first10.pdf",
    "page_num": 1,
    "text": "Roberto Zamparo\nU.S. DEPARTMENT OF COMMERCE\nTechnology Administration\nNational\nInstitute\nof Standards\nand Technology\nComputer Systems\nLaboratory\nComputer Security\nDivision\nGaithersburg, MD 20899\nNIST"
  },
  {
    "chunk_id": "A Study of OSI Key Management_first10_chunk_1",
    "filename": "A Study of OSI Key Management_first10.pdf",
    "page_num": 3,
    "text": "/\nA Study of OSI Key\nManagement\nRoberto Zamparo\nU.S. DEPARTMENT OF COMMERCE\nTechnology Administration\nNational\nInstitute\nof Standards\nand Technology\nComputer Systems\nLaboratory\nComputer Security\nDivision\nGaithersburg, MD 20899\nNovember 1992\nU.S. DEPARTMENT OF COMMERCE\nBarbara Hackman\nFranklin, Secretary\nTECHNOLOGY ADMINISTRATION\nRobert M.\nWhite, Under Secretary\nfor Technology\nNATIONAL INSTITUTE OF STANDARDS\nAND TECHNOLOGY\nJohn W.\nLyons,\nDirector"
  },
  {
    "chunk_id": "A Study of OSI Key Management_first10_chunk_2",
    "filename": "A Study of OSI Key Management_first10.pdf",
    "page_num": 5,
    "text": "TABLE OF CONTENTS\nPREFACE\nXI\nACKNOWLEDGMENTS\nXIII\n1\nINTRODUCTION\n1\n1.1 BACKGROUND\n1\n1.2 PLACE OF KEY MANAGEMENT IN THE OSI ARCHITECTURE\n3\n1.3 KEY MANAGEMENT ACTIVITIES\n3\n1.3.1 Secure Data Network System (SDNS)\n.4\n1.3.2 ANSI\nX9.17\n4\n1.3.3 ANSI\nX9.28\n4\n1.3.4 ISO/CD 11166\n.4\n1.3.5 Standards for Interoperable LAN Security (SILS)\n5\n1.3.6 ISO SC\n27\n5\n1.3.7 Network Layer Security Protocol (NLSP)\n5\n2 CRITERIA FOR OSI KEY MANAGEMENT\n7\n2.1 GENERAL CRITERIA FOR OSI KEY MANAGEMENT\n7\n2.1.1\nAlgorithm\nindependence\n7\n2.1.2 Operations across security domains\n7\n2.1.3 Support of a variety of security protocols\n7\n2.1.4 Support across a range of networldng environments\n8\n2.2 GENERAL REQUIREMENTS\n8\n3 KEY MANAGEMENT MODEL\n9\n3.1 TOP LEVEL VIEW\n9\n3.2 DECOMPOSITION OF THE KEY MANAGEMENT SERVICE\n9\n3.3 DECOMPOSITION OF THE KEY CENTER\n.10\n4 PHASES IN TRAFFIC ENCRYPTION KEY MANAGEMENT\n13\n5 ISSUES IN KEY MANAGEMENT\n15\n5.1 HOLDER OF THE CERTIFICATE\n15\n5.2 ORGANIZATION OF THE CERTMCATION AUTHORITIES\n16\n5.2.1 Organization of certification authorities in SDNS\n16\n5.2.2 Organization of certification authorities in the Directory standards\n16\n5.2.3 Organization of certification authorities in RFC 1114\n21\n5.2.4 Section summary\n29\n5.3 ORGANIZATION OF KEY DISTRIBUTION AND KEY TRANSLATION CENTERS ...29\n5.3.1 Organization of Key Distribution and Key Translation Centers in X9.17\n30\n5.3.2 Organization of Key Distribution and Key Translation Centers in X9.28\n34\n5.3.2. 1 X9.28 key exchange transaction\n37\n5.3.2.2 Diversion from the key management model\n39\n5.3.3 Section summary\n40\n5.4 PASSIVE OR ACTIVE CERTIHCATION AUTHORITY\n40\n5.5 GENERATION OF THE PRIVATE AND PUBLIC KEY PAIR\n41\n5.5.1 Generation of public key pair in SDNS\n41\n5.5.2\nGeneration of public key pair in ISO/CD 11166\n.41\n5.5.3 Generation of public key pair in the Directory standards\n.42\n5.5.4\nGeneration of public key pair in RFC 1114\n,...42\nIII"
  },
  {
    "chunk_id": "A Study of OSI Key Management_first10_chunk_3",
    "filename": "A Study of OSI Key Management_first10.pdf",
    "page_num": 6,
    "text": "TABLE OF CONTENTS (continued)\n5.6 REKEY HANDLING\n42\n5.6.1 Rekey handling in an asymmetric form of key management\n42\n5.6.1. 1 Rekey handling in SDNS\n48\n5.6. 1.2 Rekey handling in the Directory standards\n49\n5.6. 1.2.1 Rekeying as part of the Directory standards\n50\n5.6. 1.2.2 Rekeying performed outside the Directory\n52\n5.6. 1.3 Rekey handling in ISO/CD\n1 1 166\n53\n5.6. 1.4\nSection summary\n54\n5.6.2 Rekey handling in a symmetric form of key management\n54\n5.6.2. 1 Rekey handling in X9.17\n54\n5.6.2.2 Rekey handling in X9.28\n55\n5.7 REVOCATION LIST HANDLING\n55\n5.7.1\nRevocation\nlist handling\nin SDNS\n56\n5.7.2 Revocation list handling in the Directory standards\n56\n5.7.3 Revocation list handling in RFC 1114\n57\n5.7.4 Revocation list handling in ISO/CD 11166\n58\n5.7.5 Section summary\n58\n5.8 CONVERSION PROBLEMS\n59\n5.9 PROTECTION OF GROUP AND BROADCAST KEYS\n59\n5.10 ALGORITHM INDEPENDENCE\n61\n5.10.1 Algorithm independence by using Object Identifiers\n61\n5.10.2 Algorithm independence by altering presentation context\n62\n5.10.3 Algorithm independence\nin SDNS\n64\n5.10.4\nSection\nsummary\n64\n5.11 ASN.l ABSTRACT VERSUS TRANSFER SYNTAX PROBLEMS\n64\n5.12 TRIGGERING OF KEY MANAGER\n65\n5.13 ESTABLISHMENT OF SECURITY SERVICES\n68\n5.14 KEY MANAGEMENT AS PART OF THE SECURITY PROTOCOL\n73\n5.15 KEY MANAGEMENT AS PART OF A LAYER PROTOCOL\n77\n5.16 ADDING A NEW COMPONENT TO THE NETWORK\n78\n5.16.1 Adding a new component in SDNS\n78\n5.16.2\nPublic\nkey\nregistration\n78\n5.17 COMMON KEY MANAGEMENT PROTOCOL\n80\n5.18 THE CONCEPT OF SECURITY ASSOCIATION\n80\n5.19 SUBSTITUTION OF TRAFFIC ENCRYPTION KEYS\n83\n5.20 KNOWN PLAIN TEXT ATTACK\n85\n5.21 ADDRESSING PROBLEMS\n86\n5.21.1 Addressing problems in SDNS\n86\n5.21.2 Addressing problems\nin SILS\n88\n5.21.3 Can key management entities be trusted?\n91\n5.22 ASPECTS OF KEY MANAGEMENT OUTSIDE OSI\n92\n5.22.1 Key Archiving\n92\n5.22.2 Key Generation\n92\n5.22.3 Key Destruction\n92\n5.22.4\nKey\nStorage\n93\n5.22.5 Compromised Key Recovery\n93\n6 REALIZATION OF THE MODEL\n9 5\n7 GENERALITY OF THE KEY MANAGEMENT MODEL\n9 9\n7.1 IMPROVEMENTS OF THE MODEL\n99\n8 LEVEL OF CENTRALIZATION\n101\nIV"
  },
  {
    "chunk_id": "A Study of OSI Key Management_first10_chunk_4",
    "filename": "A Study of OSI Key Management_first10.pdf",
    "page_num": 7,
    "text": "TABLE OF CONTENTS (continued)\n9 KEY MANAGEMENT PROTOCOL SPECIFICATIONS\n103\n9.1 TYPES OF PROTOCOLS\n103\n9.2 ASN.l MODULE DISPOSITION\n104\n9.3 SECURITY REGISTER\n105\n9.3.1 Registration of key exchange algorithms/methods\n106\n9.3. 1.1\nApproach\none\n108\n9.3. 1.2 Approach two\n110\n9.3.2 Registration of rekeying methods\n112\n9.4 PROTOCOL OVERVIEW\n115\n9.5 INTEGRITY PROCEDURE\n117\n9.6 ENCRYPTION PROCEDURE\n118\n9.7 KEY EXCHANGE\n118\n9.8 KMSA TO KMSA PROTOCOL\n120\n9.8.1 Algorithm choice\n120\n9. 8. 1.1 A\npriori agreements\n121\n9.8. 1.2 Need to initialize cryptographic variables\n122\n9.8. 1.3 Algorithm negotiation\n123\n9.8.2 Update of traffic encryption keys\n125\n9.8.3 Support of different kinds of security protocols\n125\n9.8.4\nSecurity association\nidentification\n127\n9.8.5 Separation of confidentiality and integrity keys\n127\n9.9 KMSA TO KCA PROTOCOL\n127\n9.9.1 Algorithm choice\n128\n9.9.2 Rekeying\n128\n9.10 KCA TO KCA PROTOCOL\n129\n9.11 SECURITY PROTOCOL DEFINITIONS\n129\n9.11.1\nTLSP definitions\n130\n9.12 ERROR HANDLING\n131\n9.13 BROADCAST AND GROUP KEYS\n131\n9.14 FINDING THE REMOTE ADDRESS DYNAMICALLY\n131\n9.15 TIMERS\n131\n9.16 POSSIBILITY TO ENHANCE SECURITY\n131\n9.17 GENERALITY OF THE KEY MANAGEMENT PROTOCOL\n132\n10 COMPARISONS APPLICATION LAYER VERSUS SECURITY PROTOCOL LAYER.. 135\n10.1 APPLICATION LAYER ADVANTAGES\n135\n10.2 SECURITY PROTOCOL ADVANTAGES\n135\n11\nAREAS NOT COVERED\n137\n11.1 SYMMETRIC FORM OF KEY MANAGEMENT\n137\n11.2 REKEY HANDLING\n...137\n11.3 DISTRIBUTED ASPECTS\n137\n11.4 ACCESS CONTROL\n137\n11.5 ORANGE BOOK ASPECTS\n138\n11.6 ZERO KNOWLEDGE TECHNIQUES\n138\n11.7 SECURITY MANAGEMENT\n138\n11.8 KERBEROS\n138\nANNEX A KEY MANAGEMENT APPROACHES\n139\nA1 SYMMETRIC FORM OF KEY MANAGEMENT\n139\nA2 ASYMMETRIC FORM OF KEY MANAGEMENT\n144\nA3 COMPARISONS\n.147\nV"
  },
  {
    "chunk_id": "A Study of OSI Key Management_first10_chunk_5",
    "filename": "A Study of OSI Key Management_first10.pdf",
    "page_num": 8,
    "text": "TABLE OF CONTENTS (continued)\nANNEX B PROTOCOL AND SERVICE DEFINITIONS\n149\nB1 PROTOCOL DEFINITIONS\n149\nBl.l SECURITY DEFINITIONS MODULE\n149\nBL2 SECURITY REGISTER MODULES\n151\nBL2.1 Confidentiality Algorithms\n152\nB 1.2.1. 1 Symmetric algorithms\n153\nB 1.2. 1.2 Asymmetric algorithms\n154\nB 1.2.2 Key Exchange Methods\n155\nB 1.2.3\nIntegrity Mechanisms\n159\nB 1.2.4 Security Levels\n160\nB 1.2.5 Security Labels\n161\nB 1.2.6\nSignature\nAlgorithms\n162\nB 1.2.7\nRekeying\nMethods\n163\nB1.3 KEY MANAGEMENT PROTOCOL MODULES\n165\nBl.3.1 KMSA TO KMSA\n167\nBl.3.1.1 ASN.l declarations\n167\nBl.3.1.2 Protocol Machine\n170\nB 1.3.2 KMSA TO KCA\n172\nBl.3.2.1\nASN.l\ndefinitions\n172\nBl.3.2.2 Protocol Machine\n175\nBl.3.3 KCA TO KCA\n177\nB1.4 MAPPING OF PDUs\n178\nBl.4.1 KMSA TO KMSA\n178\nB 1.4.2 KMSA TO KCA\n179\nB1.4.3KCA TO KCA\n181\nB1.5 SECURITY PROTOCOL MODULE\n182\nBl.5.1\nTLSP\n182\nBl.5.2 NLSP\n183\nBl.5.3 SDE\n184\nB2 SERVICE SPECmCATIONS\n185\nB2.1 KMSA TO KMSA SERVICE SPECIFICATION\n185\nB2.1.1 Available service primitives\n185\nB2. 1.1.1 Key M^agement Initialization service primitive\n185\nB2.1.1.2 New Key service primitive\n187\nB2.1.1.3 Security Service service primitive\n188\nB2.1.1.4 Key Uj^ie service primitive\n189\nB2.1.1.5 KM-Release service primitive\n189\nB2.1.1.6 KM-Abort service primitive\n189\nB2.1.2\nSecurity\nprotocol parameters\n190\nB2.1.2.1 TLSP parameters\n190\nB2.2 KMSA TO KCA\nservice primitives\n192\nB2.2.1 Available service primitives\n192\nB2.2.1.1 Key M^agement Initialization service primitive\n192\nB2.2.1.2 New Key service primitive\n192\nB2.2.1.3 Rekey service primitive\n192\nB2.2.1.4 Rekey Delivery service primitive\n193\nB.2.2.1.5 KM-Release service primitive\n193\nB.2.2.1.6 KM-Abort service primitive\n193\nB2.3 KCA TO KCA service primitives\n194\nVI"
  },
  {
    "chunk_id": "A Study of OSI Key Management_first10_chunk_6",
    "filename": "A Study of OSI Key Management_first10.pdf",
    "page_num": 9,
    "text": "TABLE OF CONTENTS (continued)\nB2.4 GENERIC AND ALGORITHM DEPENDENT PARAMETERS\n195\nB2.4.1 Key Exchange Methods\n195\nB2.4.1.1 Diffie-Hellman\n195\nB2.4.1.2 RSA\n196\nB2.4.2 Rekey Methods\n197\nB2.4.2.1 rekMethl\n197\nB2.4.3 Diagnostics\n197\nB2.5 ALTERNATIVE SERVICE SPECIHCATION\n199\nANNEX\nC SUGGESTED READING\n201\nANNEX D\nASN.l EXTENSIONS\n203\nGLOSSARY\n205\nOSI TERMS AND ABBREVIATIONS\n205\nSECURITY GLOSSARY\n207\nANSI X9 SECURITY TERMS AND ABBREVIATIONS\n209\nREFERENCES\n213\nVII"
  },
  {
    "chunk_id": "A Study of OSI Key Management_first10_chunk_7",
    "filename": "A Study of OSI Key Management_first10.pdf",
    "page_num": 10,
    "text": "10 HJtlAT\n'\n•*\n'\n•»\ni'-\n'•'\n,.:\nw.\n...\n^ 'i' •-.*>-•; <5?.' Utl\n;\n. l-Jd\n.-..,,4*5^\n.\n».\n,\n. )u\nt kSfl\n.\n. ii'i?\n-\nl-.L.f'.fvS.\n,\nV\n, !?\n..\n,.<.*r.k.\n.\n?^b»v.trt|tstCI Lf- I'lK\n[^4\ny>oxv^\n?: n\\f'MZ ivr;TAvmrJAfi4k8\n\\ ) m /knsL.. Q3i'.a3£iOLr».: *7\na\n?.v:ci^i:* .ri'-jS*'\nyawtA\n*\n*\n'\n.\n*.\n'\n.\n‘\n‘\n.\n—\nAi520JD\nf n\ni-<)\n1'.^\n1/^'\n'H'f*\nrjv"
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_0",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 1,
    "text": "A111D3\nDflTflDT\nNATL INST OF STANDARDS & TECH R.I.C.\n'\n:E 8t TECHNOLOGY:\nA1 11 03089809\nNutt, Gary J/A survey of remote monltorl\nQC100 .U57 NO.500-, 42, 1979 C.I NBS-PUB\nA SURVEY OF\nREMOTE MONITORING\n500-^2\n19\nNBS Special Publication 500-42\nU.S. DEPARTMENT OF COMMERCE\nNational Bureau of Standards"
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_1",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 2,
    "text": "NATIONAL BUREAU OF STANDARDS\nThe National Bureau of Standards' was established by an act of Congress March 3, 1901. The\nBureau's overall goal\nis to strengthen and advance the Nation's science and technology and\nfacilitate\ntheir\neffective application\nfor public\nbenefit. To\nthis end,\nthe Bureau conducts\nresearch and provides; (1) a basis for the Nation's physical measurement system, (2) scientific\nand technological services for industry and government,\n(3) a technical basis for equity in\ntrade, and\n(4) technical\nservices to promote public safety. The Bureau's technical work\nis\nperformed by the National Measurement Laboratory, the National Engineering Laboratory,\nand the Institute for Computer Sciences and Technology.\nTHE NATIONAL MEASUREMENT LABORATORY\nprovides\nthe\nnational\nsystem\nof\nphysical and chemical and materials measurement; coordinates the system with measurement\nsystems of other nations and furnishes\nessential\nservices leading to accurate and uniform\nphysical and chemical measurement throughout the Nation's scientific community, industry,\nand commerce; conducts materials research leading to improved methods of measurement,\nstandards, and data on the properties of materials needed by industry, commerce, educational\ninstitutions, and Government; provides advisory and research services to other Government\nAgencies; develops, produces, and distributes Standard Reference Materials; and provides\ncalibration services. The Laboratory consists of the following centers:\nAbsolute Physical Quantities^ — Radiation Research — Thermodynamics and\nMolecular Science — Analytical Chemistry — Materials Science.\nTHE NATIONAL ENGINEERING LABORATORY\nprovides technology and\ntechnical\nservices to users\nin\nthe public and private sectors to address national needs and to solve\nnational problems in the public interest; conducts research in engineering and applied science\nin support of objectives in these efforts; builds and maintains competence in the necessary\ndisciplines required to carry out this research and technical service; develops engineering data\nand\nmeasurement\ncapabilities;\nprovides\nengineering\nmeasurement\ntraceability\nservices;\ndevelops test methods and proposes engineering standards and code changes; develops and\nproposes new\nengineering\npractices; and develops and improves mechanisms\nto\ntransfer\nresults of its research to the utlimate user. The Laboratory consists of the following centers:\nApplied Mathematics — Electronics and Electrical Engineering^ — Mechanical\nEngineering and Process Technology^ — Building Technology — Fire Research —\nConsumer Product Technology — Field Methods.\nTHE\nINSTITUTE FOR COMPUTER SCIENCES AND TECHNOLOGY\nconducts\nresearch and provides scientific and technical services to aid Federal Agencies in the selection,\nacquisition,\napplication,\nand\nuse\nof computer\ntechnology\nto improve\neffectiveness and\neconomy in Government operations in accordance with Public Law 89-306 (40 U.S.C. 759),\nrelevant Executive Orders, and other\ndirectives;\ncarries oS4\nthis mission by managing the\nFederal\nInformation\nProcessing\nStandards Program,\ndeveloping\nFederal ADP standards\nguidelines, and managing Federal participation in ADP voluntary standardization activities;\nprovides scientific and technological advisory services and assistance to Federal Agencies; and\nprovides the technical foundation for computer-related policies of the Federal Government.\nThe Institute consists of the following divisions:\nSystems and Software — Computer Systems Engineering — Information Technology.\n'Headquarters and Laboratories at Gaithersburg, Maryland, unless otherwise noted;\nmailing address Washington, D.C. 20234.\n^Some divisions within the center are located at Boulder, Colorado, 80303.\nThe National Bureau of Standards was reorganized, effective April 9, 1978."
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_2",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 3,
    "text": "O0l'\n-Arc\nCOMPUTER SCIENCE & TECHNOLOGY:\nA Survey of Remote Monitoring\n^^^^\nGary J. Nutt, Ph.D.\nConsultant\nInstitute for Computer Sciences and Technology\nNational Bureau of Standards\nWashington, D.C.\n20234\nU.S. DEPARTMENT OF COMMERCE, Juanita M. Kreps, Secretary\nJordan J. Baruch, Assistant Secretary for Science and Technology\nNATIONAL BUREAU OF STANDARDS, Ernest Ambler, Director\nIssued January 1979"
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_3",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 4,
    "text": "Reports on Computer Science and Technology\nThe National Bureau of Standards has a special responsibility within the Federal\nGovernment for computer science and technology\nactivities. The programs of the\nNBS Institute for Computer Sciences and Technology are designed to provide ADP\nstandards, guidelines, and technical advisory services to improve the effectiveness of\ncomputer utilization in the Federal sector, and to perform appropriate research and\ndevelopment efforts as foundation for such activities and programs. This publication\nseries will report these NBS efforts to the Federal computer community as well as to\ninterested specialists in the academic and private sectors. Those wishing to receive\nnotices of publications in this series should complete and return the form at the end\nof this publication.\nNational Bureau of Standards Special Publication 500-42\nNat. Bur. Stand. (U.S.), Spec. Publ. 500-42, 34 pages (Jan. 1979)\nCODEN: XNBSAV\nLibrary of Congress Cataloging in Publication Data\nNutt, Gary J\nA survey of remote monitoring.\n(Computer science & technology) (National Bureau of Standards\nspecial publication\n; 500-42)\nSupt. of Docs, no.: C13.10:500^2\n1. Electronic digital computers—Evaluation.\nI. Title.\nII. Series.\nIII.\nSeries: United States. National Bureau of Standards. Special publica-\ntion\n; 500^2.\nQCl 00. U57 no. 500^2 [QA76.9.E94] 602M s [62 1\n. 38] 78-263 1\n3\nU.S. GOVERNMENT PRINTING OFFICE\n'\nWASHINGTON:\n1978\ni\nFor sale by the Superintendent of Documents, U.S. Government Printing OflBce, Washington, D.C. 20402\nStock No. 003-003-02013-3 Price $1.50\n(Add 25\npercent\nadditional\nfor other than U.S. mailing).\n_"
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_4",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 5,
    "text": "TABLE\nOF CONTENTS\nPage\nAbstract\n1\nIntroduction\n2\nBackground\n4\nRemote Monitoring Techniques\n7\nHybrid Monitors\n14\nNetwork Monitors\n16\nFault Diagnosis Monitors\n20\nIntelligent and Extended Consoles\n21\nSummary and Conclusions\n23\nAcknowledgement\n»\n26\nReferences\n27\niii"
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_5",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 7,
    "text": "A SURVEY\nOF REMOTE MONITORING\nAbstract\nThis\nreport describes\nremote monitoring\nin\nthe application areas\nof\nperformance evaluation, diagnostic testing,\nperformance assurance\nand system security testing.\nThe evolution\nof remote monitoring\nis\nbriefly reviewed and,\nthen,\nremote monitors\nare categorized\ninto\nseven\nclasses.\nSeveral\nexample systems\nare discussed for each\nclassification,\nalong with their capabilities\nin\neach application\narea.\nThe views\npresented\nin\nthis\nreport represent only those of\nthe author,\nan\nindependent consultant,\nand\nshould not be construed\nas\na\npolicy statement of NBS\nor any other organization.\nKey Words\n:\nDiagnostic\ntesting;\nperformance assurance;\nperformance evaluation;\nremote monitoring;\nsystem security testing\nNOTE:\nReports\non commercial\ndevelopments\nincluded\nin\nthe publication were\nobtained from the open\nliterature,\nsupplemented\nby documentation\nand\ncorrespondence,\nreferenced\nby permission.\nInclusion\nor exclusion\nof specific companies,\ndevelopments,\nor products\ncannot\nbe construed\nas\nrecommendation\nor endorsement\nby the National\nBureau\nof Standards.\nPaul\nF.\nRoth\nSystems\nand Software Division\nInstitute for Computer\nSciences\nand Technology\n1"
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_6",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 8,
    "text": "INTRODUCTION\nThe general\narea\nof remote monitoring\nof computer\nsystems encompasses\na\nbroad\nspectrum of mechanisms\nfor\na wide variety of purposes.\nIn\nthis\nreport,\nthe discussion\nis\nrestricted\nto monitoring systems\nor\nstudies\nwhere\na mechanism\nis\nused\nto measure or observe\nthe\nperformance\nof\na\ncomputer\nsystem,\nand\nthat mechanism can\nbe controlled\nby another device\nor\na\nhuman\nfrom\nsome geographically distinct location.\nIn most\ncases,\nit\nis expected that the monitoring device\nitself\nis designed\nto collect\ndata about the\nhost\nsystem,\nperform\nat least preliminary filtering\nof\nthe raw data,\nand then either\nstore\nthe\nfiltered data\nfor retrieval\nby\nthe\ncentral\ncontroller or immediately transmit the\nfiltered\ndata\nto\nthe\ncentral\nmonitor\ncontroller.\nThe\nnomenclature\nused\nfor\nthe various\ncon-\nstituents,\nthen, is\nas\nfollows:\nThe\nhost\nsystem\nis\nthe\ninstallation\nbeing monitored;\na monitor\nthat\nis\nlocal\nto the\nhost\nis\nreferred\nto\nas\na\nremote monitor\n.\nThe remote monitor\nis\nultimately controlled from\na\ncentral\nsite\nby the central\nmonitor controller.\nThe\nhost computer\nis\nconsidered\nto\nbe\nthe remote\nfacility,\nwhile\nthe measurement control\nand\nanalysis\ntake\nplace\nat the central\nsite.\nThis classification of remote monitors admits\nsuch approaches\nas:\nthose\nimplemented\npurely in software which can\nbe\ninterrogated from\nan\nexternal\nterminal,\nprogrammable\nhardware monitors,\nhardware monitors\ndistributed\nover different portions of the\nhost machine,\nhybrid monitors, monitors\nused\nin distributed computer\nnetworks,\nfault diagnosis monitors,\nand\nextended consoles\nfor\na\ncomputer\nsystem.\nEach of these categories\nwill\nbe discussed\nin\ndetail\nin\na\nlater section of this\nreport.\nThe classifi-\ncation excludes classic\nhardware monitors\nthat require\nplugboard alter-\nations\nto\nchange\nthe\nlogical\ncombination of probe\nsignals.\nIt also\nexcludes\npure\nsoftware-implemented monitors\nwhich\nuse\nthe\nnormal\noper-\nating\nsystem facilities\nfor \"triggering,\"\nreporting and recording.\nRemote monitors are\nbeing\nused\nin\na\nnumber of ways\nthat earlier,\nlocally\ncontrolled monitors were\nnot used.\nThe most obvious\nuse\nof the monitors\nis\nfor gathering\nperformance\ndata.\nRemote\nperformance monitor facil-\nities are\nfrequently divided\ninto\na\nnumber of remote\ndata\ngathering\nmechanisms\nplus\na\nsingle,\nshared facility\nto analyze\ndata\nggd\nprepare\nreports;\nthe Tesdata\nfacilities\nare examples of this\ntype.\nDistri-\nbuted monitors,\nperhaps\nbest exemplified\nby the\nPARTNER\npackage\nfor\nControl\nData\n6000\nseries machines,\nare\nalso frequently used\nfor\nper-\nformance measurements;\nthe\nidea\nhere\nis\nto dedicate\ncertain hardware\nfac-\nilities\nof\nthe\nhost\nsystem\nto\nthe measurement\nfunction.\nProgrammable\nhardware monitors\nare merely\na\nrefinement of earlier\nhardware monitors,\nand also are\nprimarily used\nfor\nperformance measurement.\nA\nnewer application of remote monitors"
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_7",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 8,
    "text": "for\nControl\nData\n6000\nseries machines,\nare\nalso frequently used\nfor\nper-\nformance measurements;\nthe\nidea\nhere\nis\nto dedicate\ncertain hardware\nfac-\nilities\nof\nthe\nhost\nsystem\nto\nthe measurement\nfunction.\nProgrammable\nhardware monitors\nare merely\na\nrefinement of earlier\nhardware monitors,\nand also are\nprimarily used\nfor\nperformance measurement.\nA\nnewer application of remote monitors\nis\nfor computer\nsystem diagnosis\nand\nremote exercising\nof\na\ncomputer\nsystem,\nA number of computer manu-\nfacturers\nhave\nincluded\nthis capability\nin\ntheir current product\nline.\n5,32,47,58,59\nj^q\nbasic\nidea\nis\nto replace\nthe conventional\noperator's\nconsole with\nan\nintelligent device\nsuch\nas\na minicomputer.\nThe\nintelli-\ngent console\ncan\nbe used\nto\ninspect any of\na number\nconditions\nthat\nSuperscript numbers indicate literature references\nat end of the report.\n2"
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_8",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 9,
    "text": "exist\nin\nthe\nhost machine,\nallowing\nthe observed condition\nto\nbe analyzed,\nrecorded or transmitted\non\na telecommunications\nlink\nto\na remote controller.\nThe remote controller may\nbe\na\nhuman operator\nor another computer system.\nAlthough\nthis\nis apparently\na new concept\nto most machine manufacturers,\nit should\nbe noted\nthat Control\nData\n6000 series\ncomputer systems\nhave^\nused\nthis approach\nto\nimplement their consoles\nfor\na number\nof years.\nA new area for which remotely controlled monitors might\nbe employed\nis\nthat of performance assurance and safeguard\nstudies.\nThe goal\nis\nto mon-\nitor the workload\nof\na computer system\nin order\nto either assure\na given\nlevel\nof performance,\nor\nto assure\nthat\na computer system\nis\nnot\nbeing\nused\nfor tasks\nthat were not intended\nto\nbe executed\non\nthat\nsystem.\nAlthough\nit would\nbe satisfying\nto\nbe able\nto monitor\na\nprocessor's\npro-\ngram counter\nto determine what program the processor\nis\nexecuting,\nthis\nis obviously impossible\nin\nthe general\ncase.\nIt\nis easy\nto construct\nan\nexample that shows\nthat\nif one could write\nan algorithm that\ninspects\nthe\nprogram counter\nlocus\nand\nidentifies\na corresponding algorithm,\nthen\none\nought\nto\nbe able\nto write\na\nsimilar algorithm that inspects\nthe program\ncounter\nlocus\nand\nindicates whether the corresponding algorithm will\never\nterminate or\nragt.\nThe\nlatter algorithm\nhas\nbeen\nproven\nto\nbe impossible\nto construct.\nNevertheless,\nthere are other activities\nin\nthe computer\nsystem that\ncan\nbe\nobserved with\na monitor,\ne.g.\nresouce utilization.\nOne can easily compute\nthe ratio of\ninput/output time\nto central\npro-\ncessor time for\na given job.\nThis will\nallow one\nto partition\nheavy\ncomputer jobs\nfrom input/output\nbound jobSo\nAlthough\nit\nis\nimpossible\nto identify arbitrary programs\nin\nexecution,\nit\nmay\nbe possible\nto recognize\na\nsmall\nset of programs when\nthey are execu-\nting\non\nthe\nhost\nsystem.\nFor example,\nsuppose that an\ninstallation\nis\nintended\nto only execute programs\nP,\n,\nP^...\nP\n(on arbitrary data).\nIt\nmay\nbe possible\nto employ heuristic technique?\nto recognize exactly when\none program from that\nset executes, while any unrecognizable program\nis\ndeclared\nto\nbe\nillegal.\nIn\nthis\ncase,\nremote monitoring techniques\ncan\nbe used\nto recognize\nthe\n\"signature\"\nof each\nof the\nn acceptable programs.\nFinally,\nremote monitors may\nbe used\nto enhance system security\nor\nto\nprovide\na mechanism for checking\nthe security of\na\nsystem.\nIt\nis\nclear\nthat the presence of monitors\nof any type\nare\na\nthreat\nto\nthe overall\nsecurity of\na computer system,\ne.g.\nsee references\n6 and\n13.\nWhenever\na\nmechanism\n(i.e.\na monitor)\nis\nprovided\nthe capability of observing\ncriti-\ncal\nportions\nof\nthe operating\nsystem,\nthen\nthat\nsame device\ncan\nbe mali-\nciously employed\nto penetrate"
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_9",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 9,
    "text": "is\nclear\nthat the presence of monitors\nof any type\nare\na\nthreat\nto\nthe overall\nsecurity of\na computer system,\ne.g.\nsee references\n6 and\n13.\nWhenever\na\nmechanism\n(i.e.\na monitor)\nis\nprovided\nthe capability of observing\ncriti-\ncal\nportions\nof\nthe operating\nsystem,\nthen\nthat\nsame device\ncan\nbe mali-\nciously employed\nto penetrate the conventional\nsecurity mechanisms\nof\nthat system.\nBy partitioning\na monitor\ninto\na\nlocal\ninternal\ncomponent\nand\na remote external\ncomponent,\nsystem security\nhas\na much\nbetter chance\nof\nbeing\neffective,\n\".'he\ninternal\nmonitor can\nbe written\nas\nan\ninternal\nportion of the operating\nsystem\nitself,\nsubject to the\nsame design\ncon-\nstraints\n(such\nas\nproof of correctness,\nrestricted entry points,\nauthor-\nized access,\netc.)\nas\nother modules.\nThe attendant\nsoftware\nis\nessen-\ntially data-gathering\ncode, which\nis\nsimpler and easier\nto make secure\nthan\na\nfull\nsoftware monitor.\nThe external\nportion\nof the monitor\nis\nallowed\nto access\nthe\ninternal\nportion through normal,\nsecure\npaths,\nthus\n3"
  },
  {
    "chunk_id": "A Survey of Remote Monitoring_first10_chunk_10",
    "filename": "A Survey of Remote Monitoring_first10.pdf",
    "page_num": 10,
    "text": "allowing authorization\nchecks\nand entries\ninto predefined procedures\nof\nthe operating\nsystem.\nAlthough\nthis\napproach\nis\nnot totally secure,\nit offers\na much more effective security policy than undisciplined mon-\nitoring\nof the\nhost system.\nAnother variant of remote monitors\ncan\nbe used\nto audit\na computer sys-\ntem's\nsecurity\nstate.\nThe\nbasic\nidea\nis\nto distribute\na monitor of\ninternal\nand external\ncomponents,\nas\nabove.\nThe external\nportion\nis used\ninteractively\nby\na\nhuman\nthat\nis\nresponsible for system security\nto audit\nvarious\nportions\nof the machine with the aid\nof the\ninternal\nportion\nof\nthe monitor.\nThis approach\nis used in\nthe WWMCCS computer systems,\nand\nwill\nbe discussed\nat\nlength\nin\nthe body of this\nreport.\nThe\nRand Corpor-\nation\nhas also\ninvestigated\nthe use of monitors\nto detect data\nbank\nintru-\nsions\nand\nto delay the\nintruder until\nother protective action\ncan\nbe\ntaken. ^-^\nIn\nthe remainder of this\nreport the background\nof remote monitoring will\nfirst\nbe examined.\nThe evolution of present-day monitoring\nsystems will\nbe traced from early performance monitoring work.\nThe main\nbody of this\nreport\nis\nthe next section;\nseven categories\nof remote monitors\nare\ndefined,\nand\na number of examples\nof each category are discussed.\nThe\nfinal\nsection draws\nsome conclusions about capabilities\nand\nlimitations\nfor various application\nareas\nand\nlooks briefly at future\ntrends\nin\nremote\nmonitoring.\nBACKGROUND\nIn\nthis\nsection\nof the report,\nthe evolution\nof remote monitors\nis dis-\ncussed beginning with\nhardware and\nsoftware monitors\nof the 1960-1970\nera.\nIn\nthe early 1970's monitoring\ntechniques\nand\ntools\nbecame sub-\nstantially more sophisticated,\nleading\nto the development of mechanisms\nthat could\nbe construed\nas\nremote monitors.\nThis\nsection will\nbriefly\ndescribe this evolution\ninto current remote monitoring technology.\nComputer system monitoring\nhas\nbecome\na\nprimary component of system\ndesign, manufacture,\nand maintenance because\nof\nits application\nto\nperformance evaluation.\nAlthough\ntesting\ninstruments\n(e.g.\noscilloscopes)\nwere frequently used\nto monitor the hardware at\na very low level,\nsystem\nmonitoring\ndid not really begin\nto\nbe needed\nuntil\nthe mid\n1960's.\nIn\nthe early part of that decade,\ncomputer systems\nbegan\nto reach\na\nlevel\nof\nsophistication where resources were shared among\na\nset of users.\nOnce\nresource sharing was\nintroduced,\nthen resource utilization became\nan\nimportant metric for that\nsystem.\nIf utilization was\ntoo\nhigh,\nthen\nthe\nresource represented\na bottleneck\nto system progress;\nif utilization was\ntoo\nlow,\nthen\nthe resource was\neither over-configured\nor,\nperhaps, was\nbeing\nprevented from being used effectively\nby bottlenecks elsewhere\nin\nthe\nsystem.\nThe result was frantic activity\nin\nthe areas\nof hardware\nand software monitor development.\n4"
  },
  {
    "chunk_id": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10_chunk_0",
    "filename": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10.pdf",
    "page_num": 1,
    "text": "NIST Special Publication  \nNIST SP 800-207A \nA Zero Trust Architecture Model \nfor Access Control in Cloud-Native \nApplications in Multi-Location \nEnvironments \n \nRamaswamy Chandramouli \nZack Butcher  \n  \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-207A"
  },
  {
    "chunk_id": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10_chunk_1",
    "filename": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10.pdf",
    "page_num": 2,
    "text": "NIST Special Publication  \nNIST SP 800-207A \nA Zero Trust Architecture Model \nfor Access Control in Cloud-Native \nApplications in Multi-Location \nEnvironments \n \nRamaswamy Chandramouli \nComputer Security Division \nInformation Technology Laboratory \n \nZack Butcher \nTetrate, Inc. \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-207A \nSeptember 2023 \n \nU.S. Department of Commerce  \nGina M. Raimondo, Secretary \nNational Institute of Standards and Technology  \nLaurie E. Locascio, NIST Director and Under Secretary of Commerce for Standards and Technology"
  },
  {
    "chunk_id": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10_chunk_2",
    "filename": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10.pdf",
    "page_num": 3,
    "text": "NIST SP 800-207A \n \nZTA Model for Access Control in Cloud-Native \nSeptember 2023 \n \nApplications in Multi-Location Environments \n \n \n \nCertain commercial equipment, instruments, software, or materials, commercial or non-commercial, are identified in \nthis paper in order to specify the experimental procedure adequately. Such identification does not imply \nrecommendation or endorsement of any product or service by NIST, nor does it imply that the materials or \nequipment identified are necessarily the best available for the purpose. \nThere may be references in this publication to other publications currently under development by NIST in \naccordance with its assigned statutory responsibilities. The information in this publication, including concepts and \nmethodologies, may be used by federal agencies even before the completion of such companion publications. Thus, \nuntil each publication is completed, current requirements, guidelines, and procedures, where they exist, remain \noperative. For planning and transition purposes, federal agencies may wish to closely follow the development of \nthese new publications by NIST.   \nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback \nto NIST. Many NIST cybersecurity publications, other than the ones noted above, are available at \nhttps://csrc.nist.gov/publications. \nAuthority \nThis publication has been developed by NIST in accordance with its statutory responsibilities under the Federal \nInformation Security Modernization Act (FISMA) of 2014, 44 U.S.C. § 3551 et seq., Public Law (P.L.) 113-283. \nNIST is responsible for developing information security standards and guidelines, including minimum requirements \nfor federal information systems, but such standards and guidelines shall not apply to national security systems \nwithout the express approval of appropriate federal officials exercising policy authority over such systems. This \nguideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130. \n \nNothing in this publication should be taken to contradict the standards and guidelines made mandatory and binding \non federal agencies by the Secretary of Commerce under statutory authority. Nor should these guidelines be \ninterpreted as altering or superseding the existing authorities of the Secretary of Commerce, Director of the OMB, or \nany other federal official.  This publication may be used by nongovernmental organizations on a voluntary basis and \nis not subject to copyright in the United States. Attribution would, however, be appreciated by NIST.  \nNIST Technical Series Policies \nCopyright, Use, and Licensing Statements \nNIST Technical Series Publication Identifier Syntax \nPublication History \nApproved by the NIST Editorial Review Board on 2023-09-08 \nHow to Cite this NIST Technical Series Publication:  \nChandramouli R, Butcher Z (2023) A Zero-Trust Architecture Model for Access Control in Cloud-Native \nApplications in Multi-Location Environments. (National Institute of Standards and Technology, Gaithersburg, MD), \nNIST Special Publication (SP) NIST SP 800-207A. https://doi.org/10.6028/NIST.SP.800-207A  \nAuthor ORCID iDs \nRamaswamy Chandramouli: 0000-0002-7387-5858"
  },
  {
    "chunk_id": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10_chunk_3",
    "filename": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10.pdf",
    "page_num": 4,
    "text": "NIST SP 800-207A \n \nZTA Model for Access Control in Cloud-Native \nSeptember 2023 \n \nApplications in Multi-Location Environments \n \n \n \nContact Information \nsp800-207A-comments@nist.gov \n \nNational Institute of Standards and Technology \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 \nAll comments are subject to release under the Freedom of Information Act (FOIA)."
  },
  {
    "chunk_id": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10_chunk_4",
    "filename": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10.pdf",
    "page_num": 5,
    "text": "NIST SP 800-207A \n \nZTA Model for Access Control in Cloud-Native \nSeptember 2023 \n \nApplications in Multi-Location Environments \n \n \ni \n \nAbstract \nOne of the basic tenets of zero trust is to remove the implicit trust in users, services, and devices \nbased only on their network location, affiliation, and ownership. NIST Special Publication 800-\n207 has laid out a comprehensive set of zero trust principles and referenced zero trust \narchitectures (ZTA) for turning those concepts into reality. A key paradigm shift in ZTAs is the \nchange in focus from security controls based on segmentation and isolation using network \nparameters (e.g., Internet Protocol (IP) addresses, subnets, perimeter) to identities. From an \napplication security point of view, this requires authentication and authorization policies based \non application and service identities in addition to the underlying network parameters and user \nidentities. This in turn requires a platform that consists of Application Programming Interface \n(API) gateways, sidecar proxies, and application identity infrastructures (e.g., Secure Production \nIdentity Framework for Everyone [SPIFFE]) that can enforce those policies irrespective of the \nlocation of the services or applications, whether on-premises or on multiple clouds. The \nobjective of this publication is to provide guidance for realizing an architecture that can enforce \ngranular application-level policies while meeting the runtime requirements of ZTA for multi-\ncloud and hybrid environments. \nKeywords \negress gateway; identity-tier policies; ingress gateway; microservices; multi-cloud; network-tier \npolicies; service mesh; sidecar proxy; SPIFFE; transit gateway; zero trust; zero trust architecture. \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test \nmethods, reference data, proof of concept implementations, and technical analyses to advance \nthe development and productive use of information technology. ITL’s responsibilities include the \ndevelopment of management, administrative, technical, and physical standards and guidelines for \nthe cost-effective security and privacy of other than national security-related information in \nfederal information systems. The Special Publication 800-series reports on ITL’s research, \nguidelines, and outreach efforts in information system security, and its collaborative activities \nwith industry, government, and academic organizations."
  },
  {
    "chunk_id": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10_chunk_5",
    "filename": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10.pdf",
    "page_num": 6,
    "text": "NIST SP 800-207A \n \nZTA Model for Access Control in Cloud-Native \nSeptember 2023 \n \nApplications in Multi-Location Environments \n \n \nii \n \nPatent Disclosure Notice \nNOTICE: ITL has requested that holders of patent claims whose use may be required for \ncompliance with the guidance or requirements of this publication disclose such patent claims to \nITL. However, holders of patents are not obligated to respond to ITL calls for patents and ITL \nhas not undertaken a patent search in order to identify which, if any, patents may apply to this \npublication. \nAs of the date of publication and following call(s) for the identification of patent claims whose \nuse may be required for compliance with the guidance or requirements of this publication, no \nsuch patent claims have been identified to ITL.  \nNo representation is made or implied by ITL that licenses are not required to avoid patent \ninfringement in the use of this publication."
  },
  {
    "chunk_id": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10_chunk_6",
    "filename": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10.pdf",
    "page_num": 7,
    "text": "NIST SP 800-207A \n \nZTA Model for Access Control in Cloud-Native \nSeptember 2023 \n \nApplications in Multi-Location Environments \n \n \niii \n \nTable of Contents \nExecutive Summary ................................................................................................................. 1 \n \nIntroduction ...................................................................................................................... 2 \n \nBackground – Zero Trust Principles and Zero Trust Architecture ................................ 2 \n \nRelationship to Other NIST Guidance Documents ...................................................... 3 \n \nScope ......................................................................................................................... 3 \n \nTarget Audience ......................................................................................................... 4 \n \nOrganization of This Document .................................................................................. 4 \n \nThe Enterprise Cloud-Native Platform and its Components ......................................... 5 \n \nEnterprise Infrastructure Layer ................................................................................... 6 \n \nDesigning a Policy Framework for ZTA for Cloud-Native Application Environments . 7 \n \nFunctional Components of Identity-Based Segmentation Policies for ZTA .................. 8 \n \nShortcomings of Identity-Based Segmentation Policies for Enterprise ZTA ................ 9 \n \nMulti-Tier Policies for Enterprise ZTA ......................................................................... 9 \n \nImplementing Multi-Tier Policies for ZTA for Cloud-Native Application Environments  \n \n ..........................................................................................................................................12 \n \nReference Application Infrastructure Scenario ...........................................................12 \n \nRole of the Service Mesh in Policy Deployment, Enforcement, and Updates .............13 \n \nPolicy Deployment for Reference Application Infrastructure.......................................14 \n \nAnother Application Infrastructure Scenario ...............................................................15 \n \nFunctional Roles of Application Infrastructure Elements in Enforcing Policies ...........16 \n \nComparison of Identity-Tier and Network-Tier Policies ..............................................17 \n4.6.1. \nApproaches for Deployment and the Limitations of Network-Tier Policies ...............17 \n4.6.2. \nPrerequisites for the Deployment of Identity-Tier Policies ........................................18 \n4.6.3. \nAdvantages of Identity-Tier Policies .........................................................................19 \n \nSummary and Conclusions ............................................................................................20 \nReferences ..............................................................................................................................23 \nList of Figures \nFig. 1. Enterprise infrastructure layer for uniform policy deployment .......................................... 7 \nFig. 2. Flexibility provided by multi-tier policies .........................................................................10 \nFig. 3. Multi-tier Policies for a Hybrid Application Environment .................................................13 \nFig. 4. An Istio Authorization Policy that allows Service 1 to Service 2 on port 443 but only \nallows it to execute the GET HTTP verb on the “/public” path ........................................15 \nFig. 5. Policy Deployment for a Three-tier Application ...............................................................16"
  },
  {
    "chunk_id": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10_chunk_7",
    "filename": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10.pdf",
    "page_num": 8,
    "text": "NIST SP 800-207A \n \nZTA Model for Access Control in Cloud-Native \nSeptember 2023 \n \nApplications in Multi-Location Environments \n \n \niv \n \nAcknowledgments \nThe authors would like to express their thanks to Isabel Van Wyk of NIST for her detailed \neditorial review of the public comment version as well as the final publication."
  },
  {
    "chunk_id": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10_chunk_8",
    "filename": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10.pdf",
    "page_num": 9,
    "text": "NIST SP 800-207A \n \nZTA Model for Access Control in Cloud-Native \nSeptember 2023 \n \nApplications in Multi-Location Environments \n \n \n1 \n \nExecutive Summary \nThe principles of zero trust, as described in NIST Special Publication (SP) 800-207, have \nbecome the guiding markers for developing secure zero trust architecture. A well-established \nclass of applications is the cloud-native application class. The generally accepted \ncharacterization of a cloud-native application includes the following: \n• The application is made up of a set of loosely coupled components called microservices. \nEach of the microservices can be hosted on different physical or virtual machines (VMs) \nand even be geographically distributed (e.g., within several facilities that belong to the \nenterprise, such as the headquarters, branch offices, and in various cloud service provider \nenvironments). \n• Any transaction involving the application may also involve one or more inter-service \n(microservice) calls across the network. \n• A widespread feature (though not necessarily a requirement for cloud-native applications) \nis the presence of a software platform called the service mesh that provides an integrated \nset of all application services (e.g., services discovery, networking connections, \ncommunication resilience, and security services like authentication and authorization). \nThe realization of a zero trust architecture for the above class of cloud-native applications \nrequires a robust policy framework. In order to follow zero trust principles, the constituent \npolices in the framework should consider the following scenario: \n• There should not be implicit trust in users, services, or devices based exclusively on their \nnetwork location, affiliation, or ownership. Hence, policy definitions and associated \nsecurity controls based on the segmentation or isolation of networks using network \nparameters (e.g., IP addresses, subnets, perimeter) are insufficient. These policies fall \nunder the classification of network-tier policies. \n• To ensure the presence of zero trust principles throughout the entire application, network-\ntier policies must be augmented with policies that establish trust in the identity of the \nvarious participating entities (e.g., users and services) irrespective of the location of the \nservices or applications, whether on-premises or on multiple clouds. \nThis document provides guidance for realizing a zero trust architecture that can enforce granular \napplication-level policies for cloud-native applications. The guidance is anchored in the \nfollowing: \n• A combination of network-tier and identity-tier policies \n• The components of cloud-native applications that enable the definition and deployment \nof those policies, such as edge, ingress, sidecar, and egress gateways; the creation, \nissuance, and maintenance of service identities; and the issuance of authentication and \nauthorization tokens that carry user identities in the enterprise application infrastructure \nthat encompasses multi-cloud and hybrid environments"
  },
  {
    "chunk_id": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10_chunk_9",
    "filename": "A Zero Trust Architecture Model for Access Control in Cloud-Native Applications in Multi-Cloud Environments_first10.pdf",
    "page_num": 10,
    "text": "NIST SP 800-207A \n \nZTA Model for Access Control in Cloud-Native \nSeptember 2023 \n \nApplications in Multi-Location Environments \n \n \n2 \n \n \nIntroduction  \nZero trust (ZT) tenets or principles have been accepted as the guide markers for architecting all \napplications. There are several reasons why adherence to these tenets is critical for obtaining \nnecessary security assurances, especially for cloud-native applications. The enterprise \napplication environments for this class of applications are highly geographically distributed and \nspan multiple cloud and on-premises environments (e.g., headquarters, enterprise-operated data \ncenters, branch offices). Further, the user base consists of both remote and on-premises \nemployees. These two features call for establishing trust in all of the data sources and computing \nservices of the enterprise — irrespective of their location — through secure communication and \nthe validation of access policies.  \nApart from geographic distribution, another common feature of cloud-native applications is the \npresence of many microservices that are loosely coupled and collectively support business \nprocesses through extensive inter-service calls. This is augmented by an integrated infrastructure \nfor providing all application services called the service mesh. These features emphasize the \nconcept of identity for the various components of the application in the form of microservices as \nwell as the users who access them through direct calls or clients (other services). This in turn \nhighlights the critical need for authenticating these identities and for providing legitimate access \non a per-session basis through a dynamic policy that takes the current status of the user, service, \nand requested resource into account. \nThe above requirements can only be met through a comprehensive policy framework. This \ndocument provides guidance for developing a policy framework that will form the foundation for \nrealizing a zero trust architecture (ZTA) while incorporating zero trust principles into its design \nfor cloud-native applications. The policy framework should also consist of a comprehensive set \nof policies that span all critical entities and resources in the application stack, including the \nnetwork, network devices, users, and services. \n \nBackground — Zero Trust Principles and Zero Trust Architecture  \nA summary of the zero trust principles and the definition of a zero trust architecture, as described \nin SP 800-207, Zero Trust Architecture [1], are: \n• Zero trust is the term for an evolving set of cybersecurity paradigms that move defenses \nfrom static, network-based perimeters to focus on users and resources. It is a set of \nsecurity primitives rather than a particular set of technologies. Zero trust assumes that \nthere is no implicit trust granted to user accounts based solely on their physical or \nnetwork location (i.e., local area networks versus the internet) or to endpoints (devices) \nbased on their ownership (e.g., enterprise or personally owned). Zero trust focuses on \nprotecting resources (e.g., devices, services, workflows, network accounts) rather than \nnetwork segments, as the network location is no longer seen as the prime component to \nthe security posture of the resource. \n• A zero trust architecture uses zero trust principles to plan industrial and enterprise \ninfrastructures and workflows."
  },
  {
    "chunk_id": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10_chunk_0",
    "filename": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10.pdf",
    "page_num": 1,
    "text": "NIST SPECIAL PUBLICATION 1800-37 \nAddressing Visibility Challenges with TLS 1.3 \nwithin the Enterprise \nHigh-Level Document \nBill Newhouse \nMurugiah Souppaya \nDavid Cooper \nTim Polk* \nNational Institute of Standards \nWilliam Barker \nStratvia LLC \nKaren Scarfone \nScarfone Cybersecurity \nJohn Kent \nJulian Sexton \nMichael Dimond \nJosh Klosterman \nRyan Williams \nThe Mitre Corporation \nDavid Wells \nJohann Tonsing \nMira Security \nSean Turner \nsn3rd \nPatrick Kelsey \nNot for Radio \nRuss Housley \nVigil Security LLC \nTim Cahill \nJPMorgan Chase & Company \nMuralidharan \nPalanisamy \nAppViewX \nDung Lam \nF5 \nPaul Barrett \nRay Jones \nSandeep Jha \nNetscout \nSteven Fenter \nJake Wills \nUS Bank Corporation \nJane Gilbert \nD’Nan Godfrey \nThales TCT \nDean Cocklin \nAvesta Hojjati \nDigiCert \n*Contributed while a NIST\nEmployee\nSeptember 2025 \nFINAL \nThis publication is available free of charge from \nhtps://www.nccoe.nist.gov/addressing-visibility-challenges-tls-13"
  },
  {
    "chunk_id": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10_chunk_1",
    "filename": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10.pdf",
    "page_num": 2,
    "text": "FINAL \nNIST SP 1800-37: Addressing Visibility Challenges with TLS 1.3 \nii \nNIST SPECIAL PUBLICATION 1800-37 \n \nAddressing Visibility Challenges with TLS 1.3  \nwithin the Enterprise \nHigh-Level Document \n \nBill Newhouse \nMurugiah Souppaya \nDavid Cooper \nTim Polk* \nNational Institute of  \nStandards \n \nWilliam Barker \nStratvia LLC \n \nKaren Scarfone \nScarfone Cybersecurity \n \nJohn Kent \nJulian Sexton \nMichael Dimond \nJosh Klosterman \nRyan Williams \nThe Mitre Corporation \n \nDavid Wells \nJohann Tonsing \nMira Security \n \nSean Turner \nsn3rd \n \nPatrick Kelsey \nNot for Radio \n \nRuss Housley \nVigil Security LLC \n \nTim Cahill \nJPMorgan Chase &  \nCompany \n \nMuralidharan Palanisamy \nAppViewX \n \nDung Lam \nF5 \n \nPaul Barrett \nRay Jones \nSandeep Jha \nNetscout \n \nSteven Fenter \nJake Wills \nUS Bank Corporation \n \nJane Gilbert \nD’Nan Godfrey \nThales TCT \n \nDean Cocklin \nAvesta Hojjati \nDigiCert  \n \n*Contributed while a NIST  \nEmployee \nFinal \nSeptember 2025 \n \nU.S. Department of Commerce  \nHoward Lutnick, Secretary \nNational Institute of Standards and Technology  \nCraig Burkhardt, Acting Under Secretary of Commerce for Standards and Technology and Acting NIST Director"
  },
  {
    "chunk_id": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10_chunk_2",
    "filename": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10.pdf",
    "page_num": 3,
    "text": "FINAL \nNIST SP 1800-37: Addressing Visibility Challenges with TLS 1.3 \niii \nDISCLAIMER \nCertain commercial enƟƟes, equipment, products, or materials may be idenƟﬁed by name or \ncompany logo or other insignia in order to acknowledge their parƟcipaƟon in this collaboraƟon \nor to describe an experimental procedure or concept adequately. Such idenƟﬁcaƟon is not in-\ntended to imply special status or relaƟonship with NIST or recommendaƟon or endorsement by \nNIST or NCCoE; neither is it intended to imply that the enƟƟes, equipment, products, or materi-\nals are necessarily the best available for the purpose. \nWhile NIST and the NCCoE address goals of improving management of cybersecurity and privacy \nrisk through outreach and applicaƟon of standards and best pracƟces, it is the stakeholder’s re-\nsponsibility to fully perform a risk assessment to include the current threat, vulnerabiliƟes, like-\nlihood of a compromise, and the impact should the threat be realized before adopƟng cyberse-\ncurity measures such as this recommendaƟon. \n \nNaƟonal InsƟtute of Standards and Technology Special PublicaƟon 1800-37, Natl. Inst. Stand. \nTechnol. Spec. Publ. 1800-37, 63 pages, (September 2025), CODEN: NSPUE2 \nNATIONAL CYBERSECURITY CENTER OF EXCELLENCE \nThe NaƟonal Cybersecurity Center of Excellence (NCCoE), a part of the NaƟonal InsƟtute of \nStandards and Technology (NIST), is a collaboraƟve hub where industry organizaƟons, govern-\nment agencies, and academic insƟtuƟons work together to address businesses’ most pressing \ncybersecurity issues. This public-private partnership enables the creaƟon of pracƟcal cybersecu-\nrity soluƟons for speciﬁc industries, as well as for broad, cross-sector technology chal-\nlenges. Through consorƟa under CooperaƟve Research and Development Agreements (CRA-\nDAs), including technology partners—from Fortune 50 market leaders to smaller companies \nspecializing in informaƟon technology security—the NCCoE applies standards and best pracƟces \nto develop modular, adaptable example cybersecurity soluƟons using commercially available \ntechnology. The NCCoE documents these example soluƟons in the NIST Special PublicaƟon 1800 \nseries, which maps capabiliƟes to the NIST Cybersecurity Framework and details the steps \nneeded for another enƟty to re-create the example soluƟon. The NCCoE was established in \n2012 by NIST in partnership with the State of Maryland and Montgomery County, Maryland."
  },
  {
    "chunk_id": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10_chunk_3",
    "filename": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10.pdf",
    "page_num": 4,
    "text": "FINAL \nNIST SP 1800-37: Addressing Visibility Challenges with TLS 1.3 \niv \nTo learn more about the NCCoE, visit htps://www.nccoe.nist.gov/. To learn more about NIST, \nvisit \nhtps://www.nist.gov. \nNIST CYBERSECURITY PRACTICE GUIDES \nNIST Cybersecurity PracƟce Guides (Special PublicaƟon 1800 series) target speciﬁc cybersecurity \nchallenges in the public and private sectors. They are pracƟcal, user-friendly guides that facili-\ntate the adopƟon of standards-based approaches to cybersecurity. They show members of the \ninformaƟon security community how to implement example soluƟons that help them align with \nrelevant standards and best pracƟces, and provide users with the materials lists, conﬁguraƟon \nﬁles, and other informaƟon they need to implement a similar approach. \nThe documents in this series describe example implementaƟons of cybersecurity pracƟces that \nbusinesses and other organizaƟons may voluntarily adopt. These documents do not describe \nregulaƟons or mandatory pracƟces, nor do they carry statutory authority. \nABSTRACT \nThe Transport Layer Security (TLS) protocol is widely deployed to secure network traﬃc. TLS 1.3 \nprotects the contents of its previous TLS communicaƟons even if a TLS-enabled server is com-\npromised.  This is known as forward secrecy. The approach used to achieve forward secrecy in \nTLS 1.3 may interfere with passive decrypƟon techniques that enterprises rely on to have visibil-\nity into their TLS 1.2 traﬃc. Enterprises’ authorized network security staﬀ rely on that visibility \nto protect its data and systems with criƟcal cybersecurity controls to meet operaƟonal needs \nand legal requirements. AdopƟon of the TLS 1.3 protocol can disrupt current approaches to ob-\nserving and monitoring internal network communicaƟons within an enterprise.  \nThe NCCoE, in collaboraƟon with technology providers and enterprise customers, iniƟated a \nproject to demonstrate opƟons for maintaining visibility within the TLS 1.3 protocol using sev-\neral standards-compliant builds that enterprises can use for real-Ɵme and post-facto systems \nmonitoring and analyƟcs capabiliƟes.  \nThis publicaƟon contains demonstrated proofs of concept along with links to detailed technical \ninformaƟon online on NIST pages. This publicaƟon also includes links to mappings of TLS 1.3 vis-\nibility principles to commonly used security standards and guidelines. \nKEYWORDS \nbounded lifetime; break and inspect; ephemeral; key management; middlebox; passive decryp-\ntion; passive inspection; protocol; Transport Layer Security (TLS); visibility."
  },
  {
    "chunk_id": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10_chunk_4",
    "filename": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10.pdf",
    "page_num": 5,
    "text": "FINAL \nNIST SP 1800-37: Addressing Visibility Challenges with TLS 1.3 \nv \nACKNOWLEDGMENTS \nWe are grateful to the following individuals for their generous contribuƟons of experƟse and \nƟme. \nName \nOrganization \nRavishankar Chamarajnagar \nAppViewX \nMichael Ackermann  \nBlue Cross Blue Shield \nJonathan Chen \nF5 \nRyan Johnson \nF5 \nBrad Otlin \nF5 \nKevin Stewart \nF5 \nNanjaiah Vijayalakshmi \nNETSCOUT Corporation \nGina Scinta \nThales Trusted Cyber Technologies \nLauren Brown \nJPMorgan Chase & Company \n \nThe Technology Partners/Collaborators who participated in this build submitted their capabilities in \nresponse to a notice in the Federal Register. Respondents with relevant capabilities or product \ncomponents were invited to sign a Cooperative Research and Development Agreement (CRADA) with \nNIST, allowing them to participate in a consortium to build this example solution. We worked with: \nTechnology Partner/Collaborator \nBuild Involvement \nAppViewX \nNETSCOUT Corporation \nDigiCert \nNot for Radio LLC \nF5 \nThales Trusted Cyber Technologies \nJPMorgan Chase & Company \nU.S. Bank Corporation"
  },
  {
    "chunk_id": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10_chunk_5",
    "filename": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10.pdf",
    "page_num": 6,
    "text": "FINAL \nNIST SP 1800-37: Addressing Visibility Challenges with TLS 1.3 \nvi \nTechnology Partner/Collaborator \nBuild Involvement \nMira Security, Inc. \n \n \nDOCUMENT CONVENTIONS  \nThe terms “shall” and “shall not” indicate requirements to be followed strictly to conform to the \npublicaƟon and from which no deviaƟon is permited. The terms “should” and “should not” in-\ndicate that among several possibiliƟes, one is recommended as parƟcularly suitable without \nmenƟoning or excluding others, or that a certain course of acƟon is preferred but not neces-\nsarily required, or that (in the negaƟve form) a certain possibility or course of acƟon is discour-\naged but not prohibited. The terms “may” and “need not” indicate a course of acƟon permissi-\nble within the limits of the publicaƟon. The terms “can” and “cannot” indicate a possibility and \ncapability, whether material, physical, or causal. \n \nNOTICE: The Information Technology Laboratory (ITL) has requested that holders of patent \nclaims whose use may be required for compliance with the guidance or requirements of this \npublication disclose such patent claims to ITL. However, holders of patents are not obligated to \nrespond to ITL calls for patents and ITL has not undertaken a patent search in order to identify \nwhich, if any, patents may apply to this publication. \nAs of the date of publication and following call(s) for the identiﬁcation of patent claims whose \nuse may be required for compliance with the guidance or requirements of this publication, no \nsuch patent claims have been identiﬁed to ITL.  \nNo representation is made or implied by ITL that licenses are not required to avoid patent in-\nfringement in the use of this publication."
  },
  {
    "chunk_id": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10_chunk_6",
    "filename": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10.pdf",
    "page_num": 7,
    "text": "FINAL \nNIST SP 1800-37: Addressing Visibility Challenges with TLS 1.3 \nvii \nTable of Contents \n1 Executive Summary ............................................................................. 1 \n2 Introduction ........................................................................................ 2 \n2.1 Audience ...................................................................................................................... 4 \n2.2 How to use this Guide .................................................................................................. 4 \n3 Project Overview ................................................................................ 4 \n3.1 Background .................................................................................................................. 4 \n3.2 Solution ........................................................................................................................ 5 \n4 Architecture and Builds ....................................................................... 6 \n4.1 Project Collaborators ................................................................................................... 6 \n4.1.1 \nAppViewX ...................................................................................................................... 7 \n4.1.2 \nDigiCert ......................................................................................................................... 7 \n4.1.3 \nF5 ................................................................................................................................... 8 \n4.1.4 \nJPMorgan Chase & Co. .................................................................................................. 8 \n4.1.5 \nMira Security ................................................................................................................. 8 \n4.1.6 \nNETSCOUT ..................................................................................................................... 9 \n4.1.7 \nNot for Radio ............................................................................................................... 10 \n4.1.8 \nThales Trusted Cyber Technologies ............................................................................ 10 \n4.2 Architecture and Builds .............................................................................................. 11 \n4.2.1 \nSystem Architecture Functions ................................................................................... 11 \n4.2.2 \nHigh-Level Passive Inspection Architecture Overview ................................................ 12 \n4.2.3 \nHigh-Level Middlebox Architecture Overview ............................................................ 15 \n5 Build Implementation ....................................................................... 17 \n5.1 Passive Inspection Architecture Builds ...................................................................... 18 \n5.1.1 \nBounded-Lifetime Key Pair (Bounded-Lifetime Diffie-Hellman) ................................. 18 \n5.1.2 \nDecryption Using Exported Session Keys .................................................................... 22 \n5.2 Break and Inspect Using Middleboxes ....................................................................... 25 \n5.2.1 \nReal-Time (RT) Decryption .......................................................................................... 26 \n5.2.2 \nPost-Facto Decryption (follows RT Decryption steps) ................................................ 27 \n5.2.3 \nMiddlebox Laboratory Build Components .................................................................. 27 \n5.2.4 \nInstallation and Configuration for Active Middlebox Approach ................................. 29 \n5.3 NCCoE Laboratory Physical Architecture ................................................................... 29"
  },
  {
    "chunk_id": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10_chunk_7",
    "filename": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10.pdf",
    "page_num": 8,
    "text": "FINAL \nNIST SP 1800-37: Addressing Visibility Challenges with TLS 1.3 \nviii \n5.4 Specific Details ........................................................................................................... 29 \n6 Functional Demonstrations ............................................................... 30 \n6.1 Usage Scenarios Supported ....................................................................................... 30 \n6.1.1 \nTroubleshooting Scenario ........................................................................................... 30 \n6.1.2 \nPerformance Monitoring Scenario ............................................................................. 30 \n6.1.3 \nCybersecurity Threat Triage and Forensics Scenario .................................................. 31 \n6.1.4 \nMonitoring for Compliance and Hygiene Scenario ..................................................... 31 \n6.2 Example Demonstration Events ................................................................................. 32 \n7 Risk and Compliance Management ................................................... 34 \n7.1 Threats ....................................................................................................................... 34 \n7.2 Vulnerabilities ............................................................................................................ 35 \n7.3 Risk ............................................................................................................................ 36 \n7.4 Security Control Map ................................................................................................. 38 \n8 Demonstration and Future Considerations ........................................ 39 \n8.1 General Findings and Observations ........................................................................... 39 \n8.2 Future Build Considerations ....................................................................................... 39 \n8.2.1 \nPlanning for Visibility with Post-Quantum Cryptography (PQC) ................................. 39 \n8.2.2 \nClient-Based Monitoring ............................................................................................. 40 \nAppendix A Glossary ............................................................................. 41 \nAppendix B List of Acronyms ................................................................. 44 \nAppendix C References ......................................................................... 47 \nAppendix D Description of the Architectures ......................................... 49 \nD.1 Passive Inspection using Bounded-lifetime DH Server Keys ....................................... 49 \nD.2 Passive inspection using Exported Session Keys ........................................................ 49 \nD.3 Active Inspection using a Break-and-Inspect Middlebox ........................................... 49 \nAppendix E Descriptions of the Build Implementations ......................... 50 \nE.1 Shared Components Across All Builds ........................................................................ 50 \nE.2 Implementation of the Bounded Lifetime DH Key Architecture ................................ 50 \nE.3 Implementation of the Exported Session Key Architecture ....................................... 50 \nE.4 Implementation of Middlebox Architecture Implementations .................................. 50 \nAppendix F Details of the Functional Demonstrations and Results ........ 51"
  },
  {
    "chunk_id": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10_chunk_8",
    "filename": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10.pdf",
    "page_num": 9,
    "text": "FINAL \nNIST SP 1800-37: Addressing Visibility Challenges with TLS 1.3 \nix \nF.1 \nTraffic Visibility to Support Troubleshooting ............................................................. 51 \nF.2 \nTraffic Visibility to Support Performance Monitoring ................................................ 51 \nF.3 \nTraffic Visibility to Support Cybersecurity Threat Triage and Forensics ..................... 51 \nF.4 \nTraffic Visibility to Support Monitoring for Compliance and Hygiene ........................ 51 \nF.5 \nFunctional Demonstration Scripts and Results .......................................................... 51 \nF.5.1 \nScenario 1.1 – Identify Failed Network Traffic Due to Expired TLS PKI Certificates \n(Layer 4) ...................................................................................................................... 51 \nF.5.2 \nScenario 1.2 – Identify and Log Protocol-Specific Distinct Characteristics of Layer 5, 6, \nand 7-type Service Utilization and Consumption Information ................................... 51 \nF.5.3 \nScenario 1.3 – Identify, Collect, and Report on Protocol-Specific Error Status Codes \nfor Services (Layer 5, 6, and 7-type status codes) ...................................................... 51 \nF.5.4 \nScenario 2.1 – Identify, Collect, and Report on Protocol-Specific Error Status Codes \nfor Services. ................................................................................................................. 52 \nF.5.5 \nScenario 2.2 – Identify the Propagation of Performance Issues Throughout a System \nby Correlating Error Status Codes Across Component Services ................................. 52 \nF.5.6 \nScenario 2.3 – Develop Baselines for Traffic Performance Characteristics for Each \nServer .......................................................................................................................... 52 \nF.5.7 \nScenario 3.1 – Scan Network Flows Content for Malware ......................................... 52 \nF.5.8 \nScenario 3.2 – Scan Network Traffic for Unauthorized Encrypted Connections (i.e., \nunexpected encryption types, unauthorized encryption protocols, unencrypted \ntraffic, traffic that can’t be decrypted, etc.) ............................................................... 52 \nF.5.9 \nScenario 3.3 – Scan Network Traffic Content for Known Command-and-Control or \nExfiltration Protocols .................................................................................................. 52 \nF.5.10 Scenario 3.4 – Scan Network Traffic for Un-Sanitized User Input .............................. 52 \nF.5.11 Scenario 4.1 – Identify and Report on the Use of Outdated Protocols (and/or \n'practices') ................................................................................................................... 52 \nAppendix G Appendix G: Security Control Mapping ............................... 53"
  },
  {
    "chunk_id": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10_chunk_9",
    "filename": "Addressing Visibility Challenges with TLS 1.3 within the Enterprise_ High-Level Document_first10.pdf",
    "page_num": 10,
    "text": "FINAL \nNIST SP 1800-37: Addressing Visibility Challenges with TLS 1.3 \nx \nList of Figures \nFigure 4-1 Middlebox (Break and Inspect) Functional Architecture ..................................................... 13 \nFigure 4-2 Passive Inspection - Exported Session Key Functional Architecture .................................... 14 \nFigure 4-3 Components of Break and Inspect Middlebox Architecture ................................................ 16 \nFigure 5-1 Real-Time Bounded-Lifetime DH Passive Inspection Flow .................................................. 19 \nFigure 5-2 Post-Facto Bounded-Lifetime DH Passive Inspection Flow .................................................. 20 \nFigure 5-3 Passive Inspection Using Exported Session Keys ................................................................ 23 \nFigure 5-4 Middlebox Break and Inspect Demonstration Elements ..................................................... 26 \nFigure 8-1 Sample use of PQC KEM in TLS 1.3 Handshake ................................................................... 40 \nList of Tables \nTable 5-1: Build Components for the Passive Decryption Using Bounded Life-time \nServer Keys Reference Architecture ................................................................................................... 21 \nTable 5-2: Build Components for the Passive Decryption Using Exported Session \nKeys Reference Architecture .............................................................................................................. 24 \nTable 5-3: Build Components for the Break and Inspect Decryption Reference \nArchitecture (Layer 3 Implementation) .............................................................................................. 27 \nTable 5-4: Build Components for the Break and Inspect Decryption Reference \nArchitecture (Layer 2 Implementation) .............................................................................................. 28 \nTable 6-1: Demonstration Events ....................................................................................................... 33"
  },
  {
    "chunk_id": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10_chunk_0",
    "filename": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10.pdf",
    "page_num": 1,
    "text": "NISTIR 8103 \nAdvanced Identity Workshop on \nApplying Measurement Science in the \nIdentity Ecosystem: \nSummary and Next Steps \nMichael E. Garcia \nPaul A. Grassi \nThis publication is available free of charge from: \nhttp://dx.doi.org/10.6028/NIST.IR.8103"
  },
  {
    "chunk_id": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10_chunk_1",
    "filename": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10.pdf",
    "page_num": 2,
    "text": "NISTIR 8103 \n \n \nAdvanced Identity Workshop on \nApplying Measurement Science in the \nIdentity Ecosystem:  \nSummary and Next Steps \n \nMichael E. Garcia \nPaul A. Grassi \nApplied Cybersecurity Division \nInformation Technology Laboratory \n \n \n \n \nThis publication is available free of charge from: \nhttp://dx.doi.org/10.6028/NIST.IR.8103 \n \n \n \nSeptember 2016 \n \n \n \n \n \n \n \n \n \n \n \nU.S. Department of Commerce  \nPenny Pritzker, Secretary \n \nNational Institute of Standards and Technology  \nWillie May, Under Secretary of Commerce for Standards and Technology and Director"
  },
  {
    "chunk_id": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10_chunk_2",
    "filename": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10.pdf",
    "page_num": 3,
    "text": "National Institute of Standards and Technology Internal Report 8103 \n14 pages (September 2016) \nThis publication is available free of charge from: \nhttp://dx.doi.org/10.6028/NIST.IR.8103 \n \nCertain commercial entities, equipment, or materials may be identified in this document in order to describe an \nexperimental procedure or concept adequately. Such identification is not intended to imply recommendation or \nendorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best \navailable for the purpose.  \nThere may be references in this publication to other publications currently under development by NIST in accordance \nwith its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, \nmay be used by federal agencies even before the completion of such companion publications. Thus, until each \npublication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For \nplanning and transition purposes, federal agencies may wish to closely follow the development of these new \npublications by NIST.   \nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback to \nNIST. Many NIST cybersecurity publications, other than the ones noted above, are available at \nhttp://csrc.nist.gov/publications. \nComments on this Publication and the Workshop may be submitted to: \n \nNational Institute of Standards and Technology \nAttn: Applied Cybersecurity Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 2000) Gaithersburg, MD 20899-2000 \nEmail: NSTICworkshop@nist.gov \n \n All comments are subject to release under the Freedom of Information Act (FOIA)."
  },
  {
    "chunk_id": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10_chunk_3",
    "filename": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10.pdf",
    "page_num": 4,
    "text": "NISTIR 8103 \nAPPLYING MEASUREMENT SCIENCE IN THE IDENTITY \n \nECOSYSTEM: WORKSHOP SUMMARY & NEXT STEPS \n \n \nii \nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.IR.8103 \n \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test \nmethods, reference data, proof of concept implementations, and technical analyses to advance the \ndevelopment and productive use of information technology. ITL’s responsibilities include the \ndevelopment of management, administrative, technical, and physical standards and guidelines for \nthe cost-effective security and privacy of other than national security-related information in federal \ninformation systems. \nAbstract \nOn January 12-13, 2016, the Applied Cybersecurity Division (ACD) in the National Institute of \nStandards and Technology (NIST) Information Technology Laboratory (ITL) hosted “Applying \nMeasurement Science in the Identity Ecosystem”—a workshop to discuss the application of \nmeasurement science to digital identity management. This document summarizes the concepts \nand ideas presented at the workshop and serves as a platform to receive feedback on the major \nthemes discussed at that event. \nKeywords \nIdentity; NSTIC; authentication; biometric authentication; biometrics; identity proofing; \nattributes; metadata; identity management; cybersecurity; security; information security. \nDisclaimer \nAny mention of commercial products or reference to commercial organizations is for information \nonly; it does not imply recommendation or endorsement by NIST, nor does it imply that the \nproducts mentioned are necessarily the best available for the purpose. Content was derived from \nworkshop participant discussions captured by note takers and aggregated for the purposes of \nsummarizing the event. Any misrepresentation of comments or concepts is unintentional. \nCorrections or clarifications can be provided through the open comment period. \nAcknowledgements \nThe authors would like to thank Ryan Galluzzo and Walter McLean for their contributions to this \nNISTIR. In addition, we would like to thank panelists Ian Glazer, Kim Little-Sutherland, David \nKelts, Dario Berini, Brent Williams, Julian White, Brett McDowell, Stephanie Schuckers, Vance \nBjorn, Cathy Tilton, Liz Votaw, LaChelle LeVan, Darran Rolls, Gerry Gebel, Ryan Disraeli, and \nRobin Wilton and facilitators Kirk Brafford, Mike Wyatt, Roger Cressey, Kiersten Todt, JR \nReagan, and Colin Soutar, as well as the workshop participants who provided valuable input to \nthis report. Finally, we would like to thank and acknowledge the efforts of those that developed \nthe workshop white papers, to include Elaine Newton, Kevin Mangold, Mike Garris, Colin \nSoutar, Ryan Galluzzo, Jim Fenton, Kat Megas, and Justin Richer."
  },
  {
    "chunk_id": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10_chunk_4",
    "filename": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10.pdf",
    "page_num": 5,
    "text": "NISTIR 8103 \nAPPLYING MEASUREMENT SCIENCE IN THE IDENTITY \n \nECOSYSTEM: WORKSHOP SUMMARY & NEXT STEPS \n \n \niii \nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.IR.8103 \n \n \nTable of Contents \nIntroduction ................................................................................................................... 1 \nWorkshop Summary and Key Takeaways ................................................................... 1 \nOverall Observations ............................................................................................... 2 \nStrength of Identity Proofing .................................................................................... 3 \nStrength of Authentication ....................................................................................... 5 \nAttribute Metadata and Confidence Scoring ............................................................ 7 \nNext Steps ...................................................................................................................... 8"
  },
  {
    "chunk_id": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10_chunk_5",
    "filename": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10.pdf",
    "page_num": 6,
    "text": "NISTIR 8103 \nAPPLYING MEASUREMENT SCIENCE IN THE IDENTITY \n \nECOSYSTEM: WORKSHOP SUMMARY & NEXT STEPS \n \n \n1\nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.IR.8103 \nIntroduction \nOn January 12 and 13, 2016, the Applied Cybersecurity Division (ACD) in the National \nInstitute of Standards and Technology’s (NIST) Information Technology Laboratory \nhosted the “Applying Measurement Science in the Identity Ecosystem” workshop in \nGaithersburg, Maryland.1 The two-day workshop brought together security practitioners, \nidentity solution providers, subject matter experts, and policy makers from across the \npublic and private sectors to discuss the application of metrics and measurement science \nto common identity management practices. \nThe Identity Ecosystem has matured to the point where it is appropriate to undertake the \nwork of building measurement science for application in the market—a critical step in \nfurther aiding expansion and innovation of the Identity Ecosystem. This workshop was \nheld to obtain feedback from stakeholders on the feasibility of, and approaches necessary \nto, measure and compare three disciplines of digital identity management:  \n1. Strength of identity proofing; \n2. Strength of authentication; and  \n3. Attribute metadata and confidence scoring.  \nNIST’s ultimate goal is to establish frameworks that enable objective measurement of \nidentity solutions, so that their ability to mitigate risk is more quantitatively measurable, \nthey can more easily be compared, and, ultimately, measured when combined. NIST \nbelieves making progress in this space will achieve greater alignment of identity solutions \nand technology with risk assessment and management practices. This document provides \na summary of the proceedings to ensure NIST captured stakeholder feedback accurately \nas it executes the next steps in its broad effort towards improved digital identity. \n \nWorkshop Summary and Key Takeaways \nWorkshop attendees represented diverse public and private sector stakeholders. In total, \n224 people attended the event: 67 % from the private sector, 26 % from government \norganizations, and 7 % from academia and non-profits. The workshop included \nmoderated panels and facilitated working sessions for each workshop topic. Throughout \nthe event, participants shared risk management practices, security evaluation approaches, \nand testing processes that they utilized within their organizations. Additionally, \nparticipants identified barriers, evaluated solutions, and specified implementation \nconsiderations to enable greater quantification of strength within each digital identity \nmanagement discipline the workshop covered.  \nThe summary below identifies takeaways and observations from the event. These do not \nnecessarily indicate items that were unanimously supported by those in attendance, but \nrather frequently voiced ideas and input among panelists, audience questions, and the \nbreakout teams during the course of workshop. \n                                                 \n1 Information about the workshop is available at: https://www.nist.gov/itl/nstic/projects-events."
  },
  {
    "chunk_id": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10_chunk_6",
    "filename": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10.pdf",
    "page_num": 7,
    "text": "NISTIR 8103 \nAPPLYING MEASUREMENT SCIENCE IN THE IDENTITY \n \nECOSYSTEM: WORKSHOP SUMMARY & NEXT STEPS \n \n \n2\nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.IR.8103 \nOverall Observations \nNIST heard several recurring themes that transcended the individual workshop topics. \nThese typically involved NIST’s overall effort to apply measurement science to digital \nidentity, the efficacy of measurement within each topic, and how the relationships, or \nlack thereof, between topics could influence a future direction.  \n• Application of Metrology to Digital Identity and Access Management. Many \nparticipants saw value in NIST’s effort to establish measurement science to \ncommunicating the strength, and ability to mitigate risk, of identity management \npractices and solutions. Furthermore, most expressed willingness to remain \nengaged as those efforts develop and mature. Some attendees expressed a view \nthat mandatory metrics and measurements may place an undue burden on \nvendors. Overall, attendees felt the three focal areas of the workshop were \nappropriate to evolve and enhance the Identity Ecosystem, and supported NIST’s \nefforts to produce measurement-based guidance associated with each.  \n \nWhile the idea of producing additional guidance regarding measurements and \nmetrics was generally well received, there was no consensus on any specific \napproach to apply measurement science to digital identity, nor how to develop \nsuch approaches. Likewise, there was no consensus on the metrics that should be \nmeasured and reported within systems and federations. A few participants felt \nscoring digital identity processes and technologies was neither feasible nor \nappropriate. \n \n• Improved Transparency and Standardization. Most participants expressed a \ndesire to see increased transparency and standardization across identity \npractices—particularly in the realm of remote identity proofing practices. Many \nattendees expressed a desire to better understand the way identity solutions \noperate and to overcome a lack of visibility, whether real or perceived, into how \nproprietary scoring works within existing remote identity proofing solutions. \nMany participants also saw a need to better understand the processes that \ncontribute to data they leverage and trust to remotely proof identities. Many felt \nthat standardized processes for evaluating solutions and communicating the \nefficacy of these solutions would provide greater interoperability and trust on a \nbroad scale.  \n \n• Flexibility and Extensibility. Participants broadly encouraged NIST to ensure \nthat any future guidance is both flexible and extensible to support the diverse \nneeds of different communities, trust frameworks, and sectors. Notably, most \nparticipants wished to ensure that any guidance was reflective of the need to \naddress risks to federal agencies—while also acknowledging the needs and \nconcerns of the private sector. This reflected the view that many, if not all, digital \nidentity solutions will come from the private sector vendor community, so NIST"
  },
  {
    "chunk_id": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10_chunk_7",
    "filename": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10.pdf",
    "page_num": 8,
    "text": "NISTIR 8103 \nAPPLYING MEASUREMENT SCIENCE IN THE IDENTITY \n \nECOSYSTEM: WORKSHOP SUMMARY & NEXT STEPS \n \n \n3\nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.IR.8103 \nmust attempt to develop guidance that does not create an environment where \ncross-sector solutions will no longer be viable within the Federal Enterprise. \nMany expressed a strong desire for NIST to craft documentation in a manner that \ncould subsequently be submitted as a work product in open, consensus-based \nstandards development organizations. \n \n• Topic Area Relationships: Participants acknowledged the pre-event whitepapers \nas thoughtful starting points for much of the workshop discussion, but sought \ngreater insight on how the measurement of authenticator strength, remote and in-\nperson identity proofing, and attribute confidence would or could impact each \nother in future NIST deliverables. Many suggested NIST should explore an \noverarching model of identity measurement to help clarify the role of \nmeasurement science in digital identity and the interplay between these, and \npotentially other, components.  \n \n• Existing Work and Fora: The digital identity community is one of constant \ninnovation and many complementary efforts. Participants repeatedly sought to \nensure that NIST recognize and collaborate with existing initiatives focused on \nsimilar outcomes. Participants identified multiple existing efforts as places where \nNIST could leverage synergies to advance the community’s collective interests. \nEfforts mentioned include: \no UK Cabinet Office and the Good Practices Guides (GPGs) : \nhttps://www.gov.uk/government/collections/identity-assurance-enabling-\ntrusted-transactions  \no The Kantara Initiative Identity Assurance Working Group: \nhttps://kantarainitiative.org/confluence/display/idassurance/Home  \no The IETF Vectors of Trust internet draft: https://tools.ietf.org/html/draft-\nricher-vectors-of-trust-00 \no OASIS Trust Elevation Group: https://www.oasis-\nopen.org/committees/tc_home.php?wg_abbrev=trust-el  \no ISO/IEC SC 27 Working Group 5: \nhttp://www.iso.org/iso/iso_technical_committee?commid=45306  \no ISO/IEC SC 37 biometric activities: \nhttp://www.iso.org/iso/home/standards_development/list_of_iso_technical\n_committees/iso_technical_committee.htm?commid=313770  \no FIDO Certification Working Group: https://fidoalliance.org/working-\ngroups/  \no FIDO Biometric Assurance Sub-working Group  \nStrength of Identity Proofing \nStrength of identity proofing was the first topic of the workshop. Participants discussed \nexisting and potential identity proofing methods and ways to measure strength of each"
  },
  {
    "chunk_id": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10_chunk_8",
    "filename": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10.pdf",
    "page_num": 9,
    "text": "NISTIR 8103 \nAPPLYING MEASUREMENT SCIENCE IN THE IDENTITY \n \nECOSYSTEM: WORKSHOP SUMMARY & NEXT STEPS \n \n \n4\nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.IR.8103 \nindividual process, as well as the establishment of a scoring framework to communicate \ncommon results of digital identity proofing for the purposes of risk management. Across \nthe discussion groups, several major themes emerged. \n• Develop a common lexicon. Many participants identified a lack of standardized \nterminology regarding identity proofing processes and functions. For example, \nsome attendees used the term “verification” while others preferred “validation” \nfor the same process. For the purposes of NIST’s work, attendees suggested a \ncommon vocabulary should be developed to help ensure consistency in the \nframework and across communities, and that the taxonomy be aligned to the best \nextent possible with existing schemes.  \n \n• Identify functional components of proofing. Attendees in most sessions came to \nthe conclusion that proofing could be broken down into a set of component \nfunctions or actions that could potentially be evaluated to provide a greater \nunderstanding of the processes and the results associated with verifying a claimed \nidentity. Each component could potentially serve as the basis for a scoring \nstructure. \no Participants suggested additional functional components that could be \nadded to those currently explored in the whitepapers. Specific suggestions \nincluded: ongoing maintenance of an identity (i.e., how a provider \nmanages the identity, updates it, and supports necessary modifications \nwhen needed); fraud and compromise detection; document authentication; \nactivity history of an identity; biometric collection to support the binding \nof proofing to a credential; and processes for binding proofing data to an \nidentity. \n \n• Avoid a single score. Many participants expressed the belief that any scoring of \nthe processes associated with identity proofing should not be aggregated into a \nsingle score. Instead, many felt it more appropriate to provide individual scores \nfor the processes that could be considered and weighted by relying parties (RPs) \nto meet their needs. In some instances, more fine-grained knowledge of the \nprocesses an individual underwent to confirm a claim of identity would be just as \nvaluable as a score. \n \n• Consider existing standards and practices. Several participants referenced UK \nGPG 45 as an example of combining high-level scoring with desired outcomes. \nParticipants discussed the potential to draw lessons from the UK GPGs and apply \nthem to a US based identity proofing framework. \n \n• Define scope of proofing. Participants also discussed the scope of identity \nproofing, specifically that the goal of identity proofing guidelines should be \nscoped to proving a valid identity exists. Proofing should not, for example, \nvalidate an individual’s rights and privilege to obtain specific entitlements."
  },
  {
    "chunk_id": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10_chunk_9",
    "filename": "Advanced Identity Workshop on Applying Measurement Science in the Identity Ecosystem_  Summary and Next Steps_first10.pdf",
    "page_num": 10,
    "text": "NISTIR 8103 \nAPPLYING MEASUREMENT SCIENCE IN THE IDENTITY \n \nECOSYSTEM: WORKSHOP SUMMARY & NEXT STEPS \n \n \n5\nThis publication is available free of charge from: http://dx.doi.org/10.6028/NIST.IR.8103 \nDetermining entitlements and eligibility is an RP decision that goes beyond \nconfirming that and identity is associated with a specific individual. \nStrength of Authentication \nThe second workshop session addressed the strength underlying various authentication \nmethods. The session explored measuring mitigation methods of known vulnerabilities to \nan authentication system as a method to determine an overall score for authenticator \nperformance as well as an overall construct that would enable the assessment and \ncomparison of distinct authentication mechanisms. While the strength of authentication \nwhitepaper identified biometric authentication as a starting point for an overall \nauthentication framework, several of the workshop sessions ended up extensively \ndiscussing the broader concept of evaluating various authenticator technologies. While \nbiometrics was selected first due to its increasing consumer and commercial adoption \nrates, the framework envisioned by NIST would support the evaluation of authentication \nstrength regardless of form or factor, making these broader discussions extremely \nvaluable. Across the groups, several major themes of discussion emerged. \n• Consider user experience—or a poor user experience—as a vulnerability . \nMost participants felt that user experience with a chosen authentication method is \none of the most important factors in selecting technologies that are not only \nsecure, but also likely to be successfully adopted. Many pointed out that the \nlargest driver behind the adoption of mobile biometric solutions is market demand \nand the ease with which users are able to access services. As a result of this ease-\nof-use focus by consumers, many participants noted that security may not be the \nprimary objective of many RPs when instituting authentication solutions. \nTherefore, inclusion of user experience in any evaluation scheme may have a \nbenefit to both security personnel required to assist in risk management and \nmitigation, and to business decision makers. \n \nThis led some participants to suggest incorporating a usability score into the \nframework. Participants also considered the possibility that a poor user experience \ncould be considered a system “vulnerability” and weighted, evaluated, and scored \nmuch as the other components of the score. However, poor user experience should \nnot be the only metric. Rather, the result of poor user experience will be the users \nthemselves trying to exploit workarounds to improve their individual experience \nwith the technology. These workarounds would be considered the vulnerability. \n \n• Consider framework utility to RPs and its long-term applicability. In addition \nto the importance of usability with respect to authentication solutions, many \nidentified a need for any scoring or evaluation framework to be usable as well. \nAttendees indicated that some RPs struggle to balance the need to deliver cutting \nedge solutions to the market with the needs of security and privacy. For a \nmeasurement based framework to have broad adoption it must enable rapid \nevaluation of solutions to allow users to maintain pace with markets and customer \ndemands."
  },
  {
    "chunk_id": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10_chunk_0",
    "filename": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10.pdf",
    "page_num": 1,
    "text": "A111D3\nDfi^bM?\nNAn INST OF STANDARDS & TECH R.I.C.\nA1 11 03089647\nRuder, Brian/An analysis of computer saf\nQC100 .U57 NO.500-25, 1978 C.2 NBS-PUB-C\nNCE & TECHNOLOGY:\nAN ANALYSIS OF\nCOMPUTER SECURITY\nSAFEGUARDS FOR\nDETECTING AND\nPREVENTING INTENTIONAL\nCOMPUTER MISUSE\nNBS Special\nPublication 500-25\nU.S. DEPARTMENT OF COMMERCE\nNational Bureau\nof Standards"
  },
  {
    "chunk_id": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10_chunk_1",
    "filename": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10.pdf",
    "page_num": 2,
    "text": "NATIONAL BUREAU OF STANDARDS\nThe National Bureau of Standards^ was established by an\nact of Congress March\n3,\n1901. The Bureau's overall goal\nis to\nstrengthen and advance the Nation's science and technology and facilitate their effective application for public benefit. To this\nend, the Bureau conducts research and provides:\n(1) a basis for the Nation's physical measurement system,\n(2)\nscientific and\ntechnological services for industry and government,\n(3) a technical basis for equity in trade, and (4) technical services to pro-\nmote public safety. The. Bureau consists of the Institute for Basic Standards, the Institute for Materials Research, the Institute\nfor Applied Technology, the Institute for Computer Sciences and Technology, the Office for Information Programs, and the\nOffice of Experimental Technology Incentives Program.\nTHE INSTITUTE FOR BASIC STANDARDS provides the central basis within the United States of a complete and consist-\nent system of physical measurement; coordinates that system with measurement systems of other nations; and furnishes essen-\ntial services leading to accurate and uniform physical measurements throughout the Nation's\nscientific community,\nindustry,\nand commerce. The Institute consists of the Office of Measurement Services, and the following center and divisions:\nApplied Mathematics — Electricity — Mechanics — Heat — Optical Physics — Center for Radiation Research — Lab-\noratory Astrophysics ° — Cryogenics' — Electromagnetics^ — Time and Frequency'.\nTHE INSTITUTE FOR MATERIALS RESEARCH conducts\nmaterials research leading\nto improved methods of measure-\nment, standards, and data on the properties of well-characterized materials needed by\nindustry, commerce, educational\ninsti-\ntutions, and Government; provides advisory and research services to other Government agencies; and develops, produces, and\ndistributes standard reference materials. The Institute consists of the Office of Standard Reference Materials, the Office of Air\nand Water Measurement, and the following divisions:\nAnalytical Chemistry — Polymers — Metallurgy — Inorganic Materials — Reactor Radiation — Physical Chemistry.\nTHE INSTITUTE FOR APPLIED TECHNOLOGY provides technical services developing and promoting the use of avaU-\nable technology; cooperates with public and private organizations in developing technological standards, codes, and test meth-\nods; and provides technical advice services, and information to Government agencies and the public. The Institute consists of\nthe following divisions and centers:\nStandards Application and Analysis — Electronic Technology — Center for Consumer Product Technology: Product\nSystems Analysis; Product Engineering — Center for Building Technology:\nStructures,\nMaterials, and\nSafety;\nBuilding\nEnvironment; Technical Evaluation and Application — Center for Fire Research: Fire Science; Fire Safety Engineering.\nTHE INSTITUTE FOR COMPUTER SCIENCES AND TECHNOLOGY conducts research and provides technical\nservices\ndesigned to aid Government agencies in improving cost effectiveness\nin\nthe conduct of their programs through the\nselection,\nacquisition, and effective utilization of automatic data processing equipment; and serves as the principal focus wthin the exec-\nutive branch for the development of Federal standards for automatic data processing equipment, techniques, and computer\nlanguages. The Institute consist of the following divisions:\nComputer Services — Systems and Software — Computer Systems Engineering — Information Technology.\nTHE OFFICE OF EXPERIMENTAL TECHNOLOGY INCENTIVES PROGRAM seeks to affect public policy and process\nto facilitate technological change\nin the private sector by examining and experimenting with Government policies and prac-\ntices in order to identify and remove Government-related barriers and\nto correct inherent market imperfections\nthat impede\nthe innovation process.\nTHE OFFICE FOR INFORMATION PROGRAMS promotes optimum dissemination and accessibility of scientific informa-\ntion generated within NBS; promotes the development of the"
  },
  {
    "chunk_id": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10_chunk_2",
    "filename": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10.pdf",
    "page_num": 2,
    "text": " — Information Technology.\nTHE OFFICE OF EXPERIMENTAL TECHNOLOGY INCENTIVES PROGRAM seeks to affect public policy and process\nto facilitate technological change\nin the private sector by examining and experimenting with Government policies and prac-\ntices in order to identify and remove Government-related barriers and\nto correct inherent market imperfections\nthat impede\nthe innovation process.\nTHE OFFICE FOR INFORMATION PROGRAMS promotes optimum dissemination and accessibility of scientific informa-\ntion generated within NBS; promotes the development of the National Standard Reference Data System and a system of in-\nformation analysis centers dealing with the broader aspects of the National Measurement System; provides appropriate services\nto ensure that the NBS staff has optimum accessibility to the\nscientific information of the world. The\nOffice consists of the\nfollowing organizational units:\nOffice of Standard Reference Data — Office of Information Activities — Office of Technical Publications — Library —\nOffice of International Standards — Office of International Relations.\n' Headquarters and Laboratories at Gaithersburg, Maryland,\nunless\notherwise noted; mailing address Washington, D.C. 20234.\n^ Located at Boulder, Colorado 80302."
  },
  {
    "chunk_id": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10_chunk_3",
    "filename": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10.pdf",
    "page_num": 3,
    "text": "• BATIONAL BTJRKA'\nV PF BTAKDAPI\nLIBRA\nr'\nCOMPUTER SCIENCE & TECHNOLOGY:\n^\ni(f m\nAn Analysis of Computer Security Safeguards\n^\nfor Detecting and Preventing Intentional\n7\nComputer Misuse\n^^<^^g\n^^ix^c^^.w\nBrian Ruder and J.D. Madden\nStanford Research Institute\nMenlo Park, California 94025\nRobert P. Blanc, Editor\nInstitute for Computer Sciences and Technology\nNational Bureau of Standards\nWashington, D.C. 20234\nU.S. DEPARTMENT OF COMMERCE, Juanita M. Kreps, Secretary\nDr. Sidney Harman, Under Secretary\nJordan\nJ. Baruch, Assistant Secretary for Science and Technology\nU\nS -NATIONAL BUREAU OF STANDARDS, Ernest Ambler, Acting Director\nIssued January 1978"
  },
  {
    "chunk_id": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10_chunk_4",
    "filename": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10.pdf",
    "page_num": 4,
    "text": "Reports on Computer Science and Technology\nThe National Bureau of Standards has a special responsibility within the Federal\nGovernment for computer science and technology activities. The programs of the\nNBS Institute for Computer Sciences and Technology are designed to provide ADP\nstandards, guidelines, and technical advisory services to improve the effectiveness of\ncomputer utilization in the Federal sector, and to perform appropriate research and\ndevelopment efforts as foundation for such activities and programs. This publication\nseries will report these NBS efforts to the Federal computer community as well as to\ninterested specialists in the academic and private sectors. Those wishing to receive\nnotices of publications in this series should complete and return the form at the end\nof this publication.\nNational Bureau of Standards Special Publication 500-25\nNat. Bur. Stand.\n(U.S.), Spec. Publ. 500-25, 80. pages (Jan.\n1978)\nCODEN: XNBSAV\nLibrary of Congress Cataloging in Publication Data\nRuder, Brian.\nAn analysis of computer safeguards for detecting and preventing\nintentional computer misuse.\n(Computer science & technology) (NBS special publication ; 500-25)\nSupt. of Docs, no.:\nCI 3. 10: 500-25\n1. Computer crimes.\n2. Computers—Access control.\n3. Electronic\ndata processing departments—Security measures.\nI. Madden, J. D.,\njoint author.\nII. Title.\nIII. Series. IV. Series: United States. National\nBureau of Standards.\nSpecial publication\n; 500-25.\nQC100.U57 no. 500-25 [HV6773] 602Ms [364. r62] 77-25368\nU.S. GOVERNMENT PRINTING OFFICE\nWASHINGTON:\n1978)\nFor sale by the Superintendent of Documents, U.S. Government Printing Office\nWashington, D.C. 20402. Price $2.40—Stock No. 003-003-01871-6"
  },
  {
    "chunk_id": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10_chunk_5",
    "filename": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10.pdf",
    "page_num": 5,
    "text": "PREFACE\nThe work reported here was performed\nat Stanford Research\nInstitute\n(SRI)\nfor the National Bureau\nof\nStandards\n(NBS)\n.\nThe\nobjectives\nof\nthe study are\nto:\n(1)\nDevelop\na working definition of intentional computer\nmisuse and\na taxonomy\nto characterize\nthe different\ntypes\nof intentional computer misuse.\n(2)\nDevelop\na ranked\nlist\nof\nspecific detection mechanisms.\n(3)\nDevelop\na ranked list\nof specific prevention mechanisms.\nThe detection and prevention mechanisms were\nto be developed as\na\nresult\nof analysis\nof computer misuse case\nfiles,\nmost\nof which are\nmaintained by Mr.\nDonn\nB.\nParker of\nSRI.\nRobert\nP.\nBlanc,\nEditor\nStaff Assistant\nfor Computer\nUtilization Programs\nInstitute\nfor Computer Sciences\nand Technology\niii"
  },
  {
    "chunk_id": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10_chunk_6",
    "filename": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10.pdf",
    "page_num": 7,
    "text": "TABLE OF CONTENTS\nPage\nPreface\n.\nm\nAbstract\n=\n=\n1\nI.\nIntroduction-'\n•\n=\n2\nIIo\nTaxonomy of Vulnerability to Intentional Misuse\n3\nIIIo\nDefinition of Intentional Computer Misuse\n4\nIVo\nSafeguard Model\n=\n4\nV.\nComputer Security Program Requirements-\n--\n9\nVIo\nSafeguard Analysis and Rankings\n•\n»-\n11\nVII. Summary and Conclusions\n20\nAppendix A.\nVulnerability Category Definitions\nA-1\nAppendix Bo\nFormatted Safeguard Descriptions\nB-1\nILLUSTRATIONS\nFigure\n1«\nA Taxonomy for Vulnerabilities of Intentional\nComputer Misuse\n5\nFigure 2.\nA Model for Categorizing Computer Safeguards\nAccording to Responsibile Organizational\nUnits\n=\n6\nTABLES\n1.\nConsolidated List of Safeguards---\n14\n2.\nRanked Detection Safeguards\n17\n3.\nRanked Prevention Safeguards--\n18\n4.\nConsensus Ranking:\nDetection Safeguards\n19\n5.\nConsensus Ranking:\nPrevention Safeguards\n^9\nV"
  },
  {
    "chunk_id": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10_chunk_7",
    "filename": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10.pdf",
    "page_num": 8,
    "text": "I"
  },
  {
    "chunk_id": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10_chunk_8",
    "filename": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10.pdf",
    "page_num": 9,
    "text": "AN ANALYSIS OF COMPUTER SECURITY SAFEGUARDS FOR\nDETECTING AND PREVENTING INTENTIONAL COMPUTER MISUSE\nBrian Ruder\nJ.\nD.\nMadden\nStanford Research Institute\nMenlo Park,\nCalifornia\n94025\nABSTRACT\nStanford Research Institute\n(SRI)\nhas an extensive\nfile\nof actual\ncomputer misuse\ncases.\nThe National Bureau of\nStandards asked\nSRI\nto\nuse\nthese caaes\nas\na foundation to develop ranked lists\nof computer\nsafeguards\nthat would have prevented or detected the recorded intentional\nmisuses.\nThis report provides\na working definition of intentional computer\nmisuse,\na construction of\na vulnerability taxonomy of intentional\ncomputer misuse,\na list\nof\n88 computer safeguards,\nand\na model for\nclassifying\nthe safeguards.\nIn addition,\nthere are lists ranking\nprevention and detection safeguards, with an explanation\nof\nthe method\nof approach used\nto arrive\nat\nthe\nlists.\nThe report\nshould provide\nthe computer security specialist with\nsufficient information\nto start or enhance\na computer safeguard program.\nKEY WORDS\nComputer security;\ncomputer misuse;\ncomputer safeguards;\ncomputer\nsecurity model;\ncomputer crime;\ncomputer\nfraud;\nprivacy.\n1"
  },
  {
    "chunk_id": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10_chunk_9",
    "filename": "An Analysis of Computer Security Safeguards for Detecting and Preventing Intentional Computer Misuse_first10.pdf",
    "page_num": 10,
    "text": "I.\nINTRODUCTION\nA primary objective of\nthis report\nis\nto identify computer safeguards\nthat would have been useful\nin detecting and preventing actual cases\nof computer misuse.\nSection VI contains safeguard rankings based on\ncases\nof past intentional computer misuse.\nThese cases\nspan the spectrum\nof computer misuse,\nbut\nthe number\nof\ncases\nthat\nfall\ninto each vulner-\nability category probably do not reflect any one specific computer\nenvironment.\nGenerally speaking,\nthe highest ranking safeguards should\nbe best\nin most environments,\nbut\nthe ranking process\nis\nsomewhat\nsubjective due\nto\nthe nature\nof\nthe cases and degree of detail specified\nin\nthe safeguard description.\nTherefore,\nthe rankings\nshould not be\nconsidered absolute.\nComputer specialists should consider all\ntools\nas\nthey develop their computer protection plan.\nA set of tools and\na\ndescription\nof\ntheir purpose and application\nis provided in Appendix B.\nThis report contains\nthe results\nof six work efforts,\neach of which\nis briefly described below.\nThe first effort involved developing a taxonomy of computer\nvulnerability\nto intentional computer misuse.\nThe computer vulnerability\ntaxonomy forms\nthe foundation for the definition of intentional computer\nmisuse\nas well as\nthe foundation for categorizing past cases\nof computer\nmisuse.\nSection\nII\nof\nthis report contains\nthis\ntaxonomy.\nThe second effort was\nto develop\na working definition of intentional\ncomputer misuse.\nThe persons known\nto be studying the area of computer\nmisuse throughout\nthe country were contacted\nto determine their current\ndefinitions relating\nto computer abuse\nor computer misuse.\nThe resulting\ndefinition of intentional computer misuse and\na discussion of how the\ndefinition was arrived\nat are addressed in Section III\nof\nthis report.\nThe third effort was\nto review the case\nfile\nof computer misuses\nand distribute cases\ninto appropriate vulnerability categories.\nEach\ncase was placed\nin only one vulnerability category even though three or\nfour misuses may have been identified\nin the case writeup.\nEach case\nwas placed\nin the category corresponding\nto\nthe first misuse identified\nin the case writeup.\nThe fourth effort was\nto review case files\nto identify the prevention\nand detection safeguard mechanisms\nin each case\nthat would have mitigated\nthe misuses\nin that\ncase.\nThe safeguards from a previous NSF studyl\nas well\nas those gathered from other relevant source material were used\nas\na base and were supplemented by\nthe authors'\nexperiences and\nideas.\n\"Computer System Integrity Research Program,\" National Science\nFoundation Grant DCR74-23774.\n2"
  },
  {
    "chunk_id": "An Introduction to Information Security_first10_chunk_0",
    "filename": "An Introduction to Information Security_first10.pdf",
    "page_num": 1,
    "text": "NIST Special Publication 800-12 \nRevision 1 \nAn Introduction to Information Security \n \nMichael Nieles \nKelley Dempsey \nVictoria Yan Pillitteri \n \n \n \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-12r1 \n \n \n \nC  O  M  P  U  T  E  R      S  E  C  U  R  I  T  Y"
  },
  {
    "chunk_id": "An Introduction to Information Security_first10_chunk_1",
    "filename": "An Introduction to Information Security_first10.pdf",
    "page_num": 2,
    "text": "NIST Special Publication 800-12 \nRevision 1 \nAn Introduction to Information Security \n  \n \nMichael Nieles \nKelley Dempsey \nVictoria Yan Pillitteri \nComputer Security Division \nInformation Technology Laboratory \n \n \n \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-12r1 \n \n \n \nJune 2017 \n \n \n \n \n \nU.S. Department of Commerce \nWilbur L. Ross, Jr., Secretary \n \nNational Institute of Standards and Technology  \nKent Rochford, Acting NIST Director and Under Secretary of Commerce for Standards and Technology"
  },
  {
    "chunk_id": "An Introduction to Information Security_first10_chunk_2",
    "filename": "An Introduction to Information Security_first10.pdf",
    "page_num": 3,
    "text": "Authority \nThis publication has been developed by NIST in accordance with its statutory responsibilities under the \nFederal Information Security Modernization Act (FISMA) of 2014, 44 U.S.C. § 3551 et seq., Public Law \n(P.L.) 113-283. NIST is responsible for developing information security standards and guidelines, including \nminimum requirements for federal systems, but such standards and guidelines shall not apply to national \nsecurity systems without the express approval of appropriate federal officials exercising policy authority \nover such systems. This guideline is consistent with the requirements of the Office of Management and \nBudget (OMB) Circular A-130. \nNothing in this publication should be taken to contradict the standards and guidelines made mandatory and \nbinding on federal agencies by the Secretary of Commerce under statutory authority. Nor should these \nguidelines be interpreted as altering or superseding the existing authorities of the Secretary of Commerce, \nDirector of the OMB, or any other federal official.  This publication may be used by nongovernmental \norganizations on a voluntary basis and is not subject to copyright in the United States. Attribution would, \nhowever, be appreciated by NIST.   \nNational Institute of Standards and Technology Special Publication 800-12 Revision 1 \nNatl. Inst. Stand. Technol. Spec. Publ. 800-12 Rev. 1, 101 pages (June 2017) \nCODEN: NSPUE2 \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-12r1 \nCertain commercial entities, equipment, or materials may be identified in this document in order to describe an \nexperimental procedure or concept adequately. Such identification is not intended to imply recommendation or \nendorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best \navailable for the purpose.  \nThere may be references in this publication to other publications currently under development by NIST in accordance \nwith its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, \nmay be used by federal agencies even before the completion of such companion publications. Thus, until each \npublication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For \nplanning and transition purposes, federal agencies may wish to closely follow the development of these new \npublications by NIST.   \nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback to \nNIST. Many NIST cybersecurity publications, other than the ones noted above, are available at \nhttp://csrc.nist.gov/publications. \n \nComments on this publication may be submitted to: \nNational Institute of Standards and Technology \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 \nEmail: sec-cert@nist.gov  \nAll comments are subject to release under the Freedom of Information Act (FOIA)."
  },
  {
    "chunk_id": "An Introduction to Information Security_first10_chunk_3",
    "filename": "An Introduction to Information Security_first10.pdf",
    "page_num": 4,
    "text": "NIST SP 800-12 REV. 1  \n \n \nAN INTRODUCTION TO INFORMATION SECURITY \n \n \n \nii \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-12r1 \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test \nmethods, reference data, proof of concept implementations, and technical analyses to advance the \ndevelopment and productive use of information technology. ITL’s responsibilities include the \ndevelopment of management, administrative, technical, and physical standards and guidelines for \nthe cost-effective security and privacy of other than national security-related information in federal \nsystems. The Special Publication 800-series reports on ITL’s research, guidelines, and outreach \nefforts in systems security as well as its collaborative activities with industry, government, and \nacademic organizations. \nAbstract \nOrganizations rely heavily on the use of information technology (IT) products and services to run \ntheir day-to-day activities. Ensuring the security of these products and services is of the utmost \nimportance for the success of the organization. This publication introduces the information \nsecurity principles that organizations may leverage to understand the information security needs \nof their respective systems.  \n \nKeywords \n \nassurance; computer security; information security; introduction; risk management; security \ncontrols; security requirements"
  },
  {
    "chunk_id": "An Introduction to Information Security_first10_chunk_4",
    "filename": "An Introduction to Information Security_first10.pdf",
    "page_num": 5,
    "text": "NIST SP 800-12 REV. 1  \n \n \nAN INTRODUCTION TO INFORMATION SECURITY \n \n \n \niii \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-12r1 \nAcknowledgements \nThe authors would like to thank everyone who took the time to review and make comments on \nthe draft of this publication, specifically Celia Paulsen, Ned Goren, Isabel Van Wyk, and Rathini \nVijayaverl of the National Institute of Standards and Technology (NIST). The authors would also \nlike to acknowledge the original authors, Barbara Guttman and Edward A. Roback, as well as all \nthose individuals who contributed to the original version of this publication."
  },
  {
    "chunk_id": "An Introduction to Information Security_first10_chunk_5",
    "filename": "An Introduction to Information Security_first10.pdf",
    "page_num": 6,
    "text": "NIST SP 800-12 REV. 1  \n \n \nAN INTRODUCTION TO INFORMATION SECURITY \n \n \n \niv \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-12r1 \nTable of Contents \n1 \nIntroduction ............................................................................................................ 1 \n1.1 Purpose ............................................................................................................. 1 \n1.2 Intended Audience ............................................................................................ 1 \n1.3 Organization ...................................................................................................... 1 \n1.4 Important Terminology ...................................................................................... 2 \n1.5 Legal Foundation for Federal Information Security Programs ........................... 3 \n1.6 Related NIST Publications ................................................................................ 4 \n2 \nElements of Information Security ......................................................................... 7 \n2.1 Information security supports the mission of the organization ........................... 7 \n2.2 Information security is an integral element of sound management ................... 8 \n2.3 Information security protections are implemented so as to be commensurate \nwith risk ................................................................................................................... 8 \n2.4 Information security roles and responsibilities are made explicit ....................... 9 \n2.5 Information security responsibilities for system owners go beyond their own \norganization ............................................................................................................ 9 \n2.6 Information security requires a comprehensive and integrated approach ......... 9 \n2.6.1 Interdependencies of security controls ............................................... 10 \n2.6.2 Other interdependencies .................................................................... 10 \n2.7 Information security is assessed and monitored regularly ............................... 10 \n2.8 Information security is constrained by societal and cultural factors ................. 11 \n3 \nRoles and Responsibilities.................................................................................. 13 \n3.1 Risk Executive Function (Senior Management) .............................................. 13 \n3.2 Chief Executive Officer (CEO) ......................................................................... 13 \n3.3 Chief Information Officer (CIO) ........................................................................ 14 \n3.4 Information Owner/Steward ............................................................................ 14 \n3.5 Senior Agency Information Security Officer (SAISO) ...................................... 14 \n3.6 Authorizing Official (AO) .................................................................................. 15 \n3.7 Authorizing Official Designated Representative .............................................. 15 \n3.8 Senior Agency Official for Privacy (SAOP) ...................................................... 15 \n3.9 Common Control Provider ............................................................................... 15 \n3.10 System Owner ............................................................................................... 16 \n3.11 System Security Officer (SSO) ...................................................................... 16"
  },
  {
    "chunk_id": "An Introduction to Information Security_first10_chunk_6",
    "filename": "An Introduction to Information Security_first10.pdf",
    "page_num": 7,
    "text": "NIST SP 800-12 REV. 1  \n \n \nAN INTRODUCTION TO INFORMATION SECURITY \n \n \n \nv \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-12r1 \n3.12 Information Security Architect ....................................................................... 16 \n3.13 System Security Engineer (SSE) .................................................................. 17 \n3.14 Security Control Assessor ............................................................................. 17 \n3.15 System Administrator .................................................................................... 17 \n3.16 User .............................................................................................................. 17 \n3.17 Supporting Roles ........................................................................................... 18 \n4 \nThreats and Vulnerabilities: A Brief Overview ................................................... 20 \n4.1 Examples of Adversarial Threat Sources and Events ..................................... 20 \n4.1.1 Fraud and Theft .................................................................................. 21 \n4.1.2 Insider Threat ..................................................................................... 22 \n4.1.3 Malicious Hacker ................................................................................ 22 \n4.1.4 Malicious Code ................................................................................... 23 \n4.2 Examples of Non-Adversarial Threat Sources and Events ............................. 24 \n4.2.1 Errors and Omissions ......................................................................... 24 \n4.2.2 Loss of Physical and Infrastructure Support ....................................... 24 \n4.2.3 Impacts to Personal Privacy of Information Sharing ........................... 25 \n5 \nInformation Security Policy ................................................................................. 26 \n5.1 Standards, Guidelines, and Procedures .......................................................... 26 \n5.2 Program Policy ................................................................................................ 27 \n5.2.1 Basic Components of Program Policy ................................................ 27 \n5.3 Issue-Specific Policy ....................................................................................... 28 \n5.3.1 Example Topics for Issue-Specific Policy ........................................... 28 \n5.3.2 Basic Components of Issue-Specific Policy ........................................ 29 \n5.4 System-Specific Policy .................................................................................... 30 \n5.4.1 Security Objectives ............................................................................. 31 \n5.4.2 Operational Security Rules ................................................................. 31 \n5.4.3 System-Specific Policy Implementation .............................................. 32 \n5.5 Interdependencies ........................................................................................... 32 \n5.6 Cost Considerations ........................................................................................ 33 \n6 \nInformation Security Risk Management ............................................................. 34 \n6.1 Categorize ....................................................................................................... 36 \n6.2 Select .............................................................................................................. 36"
  },
  {
    "chunk_id": "An Introduction to Information Security_first10_chunk_7",
    "filename": "An Introduction to Information Security_first10.pdf",
    "page_num": 8,
    "text": "NIST SP 800-12 REV. 1  \n \n \nAN INTRODUCTION TO INFORMATION SECURITY \n \n \n \nvi \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-12r1 \n6.3 Implement ....................................................................................................... 37 \n6.4 Assess ............................................................................................................ 37 \n6.5 Authorize ......................................................................................................... 37 \n6.6 Monitor ............................................................................................................ 37 \n7 \nAssurance ............................................................................................................. 38 \n7.1 Authorization ................................................................................................... 38 \n7.1.1 Authorization and Assurance .............................................................. 39 \n7.1.2 Authorization of Products to Operate in Similar Situation ................... 39 \n7.2 Security Engineering ....................................................................................... 39 \n7.2.1 Planning and Assurance ..................................................................... 39 \n7.2.2 Design and Implementation Assurance .............................................. 39 \n7.3 Operational Assurance .................................................................................... 41 \n7.3.1 Security and Privacy Control Assessments ........................................ 42 \n7.3.2 Audit Methods and Tools .................................................................... 42 \n7.3.3 Monitoring Methods and Tools ........................................................... 44 \n7.4 Interdependencies ........................................................................................... 46 \n7.5 Cost Considerations ........................................................................................ 46 \n8 \nSecurity Considerations in System Support and Operations .......................... 47 \n8.1 User Support ................................................................................................... 47 \n8.2 Software Support ............................................................................................ 48 \n8.3 Configuration Management ............................................................................. 48 \n8.4 Backups .......................................................................................................... 49 \n8.5 Media Controls ................................................................................................ 49 \n8.6 Documentation ................................................................................................ 49 \n8.7 Maintenance .................................................................................................... 50 \n8.8 Interdependencies ........................................................................................... 50 \n8.9 Cost Considerations ........................................................................................ 51 \n9 \nCryptography........................................................................................................ 52 \n9.1 Uses of Cryptography ..................................................................................... 52 \n9.1.1 Data Encryption .................................................................................. 52 \n9.1.2 Integrity ............................................................................................... 53 \n9.1.3 Electronic Signatures .......................................................................... 53"
  },
  {
    "chunk_id": "An Introduction to Information Security_first10_chunk_8",
    "filename": "An Introduction to Information Security_first10.pdf",
    "page_num": 9,
    "text": "NIST SP 800-12 REV. 1  \n \n \nAN INTRODUCTION TO INFORMATION SECURITY \n \n \n \nvii \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-12r1 \n9.1.4 User Authentication ............................................................................ 54 \n9.2 Implementation Issues .................................................................................... 54 \n9.2.1 Selecting Design and Implementation Standards ............................... 55 \n9.2.2 Deciding between Software, Hardware, or Firmware Implementations ..  \n \n ........................................................................................................... 55 \n9.2.3 Managing Keys ................................................................................... 55 \n9.2.4 Security of Cryptographic Modules ..................................................... 56 \n9.2.5 Applying Cryptography to Networks ................................................... 56 \n9.2.6 Complying with Export Rules .............................................................. 57 \n9.3 Interdependencies ........................................................................................... 57 \n9.4 Cost Considerations ........................................................................................ 58 \n9.4.1 Direct Costs ........................................................................................ 58 \n9.4.2 Indirect Costs ..................................................................................... 58 \n10 Control Families ................................................................................................... 59 \n10.1 Access Control (AC) ...................................................................................... 59 \n10.2 Awareness and Training (AT) ........................................................................ 59 \n10.3 Audit and Accountability (AU) ........................................................................ 60 \n10.4 Assessment, Authorization, and Monitoring (CA) .......................................... 60 \n10.5 Configuration Management (CM) .................................................................. 61 \n10.6 Contingency Planning (CP) ........................................................................... 61 \n10.7 Identification and Authentication (IA) ............................................................. 62 \n10.8 Individual Participation (IP) ............................................................................ 63 \n10.9 Incident Response (IR) ................................................................................. 64 \n10.10 Maintenance (MA) ....................................................................................... 64 \n10.11 Media Protection (MP) ................................................................................ 65 \n10.12 Privacy Authorization (PA) .......................................................................... 65 \n10.13 Physical and Environmental Protection (PE) ............................................... 66 \n10.14 Planning (PL) .............................................................................................. 67 \n10.15 Program Management (PM) ........................................................................ 67 \n10.16 Personnel Security (PS) .............................................................................. 68 \n10.17 Risk Assessment (RA) ................................................................................ 68 \n10.18 System and Services Acquisition (SA) ........................................................ 69 \n10.19 System and Communications Protection (SC) ............................................ 69"
  },
  {
    "chunk_id": "An Introduction to Information Security_first10_chunk_9",
    "filename": "An Introduction to Information Security_first10.pdf",
    "page_num": 10,
    "text": "NIST SP 800-12 REV. 1  \n \n \nAN INTRODUCTION TO INFORMATION SECURITY \n \n \n \nviii \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-12r1 \n10.20 System and Information Integrity (SI) .......................................................... 70 \n \nList of Appendices \n References .......................................................................................... 71 \n Glossary .............................................................................................. 76 \n Acronyms and Abbreviations ............................................................ 88 \n \nList of Figures \nFigure 1 - Risk Management Framework (RMF) Overview ........................................... 36"
  },
  {
    "chunk_id": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10_chunk_0",
    "filename": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10.pdf",
    "page_num": 1,
    "text": "NIST Cybersecurity White Paper \nNIST CSWP 46 \nAnalyzing Collusion Threats in the \nSemiconductor Supply Chain \nSanjay (Jay) Rekhi \nKostas Amberiadis \nComputer Security \nInformation Technology Laboratory \nAbir Ahsan Akib \nAnkur Srivastava \nElectrical and Computer Engineering \nUniversity of Maryland, College Park \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.CSWP.46 \nJune 30, 2025"
  },
  {
    "chunk_id": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10_chunk_1",
    "filename": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10.pdf",
    "page_num": 2,
    "text": "NIST CSWP 46  \n \nAnalyzing Collusion Threats in the \nJune 30, 2025 \n \nSemiconductor Supply Chain \n \n \nCertain equipment, instruments, software, or materials, commercial or non-commercial, are identified in this \npaper in order to specify the experimental procedure adequately. Such identification does not imply \nrecommendation or endorsement of any product or service by NIST, nor does it imply that the materials or \nequipment identified are necessarily the best available for the purpose. \nNIST Technical Series Policies \nCopyright, Use, and Licensing Statements \nNIST Technical Series Publication Identifier Syntax \nPublication History \nApproved by the NIST Editorial Review Board on 2025-01-30 \nHow to Cite this NIST Technical Series Publication:  \nRekhi S, Amberiadis K, Akib AA, Srivastava A (2025) Analyzing Collusion Threats in the Semiconductor Supply Chain. \n(National Institute of Standards and Technology, Gaithersburg, MD), NIST Cybersecurity White Paper (CSWP) NIST \nCSWP 46. https://doi.org/10.6028/NIST.CSWP.46 \nAuthor ORCID iDs \nSanjay (Jay) Rekhi: 0009-0008-8711-4030 \nKostas Amberiadis: 0009-0000-7771-5002 \nAbir Ahsan Akib: 0000-0002-1455-6662 \nAnkur Srivastava: 0000-0002-5445-904X \nContact Information \nhwsec@nist.gov \n \nNational Institute of Standards and Technology \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 \nAdditional Information \nAdditional information about this publication is available at https://csrc.nist.gov/publications/cswp, including \nrelated content, potential updates, and document history.  \nAll comments are subject to release under the Freedom of Information Act (FOIA)."
  },
  {
    "chunk_id": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10_chunk_2",
    "filename": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10.pdf",
    "page_num": 3,
    "text": "NIST CSWP 46  \n \nAnalyzing Collusion Threats in the \nJune 30, 2025 \n \nSemiconductor Supply Chain \n \ni \nAbstract \nThis work proposes a framework for analyzing threats related to the semiconductor supply \nchain. The framework introduces a metric that quantifies the severity of different threats \nsubjected to a collusion of adversaries from different stages of the supply chain. Two different \ncase studies are provided to describe the real-life application of the framework. The metrics \nand analysis aim to guide security efforts and optimize the trade-offs of hardware security and \ncosts. \nKeywords \ncollusion; security metrics; supply chain life cycle; supply chain security."
  },
  {
    "chunk_id": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10_chunk_3",
    "filename": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10.pdf",
    "page_num": 4,
    "text": "NIST CSWP 46  \n \nAnalyzing Collusion Threats in the \nJune 30, 2025 \n \nSemiconductor Supply Chain \n \nii \nTable of Contents \n1. Introduction ...................................................................................................................................1 \n2. Stages of Semiconductor Supply Chain Stages .................................................................................3 \n3. Framework for Supply Chain Threat Analysis...................................................................................5 \n4. Case Study .....................................................................................................................................8 \n5. Conclusion and Future Work ......................................................................................................... 12 \nReferences ....................................................................................................................................... 13 \nList of Figures \nFig. 1. Security challenges in the semiconductor supply chain ..............................................................2 \nFig. 2. Methodology for supply chain threat analysis ...........................................................................5 \nFig. 3. Threat severity levels for colluding adversaries in the context of hardware Trojan insertion ......6 \nFig. 4. Threat severity levels for colluding adversaries in context of logic obfuscation ........................ 10"
  },
  {
    "chunk_id": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10_chunk_4",
    "filename": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10.pdf",
    "page_num": 5,
    "text": "NIST CSWP 46  \n \nAnalyzing Collusion Threats in the \nJune 30, 2025 \n \nSemiconductor Supply Chain \n \n1 \n1. Introduction  \nThere are numerous security challenges in the semiconductor supply chain. As most chip design \ncompanies have become fabless, they rely on offshore foundries for fabrication. This is \nespecially true for the most advanced technology nodes, and the semiconductor supply shock \nin 2021 has manifested these supply chain security issues. In addition to availability uncertainty, \nthere are many more nuanced security risks in the current semiconductor supply chain, such as \nIP theft, counterfeiting, Trojan insertion, and reverse engineering.  \nIn order to counteract these security risks, many types of solutions have been proposed, \nranging from design to test phases of the supply chain. Numerous government-funded research \nprograms have been established to develop countermeasures, such as the Defense Advanced \nResearch Projects Agency (DARPA) Automated Implementation of Secure Silicon (AISS) program \n[1], the DARPA Structured Array Hardware for Automatically Realized Applications (SAHARA) \nprogram [2], the Naval Surface Warfare Center (NSWC) Crane State-of-the-Art Heterogeneous \nIntegration Prototype (SHIP) program [3], the Air Force Research Laboratory (AFRL) Locked \nElectronics for Assured Design (LEAD) program [4], and the AFRL Aether Spy program [5], just to \nname a few, as addressing these security issues is crucial to national security. Dealing with such \nserious challenges necessitates directing security countermeasure initiatives in stages where \nthe severity of the threat can be best diminished.  \nSupply chain threat analysis is an essential component of security research. The goals of such \nanalysis are to 1) identify the different threats and related vulnerabilities associated with \nintegrated circuits, 2) analyze how severe the threats become at different stages of the supply \nchain, and 3) quantify the severity of threats due to collusion among adversaries. The first thing \nto acknowledge before beginning any such analysis is that, while there are many threats and \nrelated vulnerabilities, not all of them can be exploited at every stage in the semiconductor \nsupply chain. Threats vary in severity depending on the stage of supply chain.  \nFor example, the risk of side-channel analysis is more common in chip use scenarios, whereas \nthe risk of a hardware Trojan is more common in the early stages of design and manufacturing, \nas shown in Fig. 1."
  },
  {
    "chunk_id": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10_chunk_5",
    "filename": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10.pdf",
    "page_num": 6,
    "text": "NIST CSWP 46  \n \nAnalyzing Collusion Threats in the \nJune 30, 2025 \n \nSemiconductor Supply Chain \n \n2 \n \nFig. 1. Security challenges in the semiconductor supply chain \nThis implies that threat analysis must consider both the type of threat and the various phases of \nthe supply chain in which the threat is most effective. Moreover, one or more adversaries from \ndifferent stages of supply chain can collaborate to compromise a hardware, which increases the \nseverity of threats. Such insider threats are called collusion threats [6].  \nThis document focuses on potential collusion risks in the hardware supply chain and is \norganized as follows:  \n• Section 2 outlines the different phases of a semiconductor supply chain. \n• Section 3 describes a framework for analyzing supply chain threats.  \n• Section 4 presents two real-life examples of hardware security threats to provide a \ncomprehensive explanation of the proposed framework.  \n• Section 5 concludes the discussion and provides directions for future work."
  },
  {
    "chunk_id": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10_chunk_6",
    "filename": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10.pdf",
    "page_num": 7,
    "text": "NIST CSWP 46  \n \nAnalyzing Collusion Threats in the \nJune 30, 2025 \n \nSemiconductor Supply Chain \n \n3 \n2. Stages of Semiconductor Supply Chain Stages \nThe first step in analyzing security concerns in the semiconductor supply chain is to outline the \nvarious stages of the supply chain and identify potential threats associated with each. There is \nno standard set of stages. However, for our analysis we will use seven stages as defined by \nAreno [7]. The user stage has been merged with the deployment stage since they have similar \nattack surfaces. An end-of-life stage has also been added to the seven stages originally defined \nby Areno [7]. A brief explanation of the stages is described below \n1. Concept: Concept stage is the birthplace of an Integrated Circuit (IC). At this stage, the \ngoals and purpose of an integrated circuit (IC) are formulated, and the scope and target \nof a hardware component are discussed. Customers, the design, planning, finance \nteams, and other key stakeholders are involved at this stage. \n2. Design: Design stage gives a form to the ideas generated in the concept stage. This is \nthe stage where prototypes of the concept are created with the help of different \nComputer Aided Design (CAD) tools and analysis of whether the goals identified during \nthe concept stage are met. This stage also includes the use of third-party software and \nhardware prototyping. \n3. Integration: Integration is the stage where different design components from designers \nand third parties are integrated together. This phase is crucial since many design \nelements already have tested solutions, so not everything needs to be created from the \nground up. It is more feasible to purchase these solutions from third parties and \nintegrate them into the design. \n4. Manufacturing: After the IC's design is finished, the manufacturing phase begins. This \nstage includes several processes, including fabrication and packaging. Due to the high \ncost of building and maintaining manufacturing facilities, many design houses are \nfabless and outsource their designs to manufacturers located elsewhere. \n5. Testing: Testing is the stage at which manufactured Integrated Circuits (ICs) are tested \nto ensure that they perform properly. Following the completion of fabrication, each IC \nundergoes testing. An IC's functionalities are tested here to make sure they adhere to \ndesign specifications. \n6. Provisioning: Provisioning is the stage where standard and sensitive data are loaded \ninto the manufactured IC. Standard data are generic and mostly available open source, \nbut the sensitive data are anything whose disclosure would compromise IP or security. \nFor example, keys of crypto modules or logic locking keys are sensitive data. \n7. Deployment and Use: This stage includes delivering the IC to customers and using the \nIC. Many hardware vulnerabilities are exploited at this stage. \n8. End of Life: End-of-life for an IC is the stage where the manufacturer no longer sells or \nmanufactures IC [8]. This is often because of technological advancements when new ICs \nexhibiting better performance have been launched. When a chip reaches its end-of-life, \nthe deployed chips are gradually replaced and discarded. These discarded chips are"
  },
  {
    "chunk_id": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10_chunk_7",
    "filename": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10.pdf",
    "page_num": 8,
    "text": "NIST CSWP 46  \n \nAnalyzing Collusion Threats in the \nJune 30, 2025 \n \nSemiconductor Supply Chain \n \n4 \noften reused or recycled into new hardware compromising their quality and \nperformance."
  },
  {
    "chunk_id": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10_chunk_8",
    "filename": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10.pdf",
    "page_num": 9,
    "text": "NIST CSWP 46  \n \nAnalyzing Collusion Threats in the \nJune 30, 2025 \n \nSemiconductor Supply Chain \n \n5 \n3. Framework for Supply Chain Threat Analysis  \nThis work proposes a framework for analyzing different threats and how collusion among \nadversaries can affect the severity of threats. This analysis is divided into five distinct stages \nthat discuss adversaries' intent, access, and resources, and how their collusion affects the \nseverity of different threats. The framework is shown in Fig. 2. The framework incorporates \nthreats across all stages of supply chain including insider threats. \n \nFig. 2. Methodology for supply chain threat analysis \n3.1. Identify the Intent of the Adversary \nSupply chain security analysis begins with identifying the adversary’s objectives. For example, \nan adversary may wish to disrupt a hardware’s functionality or steal a designer’s intellectual \nproperty (IP). This analysis describes the potential attacker, the resources that must be \nprotected, and the semiconductor supply chain stage at which mitigation is best applied. \n3.2. Identify Hardware Threats \nThe second step is identifying the threats associated with the adversary’s intent. For example, if \nthe intent is IP theft, then the IP to be protected must be identified. In this context, an attack \non logic obfuscation can be characterized as a threat. Similarly, if the adversary intends to \ninfiltrate hardware, then hardware Trojan insertion may need to be examined. \n3.3. Analyze Stages of Hardware Development Life Cycle for Exploitability of the Threat \nAt this point, one or more significant hardware threats have been identified. The following \nstage involves determining which stage of the semiconductor supply chain the threat can be \nexploited. Questions such as how much threat an adversary in the manufacturing stage poses \nto logic obfuscation, or whether an adversary in the provisioning stage offers threats to \nhardware Trojan insertion, are raised. In light of a threat, this step determines the \nsemiconductor supply chain's security-critical phases. In addition, this step determines if a \nthreat is unexploitable at a specific point in the supply chain. \n3.4. Analyze the Effect of Collusion Among Adversaries in Different Stages \nSince every stage of the semiconductor supply chain is distinct, adversaries have varying \ndegrees of access to and knowledge of the system at different stages of the semiconductor"
  },
  {
    "chunk_id": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10_chunk_9",
    "filename": "Analyzing Collusion Threats in the Semiconductor Supply Chain_first10.pdf",
    "page_num": 10,
    "text": "NIST CSWP 46  \n \nAnalyzing Collusion Threats in the \nJune 30, 2025 \n \nSemiconductor Supply Chain \n \n6 \nsupply chain. The effectiveness of an attack depends largely on the adversary’s knowledge of \nthe system and their level of access. Different adversaries possess varying degrees of both. For \nexample, a manufacturer may have detailed design knowledge, while an end user typically has \nlimited access and little insight into a system’s internal functions. As a result, their capabilities \ndiffer significantly. \nThus, collusion between adversaries from different stages of the life cycle can make threats \nconsiderably more severe, which is why this stage is crucial in the context of security analysis.  \nAt this point in the analysis, we apply a linear scale to determine the severity of threats when \nadversaries from different stages of the supply chain collude. This scale ranges from 0 to 10 and \nrepresents the relative threat level of a group of colluding adversaries. Fig. 3 is an example of \nthe scale developed in the context of the threat of hardware trojan insertion. The scale begins \nat 10, representing the highest threat severity level. This scenario assumes that all relevant \nadversaries are collaborating. From this point, we progressively remove one adversary at a time \nfrom the collusion and assess the resulting threat severity for each possible combination of \nremaining adversaries. As adversaries are removed, the threat severity decreases, depending \non the number of adversaries and their specific roles. For instance, as shown in Fig. 3, if the \nmanufacturer is removed from the collusion, the threat severity level drops to 8. However, if \nthe designer is removed, the threat severity level decreases to 6. This suggests that a malicious \ndesigner poses a higher risk of hardware Trojan insertion compared to a malicious \nmanufacturer. \n \n \nFig. 3. Threat severity levels for colluding adversaries in the context of hardware Trojan insertion \nThis scale is relative, meaning it provides a context on the severity of the threat posed by \ndifferent adversaries in a collusion but does not quantify the exact difference in severity. For \nexample, Fig. 3 illustrates that a collusion between an integrator and a designer presents a \nmore severe threat than one involving a manufacturer and a designer, but the scale does not \nspecify how much more severe the threat is. This relative approach is intentional, as different \nstakeholders may prioritize different metrics for evaluating threat severity. One analyst might \nprioritize attack completion time, while another may focus on the likelihood of attack success. \nThis flexibility allows analysts to develop their own customized, non-linear scales based on the \nmetrics they deem most important. These scales can provide a more detailed understanding,"
  },
  {
    "chunk_id": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10_chunk_0",
    "filename": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10.pdf",
    "page_num": 1,
    "text": "ANNUAL REPORT\n2018\nNIST/ITL CYBERSECURITY PROGRAM\nNIST SPECIAL PUBLICATION 800-206"
  },
  {
    "chunk_id": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10_chunk_1",
    "filename": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10.pdf",
    "page_num": 2,
    "text": "ANNUAL REPORT 2018\nNIST/ITL CYBERSECURITY PROGRAM\nPATRICK O’REILLY, EDITOR\nComputer Security Division  \nInformation Technology Laboratory\nKRISTINA RIGOPOULOS, EDITOR\nApplied Cybersecurity Division  \nInformation Technology Laboratory\n  CO-EDITORS:\nLarry Feldman\nGreg Witte\nG2, Incorporated (“G2”)\na Huntington Ingalls Company \nAnnapolis Junction, Maryland\nTHIS PUBLICATION IS AVAILABLE FREE OF CHARGE FROM \nhttps://doi.org/10.6028/NIST.SP.800-206\nJANUARY 2020\nU.S. DEPARTMENT OF COMMERCE\nWilbur L. Ross, Jr., Secretary\nNATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY\nWalter Copan, NIST Director and Under Secretary of Commerce for Standards and Technology"
  },
  {
    "chunk_id": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10_chunk_2",
    "filename": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10.pdf",
    "page_num": 3,
    "text": "THIS PAGE IS INTENTIONALLY LEFT BLANK"
  },
  {
    "chunk_id": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10_chunk_3",
    "filename": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10.pdf",
    "page_num": 4,
    "text": "NIST/ITL CYBERSECURITY PROGRAM ANNUAL REPORT | 2018\nI\nAUTHORITY\nThis publication has been developed by NIST in accordance with its statutory \nresponsibilities under the Federal Information Security Modernization Act (FISMA) of \n2014, 44 U.S.C. § 3551 et seq., Public Law (P.L.) 113-283. NIST is responsible for developing \ninformation security standards and guidelines, including minimum requirements for \nfederal information systems, but such standards and guidelines shall not apply to \nnational security systems without the express approval of appropriate federal officials \nexercising policy authority over such systems. This guideline is consistent with the \nrequirements of the Office of Management and Budget (OMB) Circular A-130.\nNothing in this publication should be taken to contradict the standards and guidelines \nmade mandatory and binding on federal agencies by the Secretary of Commerce under \nstatutory authority. Nor should these guidelines be interpreted as altering or superseding \nthe existing authorities of the Secretary of Commerce, Director of the OMB, or any other \nfederal official. This publication may be used by nongovernmental organizations on a \nvoluntary basis and is not subject to copyright in the United States. Attribution would, \nhowever, be appreciated by NIST.\nNational Institute of Standards and Technology Special Publication 800-206 \nNatl. Inst. Stand. Technol. Spec. Publ. 800-206, 31 pages (January 2020) \nCODEN: NSPUE2\nThis publication is available free of charge from:  \nhttps://doi.org/10.6028/NIST.SP.800-206\nREPORTS ON COMPUTER SYSTEMS TECHNOLOGY\nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops \ntests, test methods, reference data, proof of concept implementations, and technical \nanalyses to advance the development and productive use of information technology. \nITL’s responsibilities include the development of management, administrative, technical, \nand physical standards and guidelines for the cost-effective security and privacy of other \nthan national security-related information in federal information systems. The Special \nPublication 800-series reports on ITL’s research, guidelines, and outreach efforts in \ninformation system security, and its collaborative activities with industry, government, \nand academic organizations."
  },
  {
    "chunk_id": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10_chunk_4",
    "filename": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10.pdf",
    "page_num": 5,
    "text": "NIST/ITL CYBERSECURITY PROGRAM ANNUAL REPORT | 2018\nII\nDISCLAIMER\nAny mention of commercial products or organizations is for informational purposes only; \nit is not intended to imply recommendation or endorsement by the National Institute of \nStandards and Technology, nor is it intended to imply that the products identified are \nnecessarily the best available for the purpose.\nTRADEMARK INFORMATION\nAll names are trademarks or registered trademarks of their respective owners."
  },
  {
    "chunk_id": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10_chunk_5",
    "filename": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10.pdf",
    "page_num": 6,
    "text": "NIST/ITL CYBERSECURITY PROGRAM ANNUAL REPORT | 2018\nIII\nFOREWORD\nCybersecurity: Picking up the pace\n“The more things change, the more they stay the same.” (From a French proverb)\nTen years ago, the National Institute of Standards and Technology (NIST) annual  \nreport on cybersecurity featured accomplishments and challenges in quantum \ncomputing, encryption, identity management, personal identity verification, \nvulnerability measurements, assessing the security controls in federal information \nsystems, mobile devices, international standardization, and addressing the needs of \nsmall and medium-sized businesses, all of which were among the many pressing topics \nof the day. Sound familiar?\nReviewing those topics in the NIST Fiscal Year 2008 report on computer security \nactivities and accomplishments might lead some to conclude that the old French \nproverb is true when it comes to cybersecurity. But in this case, a more appropriate \nstatement might be, “The more things appear to stay the same, the more quickly they \nactually change.”\nThat certainly is true for the threat environment in which we function today. New attack \nsurfaces, new vulnerabilities, and new attackers emerge constantly. The creativity, \nthe dramatically increased frequency of attacks, and the ready availability of new \ntechnologically enhanced modes of attack are even more difficult to identify—much \nless protect, detect, respond to, and recover from—before they inflict great harm to U.S. \norganizations and our economy, security, and society in general.\nA decade later, these changes have enormous implications in a world that is so much \nmore dependent on digital devices, systems, and connectivity for carrying out both the \nspecialized and ordinary activities that drive our economy and safeguard our security. \nThey create thorny challenges as we seek balance in battling attacks and attackers while \npreserving our intellectual property, privacy, civil rights, and liberties.\nThe speed with which our cybersecurity risks change means that everyone involved in \nmanaging those risks needs to pick up the pace. That is what NIST is doing with the help \nof many partners and through varied programs and approaches.\nIn Fiscal Year 2018, we received and worked on new cybersecurity-related assignments \nfrom Congress and the President. Those have led us to focus our attention on assisting \nsmall businesses, forging practical solutions to address security concerns raised by the \nInternet of Things, and updating our guidance on risk management and security controls \nfor federal agencies and others. We also launched major new initiatives, including the \ndevelopment of a voluntary framework for privacy risk management, standards for"
  },
  {
    "chunk_id": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10_chunk_6",
    "filename": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10.pdf",
    "page_num": 7,
    "text": "NIST/ITL CYBERSECURITY PROGRAM ANNUAL REPORT | 2018\nIV\npost-quantum cryptography, and revisions to Federal Information Processing Standard \n(FIPS) 140-3,1 Security Requirements for Cryptographic Modules.\nOne thing has remained constant over the past decade: our commitment to cultivating \ntrust in information and the technology that drives the development and handling \nof that information. This annual report focuses on some of NIST’s most noteworthy \ncybersecurity achievements in 2018 and offers insights into our current priorities \nand strategies. For a more complete review of our work, check out our primary \ncybersecurity website.2\nNIST welcomes all suggestions for how we can improve our cybersecurity work to \nbetter serve the public and private sectors. And, by all means, please join us as we pick \nup the pace.\nDonna F. Dodson \nNIST Chief Cybersecurity Advisor\n1 \u0007Federal Information Processing Standard (FIPS) 140-3, https://csrc.nist.gov/publications/detail/fips/140/3/final \n2 \u0007NIST Cybersecurity, https://www.nist.gov/topics/cybersecurity"
  },
  {
    "chunk_id": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10_chunk_7",
    "filename": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10.pdf",
    "page_num": 8,
    "text": "NIST/ITL CYBERSECURITY PROGRAM ANNUAL REPORT | 2018\nV\nTABLE OF CONTENTS\nIntroduction .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   1\nImperative 1 – Advancing Cybersecurity and Privacy Standards .  .   .  .   .  .   .  .   .  .  .  .  .  .  .   3\nImperative 2 – Enhancing Risk Management  .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .  .  .  .  .  .  .  .  .   5\nImperative 3 – Strengthening Cryptographic Standards and Validation  .  .   .  .   .  .   .  .  .  .   8\nImperative 4 – \u0007Advancing Cybersecurity Research  \nand Applications Development .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .  .  .  .  .  .  .    12\nImperative 5 – \u0007Improving Cybersecurity Awareness, Training, Education,  \nand Workforce Development  .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .  .  .  .  .  .  .  .   15\nImperative 6 – Enhancing Identity and Access Management .  .   .  .   .  .   .  .   .  .   .  .  .  .  .  .   19\nImperative 7 – Bolstering Infrastructure Protection  .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .  .  .  .  .  .  .  21\nImperative 8 – Securing Emerging Technologies .  .   .  .   .  .   .  .   .  .   .  .   .  .   .  .  .  .  .  .  .  .  .   24\nImperative 9 – Advancing Security Test and Measurement Tools  .  .   .  .   .  .   .  .   .  .  .  .  .  29"
  },
  {
    "chunk_id": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10_chunk_8",
    "filename": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10.pdf",
    "page_num": 9,
    "text": "THIS PAGE IS INTENTIONALLY LEFT BLANK"
  },
  {
    "chunk_id": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10_chunk_9",
    "filename": "Annual Report 2018_ NIST_ITL Cybersecurity Program_first10.pdf",
    "page_num": 10,
    "text": "NIST/ITL CYBERSECURITY PROGRAM ANNUAL REPORT | 2018\n1\nINTRODUCTION\nIt is often said that cybersecurity is about people, process, and technology. That’s a \nconvenient way to think about cybersecurity challenges, and it is the primary approach \nthat the National Institute of Standards and Technology (NIST) takes in carrying out its \ncybersecurity mission. This report highlights NIST’s Fiscal Year (FY) 2018 cybersecurity-\nrelated accomplishments and includes many examples of how the NIST Information \nTechnology Laboratory (ITL) delivers value to the nation by focusing on each element \nof the people, process, and technology triad. Importantly, NIST strives to address those \nthree areas in an integrated fashion, knowing that siloed thinking about cybersecurity is \nnot a viable path to success.\nNIST carries out its cybersecurity responsibilities through an open, transparent, and \ninclusive approach, teaming with organizations in the private sector, non-profit sphere, \nacademia, and government at multiple levels. It does so by cooperating with partners in \nthe United States and abroad who contribute to the research, development, standards, \nand applications that are all needed to advance both the state-of-the-art and the state-\nof-practice when it comes to cybersecurity. NIST is also assisted in identifying emerging \nmanagerial, technical, administrative, and physical safeguard issues by the Information \nSecurity and Privacy Advisory Board (ISPAB).3 ISPAB is the Federal Advisory Committee4 \nthat advises NIST, the Secretaries of Commerce and Homeland Security, and the Office of \nManagement and Budget on security and privacy matters.\nAll of NIST’s cybersecurity work is conducted in an environment that demands \ntechnical excellence and integrity and that aims to cultivate trust in technologies and \ninstitutions. NIST’s portfolio of cybersecurity programs works along the full spectrum \nof cybersecurity challenges and potential, from foundational research to applied \nengineering and transition to practice.\nNIST knows that improving all aspects of cybersecurity is an imperative, not just for the \nagency but for all of society that relies on technologies, products, and systems. NIST’s \nFY18 premier cybersecurity accomplishments and brief insights into FY19 priorities are \ncaptured in the cybersecurity imperatives that follow.\n3 \u0007Charter of the Information Security and Privacy Advisory Board (ISPAB), https://csrc.nist.gov/CSRC/media/\nProjects/ISPAB/documents/ispab_charter_2016-2018.pdf \n4 \u0007Federal Advisory Committee Act, https://uscode.house.gov/view.xhtml?path=/prelim@title5/title5a/\nnode2&edition=prelim"
  },
  {
    "chunk_id": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10_chunk_0",
    "filename": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10.pdf",
    "page_num": 1,
    "text": "NISTIR 8420A \nApproaches and Challenges of \nFederal Cybersecurity \nAwareness Programs \nJulie Haney \nJody Jacobs \nSusanne Furman \nFernando Barrientos \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8420A"
  },
  {
    "chunk_id": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10_chunk_1",
    "filename": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10.pdf",
    "page_num": 2,
    "text": "NISTIR 8420A \n \nApproaches and Challenges of \nFederal Cybersecurity \nAwareness Programs \n \nJulie Haney \nJody Jacobs \nSusanne Furman \nFernando Barrientos \nInformation Access Division \nInformation Technology Laboratory \n \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8420A \n \n \nMarch 2022 \n \n \n \n \nU.S. Department of Commerce \nGina M. Raimondo, Secretary \n \nNational Institute of Standards and Technology \nJames K. Olthoff, Performing the Non-Exclusive Functions and Duties of the Under Secretary of Commerce \nfor Standards and Technology & Director, National Institute of Standards and Technology"
  },
  {
    "chunk_id": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10_chunk_2",
    "filename": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10.pdf",
    "page_num": 3,
    "text": "National Institute of Standards and Technology Interagency or Internal Report 8420A \n73 pages (March 2022) \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8420A \nCertain commercial entities, equipment, or materials may be identified in this document in order to describe an \nexperimental procedure or concept adequately. Such identification is not intended to imply recommendation or \nendorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best \navailable for the purpose.  \nThere may be references in this publication to other publications currently under development by NIST in accordance \nwith its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, \nmay be used by federal agencies even before the completion of such companion publications. Thus, until each \npublication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For \nplanning and transition purposes, federal agencies may wish to closely follow the development of these new \npublications by NIST.   \nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback to \nNIST. Many NIST cybersecurity publications, other than the ones noted above, are available at \nhttps://csrc.nist.gov/publications."
  },
  {
    "chunk_id": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10_chunk_3",
    "filename": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10.pdf",
    "page_num": 4,
    "text": "NISTIR 8420A  \n \nAPPROACHES AND CHALLENGES OF FEDERAL \n \n \nCYBERSECURITY AWARENESS PROGRAMS \nii \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test \nmethods, reference data, proof of concept implementations, and technical analyses to advance the \ndevelopment and productive use of information technology. ITL’s responsibilities include the \ndevelopment of management, administrative, technical, and physical standards and guidelines for \nthe cost-effective security and privacy of other than national security-related information in federal \ninformation systems. \nAbstract \nOrganizational security awareness programs experience a number of challenges, including lack \nof resources, difficulty measuring the impact of the program, and perceptions among the \nworkforce that training is a boring, “check-the-box” activity. While prior surveys and research \nhave examined programs in the private sector, there is little understanding of whether these \nfindings also apply within the U.S. government. To address this gap and better understand the \nneeds, challenges, practices, and necessary competencies of federal security awareness teams and \nprograms, NIST conducted a research study that leveraged both qualitative and quantitative \nmethodologies. This companion document to NISTIR 8420 “Federal Cybersecurity Awareness \nPrograms: A Mixed Methods Research Study” reports on a subset of study results focused on \nidentifying the current approaches and challenges of security awareness programs within the \nfederal government. Insights gained from these results are informing guidance and other \ninitiatives to aid federal organizations in building effective security awareness programs. While \nfocused on the U.S. government, findings may also have implications for organizational security \nawareness programs in other sectors. \nKeywords \ncybersecurity; cybersecurity awareness; focus groups; measures of effectiveness; mixed \nmethods; phishing; security professionals; survey; training; usable cybersecurity \n \n \n______________________________________________________________________________________________________ \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8420A"
  },
  {
    "chunk_id": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10_chunk_4",
    "filename": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10.pdf",
    "page_num": 5,
    "text": "NISTIR 8420A  \n \nAPPROACHES AND CHALLENGES OF FEDERAL \n \n \nCYBERSECURITY AWARENESS PROGRAMS \niii \nExecutive Summary \nSecurity awareness programs aim to help employees recognize and appropriately respond to \nsecurity issues, with a goal of achieving long-term behavior change. Industry and research \nsurveys have revealed that organizational security awareness programs face a number of \nchallenges, including lack of resources, difficulty measuring the impact of the program, and \nperceptions among the workforce that training is a boring, “check-the-box” activity. However, it \nis unclear if these challenges also apply to security awareness programs in the United States \n(U.S.) government. \nTo better understand the needs, challenges, practices, and necessary competencies of federal \nsecurity awareness teams and programs, we conducted a “mixed methods” research study that \nleveraged both qualitative and quantitative methodologies. We first conducted eight focus groups \nof federal employees who had security awareness duties or were managers or executives who \noversaw the programs within their organizations. The focus groups then informed an online \nsurvey completed by 96 federal employees with security awareness responsibilities.  \nThe research background and methodologies for these two phases are described in detail in \nNISTIR 8420 “Federal Cybersecurity Awareness Programs: A Mixed Methods Research Study.” \nThis companion document reports on a subset of results focused on the approaches and \nchallenges of federal security awareness programs. The following is a high-level overview of \nthese results, with cited statistics from the survey.  \nRequired Annual Security Awareness Training \n• Two-thirds of survey participants said they develop at least some required security awareness \ntraining content in-house, with 80% updating content at least once a year. Focus group \nparticipants expressed frustration that each organization had to acquire or create their own \ntraining. Instead, they desired standardized government training and guidance that allow \ncustomization for the unique needs of each organization. \n• Automation was viewed as essential for efficient tracking of employees’ completion of \ntraining. However, some organizations lacked this automation, especially when tracking \ncontractors, who may not have access to organizations’ learning management systems.  \n• When dealing with individuals who do not complete their training by the deadline, many \norganizations disabled accounts of non-compliant employees, resulting in higher compliance \nnumbers. Still, almost half (47%) said that getting employees to complete the required \ntraining was challenging, largely because employees were busy or disinterested.  \nSecurity Awareness Approaches \n• In addition to the required annual training, 79% of surveyed programs held a variety of \nsecurity awareness activities throughout the year, such as speaker events, instructor-led \nsessions, webinars, and interactive activities like escape rooms. Smaller programs were less \nlikely to offer additional activities.  \n• Programs often disseminated information that employees could use in both their work and \npersonal lives, which was viewed as important for establishing consistent security habits. \nThey have also recently introduced more topics relevant to teleworking.  \n______________________________________________________________________________________________________ \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8420A"
  },
  {
    "chunk_id": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10_chunk_5",
    "filename": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10.pdf",
    "page_num": 6,
    "text": "NISTIR 8420A  \n \nAPPROACHES AND CHALLENGES OF FEDERAL \n \n \nCYBERSECURITY AWARENESS PROGRAMS \niv \n• Programs utilized a wide range of other communication channels, such as email, newsletters, \nposters, and videos. However, 56% of surveyed programs had difficulty providing security \nawareness information in an engaging way, 47% experienced challenges customizing \nsecurity awareness information to a diverse workforce, and 40% struggle with ensuring \nmaterials are Section 508 compliant, especially when utilizing interactive approaches.  \n• 85% of programs performed phishing simulations, which were often described as being one \nof the successful aspects of the security awareness program. While many focused on phishing \nclick rates to gauge learning, others were more interested in reporting rates to demonstrate \npositive impacts on employee behavior. \n• 44% of surveyed programs recognized employees for practicing good security behaviors via \na variety of means, such as virtual awards, personal thank-yous, and formal recognitions. \nSeveral focus group participants described several successful incentive initiatives related to \nphishing simulations. \nInforming the Security Awareness Program \n• Participants frequently collaborated with other groups in the organization to augment and \ninform their programs, most commonly other cybersecurity and IT teams, but also with \nothers such as human resources and communications. \n• Programs used a variety of government and non-government resources to inform security \nawareness topics and approaches, e.g., workforce feedback, organizational security incident \ntrends, news stories, and security mailing lists.  \n• While only 27% of survey participants expressed challenges collaborating or sharing \ninformation with other federal security awareness professionals, focus group participants \nfrequently highlighted their desire for increased collaboration. For example, they suggested \nthe creation of a central repository of awareness materials, ongoing working groups, or real-\ntime online forums.  \nProgram Success and Support \n• Training completion rates were the most common way programs try to determine their \neffectiveness (84%). Behavior based measures (e.g., phishing click rates, reporting of \nphishing emails or other incidents) were utilized by over half.  \n• Over half (56%) of survey participants thought their leadership viewed compliance metrics as \nthe most important indicator of program success, with slightly fewer (47%) having the same \nopinion themselves. However, in qualitative remarks, many focus group and survey \nparticipants disagreed with this compliance focus, instead emphasizing that the real purpose \nof security awareness is to affect employees’ security behaviors; therefore, success should be \nmeasured in ways beyond training completion rates. \n• 77% rated their security awareness programs as moderately or very successful. However, \n44% of survey participants expressed challenges determining how to measure program \neffectiveness. Survey and focus group participants desired more guidance on appropriate \nmetrics and government-specific data for benchmarking their own program. \n• 48% of survey participants indicated that correlating security incident data with behaviors \ntargeted by the security awareness program was challenging. Yet managers taking the survey \nlisted security incident data as the measure of effectiveness most preferred for helping them \n______________________________________________________________________________________________________ \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8420A"
  },
  {
    "chunk_id": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10_chunk_6",
    "filename": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10.pdf",
    "page_num": 7,
    "text": "NISTIR 8420A  \n \nAPPROACHES AND CHALLENGES OF FEDERAL \n \n \nCYBERSECURITY AWARENESS PROGRAMS \nv \nmake decisions about the security awareness program, while training completion and \nphishing click rates were mentioned by much fewer. \n• Large majorities (70% and greater) thought that security was a priority for the organization, \nthat security was understood by leadership and employees as important, and that leadership \nand employees supported the security awareness program. However, only 35% of survey \nparticipants thought the program had been provided adequate funding and staff. \nStudy results can inform federal security awareness professionals, organizational decision \nmakers, policy makers, and guidance developers in their efforts to improve and advocate for \nfederal security awareness programs. The results may also be valuable to security awareness \nprofessionals outside of the government who face similar challenges. Additionally, although this \nstudy refers to security awareness programs, its focus is not only relevant to awareness but also \nto security training issues as well. \n \n______________________________________________________________________________________________________ \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8420A"
  },
  {
    "chunk_id": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10_chunk_7",
    "filename": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10.pdf",
    "page_num": 8,
    "text": "NISTIR 8420A  \n \nAPPROACHES AND CHALLENGES OF FEDERAL \n \n \nCYBERSECURITY AWARENESS PROGRAMS \nvi \n \nTable of Contents \nEXECUTIVE SUMMARY ......................................................................................................... iii \n1 \nINTRODUCTION................................................................................................................. 1 \n2 \nREPORTING CONVENTIONS.......................................................................................... 2 \n3 \nSECURITY AWARENESS APPROACHES ..................................................................... 3 \n3.1 ANNUAL REQUIRED TRAINING ............................................................................................. 3 \n3.1.1 Required Training Fulfillment .................................................................................... 3 \n3.1.2 Obtaining Training Content ........................................................................................ 4 \n3.1.3 Update Frequency ....................................................................................................... 6 \n3.1.4 Non-Compliance Actions and Consequences ............................................................. 6 \n3.1.5 Challenges: Required Training................................................................................... 8 \n3.2 OTHER SECURITY AWARENESS ACTIVITIES ....................................................................... 13 \n3.2.1 Number of Additional Activities ................................................................................ 13 \n3.2.2 Communication Channels ......................................................................................... 14 \n3.3 TOPICS ............................................................................................................................... 17 \n3.4 PHISHING SIMULATIONS ..................................................................................................... 19 \n3.4.1 Frequency of phishing simulations ........................................................................... 21 \n3.4.2 Handling Repeat Clickers ......................................................................................... 22 \n3.5 RECOGNIZING POSITIVE SECURITY BEHAVIORS ................................................................. 23 \n3.6 CHANGES DUE TO PANDEMIC ............................................................................................ 24 \n3.7 CHALLENGES: SECURITY AWARENESS APPROACHES ......................................................... 25 \n4 \nAIDING AND INFORMING THE SECURITY AWARENESS PROGRAM ............. 29 \n4.1 DEPARTMENT INFLUENCE .................................................................................................. 29 \n4.2 INTERNAL SOURCES ........................................................................................................... 30 \n4.2.1 Collaborations with Internal Groups........................................................................ 30 \n4.2.2 Sources for Topics and Approaches ......................................................................... 32 \n4.3 EXTERNAL SOURCES .......................................................................................................... 33 \n4.4 NIST SECURITY AWARENESS RESOURCES ........................................................................ 35 \n4.5 CHALLENGES: INFORMING THE SECURITY AWARENESS PROGRAM .................................... 36 \n5 \nDETERMINING PROGRAM SUCCESS ........................................................................ 38 \n5.1 MEASURES OF EFFECTIVENESS .......................................................................................... 38 \n5.2 COMPLIANCE AS INDICATOR OF SUCCESS .......................................................................... 41 \n5.3 USING EFFECTIVENESS DATA ............................................................................................ 43 \n5.4 MANAGER PREFERENCES FOR DEMONSTRATING EFFECTIVENESS ..................................... 44 \n5.5 OVERALL PROGRAM SUCCESS ........................................................................................... 46 \n5.6 CHALLENGES: DETERMINING PROGRAM SUCCESS ............................................................. 46 \n6 \nPROGRAM SUPPORT ...................................................................................................... 49 \n6.1 ORGANIZATIONAL SUPPORT FOR SECURITY ....................................................................... 50 \n6.2 ORGANIZATIONAL SUPPORT FOR THE SECURITY AWARENESS PROGRAM .......................... 52 \n6.3 RESOURCES FOR THE SECURITY AWARENESS PROGRAM ................................................... 54 \n______________________________________________________________________________________________________ \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8420A"
  },
  {
    "chunk_id": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10_chunk_8",
    "filename": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10.pdf",
    "page_num": 9,
    "text": "NISTIR 8420A  \n \nAPPROACHES AND CHALLENGES OF FEDERAL \n \n \nCYBERSECURITY AWARENESS PROGRAMS \nvii \n7 \nKEY TAKEAWAYS ........................................................................................................... 57 \n7.1 REQUIRED TRAINING ......................................................................................................... 57 \n7.2 GENERAL APPROACHES ..................................................................................................... 58 \n7.3 COLLABORATION ............................................................................................................... 58 \n7.4 SOURCES OF TOPICS AND APPROACHES .............................................................................. 59 \n7.5 MEASURING SUCCESS ........................................................................................................ 59 \n7.6 PROGRAM SUPPORT ........................................................................................................... 59 \n8 \nMOVING FORWARD ....................................................................................................... 60 \nACKNOWLEDGEMENTS ....................................................................................................... 61 \nREFERENCES ............................................................................................................................ 62 \n \nList of Appendices \nAPPENDIX A— ACRONYMS ................................................................................................. 63 \n \nList of Figures \nFigure 1: How training requirements can be fulfilled (n=89) ......................................................... 3 \nFigure 2: How required training is obtained (n=89) ....................................................................... 5 \nFigure 3: Required training content update frequency (n=89)........................................................ 6 \nFigure 4: Required training non-compliance actions and consequences (n=90) ............................ 7 \nFigure 5: Challenges – Required training ....................................................................................... 8 \nFigure 6: Number of additional security awareness activities or events (n=86)........................... 13 \nFigure 7: Security awareness communication channels (n=85) ................................................... 14 \nFigure 8: Number of security awareness communication channels (n=85) .................................. 16 \nFigure 9: Security awareness topics (n=85) .................................................................................. 17 \nFigure 10: Frequency with which security awareness programs provide information applicable to \nemployees’ personal lives (n=86) ......................................................................................... 18 \nFigure 11: Organizations performing phishing simulations (n=89) ............................................. 19 \nFigure 12: Phishing simulation frequency (n=64) ........................................................................ 21 \nFigure 13: Repeat clicker consequences (n=64) ........................................................................... 22 \nFigure 14: Ways in which good security behaviors are recognized (n=85) ................................. 23 \nFigure 15: Challenges – Security awareness approaches ............................................................. 25 \nFigure 16: Subcomponents’ security awareness relationships with their Departments (n = 32) .. 29 \nFigure 17: Departments' security awareness relationships with their sub-components (n = 30) .. 30 \nFigure 18: Internal groups collaborating with security awareness programs (n=81) ................... 31 \n______________________________________________________________________________________________________ \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8420A"
  },
  {
    "chunk_id": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10_chunk_9",
    "filename": "Approaches and Challenges of Federal Cybersecurity Awareness Programs_first10.pdf",
    "page_num": 10,
    "text": "NISTIR 8420A  \n \nAPPROACHES AND CHALLENGES OF FEDERAL \n \n \nCYBERSECURITY AWARENESS PROGRAMS \nviii \nFigure 19: Internal sources informing security awareness topics and approaches (n=81) ........... 32 \nFigure 20: External sources informing security awareness content and approaches (n=81) ........ 33 \nFigure 21: FISSEA awareness and attendance (n=80) ................................................................. 36 \nFigure 22: NIST Special Publication 800-50 awareness and use (n=81) ..................................... 36 \nFigure 23: Challenges - Informing the security awareness program ............................................ 37 \nFigure 24: Measures of effectiveness (n=79) ............................................................................... 39 \nFigure 25: Number of measures of effectiveness (n = 79) ........................................................... 39 \nFigure 26: Agreement that compliance is the most important indicator of success ..................... 42 \nFigure 27: How effectiveness data is used (n=72) ........................................................................ 44 \nFigure 28: Program success ratings (n=80) .................................................................................. 46 \nFigure 29: Challenges – Determining program success ............................................................... 47 \nFigure 30: Agreement for statements about organizational support for security .......................... 50 \nFigure 31: Agreement for statements about organizational support for the security awareness \nprogram ................................................................................................................................. 52 \nFigure 32: Agreement for statements about adequacy of resources for the security awareness \nprogram ................................................................................................................................. 54 \n \n______________________________________________________________________________________________________ \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8420A"
  },
  {
    "chunk_id": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10_chunk_0",
    "filename": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10.pdf",
    "page_num": 1,
    "text": "NISTIR 8170 \nApproaches for Federal Agencies to Use  \nthe Cybersecurity Framework  \n \n \nMatt Barrett \nJeff Marron \nVictoria Yan Pillitteri \nJon Boyens \nStephen Quinn \nGreg Witte \nLarry Feldman \n \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8170-upd"
  },
  {
    "chunk_id": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10_chunk_1",
    "filename": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10.pdf",
    "page_num": 2,
    "text": "NISTIR 8170 \nApproaches for Federal Agencies to Use  \nthe Cybersecurity Framework  \n \n \nMatt Barrett* \nVictoria Yan Pillitteri \n \nJeff Marron \nJon Boyens \n \nApplied Cybersecurity Division \nStephen Quinn \n \nInformation Technology Laboratory \nComputer Security Division \n \n \nInformation Technology Laboratory \n \nGreg Witte \nLarry Feldman \nHuntington Ingalls Industries \nAnnapolis Junction, MD \n \n*Former employee; all work for this publication was done while at NIST \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8170-upd \n \nMarch 2020 \nINCLUDES UPDATES AS OF 08-17-2021; SEE PAGE VI \n \n \nU.S. Department of Commerce \nWilbur L. Ross, Jr., Secretary \nNational Institute of Standards and Technology \nWalter Copan, NIST Director and Under Secretary of Commerce for Standards and Technology"
  },
  {
    "chunk_id": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10_chunk_2",
    "filename": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10.pdf",
    "page_num": 3,
    "text": "National Institute of Standards and Technology Interagency Report 8170 \n33 pages (March 2020) \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8170-upd \nCertain commercial entities, equipment, or materials may be identified in this document in order to describe an \nexperimental procedure or concept adequately. Such identification is not intended to imply recommendation or \nendorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best \navailable for the purpose. \nThere may be references in this publication to other publications currently under development by NIST in accordance \nwith its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, \nmay be used by federal agencies even before the completion of such companion publications. Thus, until each \npublication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For \nplanning and transition purposes, federal agencies may wish to closely follow the development of these new \npublications by NIST. \nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback to \nNIST. Many NIST cybersecurity publications, other than the ones noted above, are available at \nhttps://csrc.nist.gov/publications. \nComments on this publication may be submitted to: \nNational Institute of Standards and Technology \nAttn: Applied Cybersecurity Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 2000) Gaithersburg, MD 20899-2000  \nEmail: nistir8170@nist.gov \nAll comments are subject to release under the Freedom of Information Act (FOIA)."
  },
  {
    "chunk_id": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10_chunk_3",
    "filename": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10.pdf",
    "page_num": 4,
    "text": "NISTIR 8170 \n \nAPPROACHES FOR FEDERAL AGENCIES \nTO USE THE CYBERSECURITY FRAMEWORK \nii \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8170-upd \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test \nmethods, reference data, proof of concept implementations, and technical analyses to advance the \ndevelopment and productive use of information technology. ITL’s responsibilities include the \ndevelopment of management, administrative, technical, and physical standards and guidelines for \nthe cost-effective security and privacy of other than national security-related information in federal \ninformation systems. \nAbstract \nThe document highlights examples for implementing the Framework for Improving Critical \nInfrastructure Cybersecurity (known as the Cybersecurity Framework) in a manner that \ncomplements the use of other NIST security and privacy risk management standards, guidelines, \nand practices. These examples include support for an Enterprise Risk Management (ERM) \napproach in alignment with OMB and FISMA requirements that agency heads “manage risk \ncommensurate with the magnitude of harm that would result from unauthorized access, use, \ndisclosure, disruption, modification, or destruction of a federal information system or federal \ninformation.” The use of the Cybersecurity Framework’s components enable discussion about the \nvarious types of risk that might occur within federal organizations and promote conversations \nabout how to determine the likelihood and potential consequences of risk events. These activities \ncan then be combined with those described in NIST Special Publication (SP) 800-37, Revision 2, \nRisk Management Framework for Information Systems and Organizations; SP 800-39, Managing \nInformation Security Risk; and other guidelines to form a comprehensive risk-based approach for \nsecurity and privacy.  \nThis risk-based approach will assist agencies in determining the risks that are relevant to its \nmission throughout the operational lifecycle and apply an appropriate type and degree of resources \nto treat those risks to an acceptable level. Examples in this publication will demonstrate the use of \nthe Cybersecurity Framework, the NIST Risk Management Framework (RMF), and other models \nto evaluate and report agency goals and progress and to inform tailoring activities for managing \ncybersecurity risk appropriately. Use of a comprehensive cybersecurity risk-based approach, as \ndemonstrated through these examples, supports agencies’ activities to meet their concurrent \nobligations to comply with the requirements of FISMA and Executive Order (EO) 13800. \nKeywords \nCybersecurity Framework; Federal Information Security Management Act (FISMA); Risk \nManagement Framework (RMF); Enterprise Risk Management; security and privacy controls."
  },
  {
    "chunk_id": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10_chunk_4",
    "filename": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10.pdf",
    "page_num": 5,
    "text": "NISTIR 8170 \n \nAPPROACHES FOR FEDERAL AGENCIES \nTO USE THE CYBERSECURITY FRAMEWORK \niii \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8170-upd \nAcknowledgments \nThe authors would like to thank our advisors and reviewers including Nahla Ivy, Donna Dodson, \nAdam Sedgewick, Amy Mahn, Matt Scholl, Kevin Stine, Kelley Dempsey, Ron Ross, Jim Foti, \nMat Heyman, and Matt Smith. \nSupplemental Content \nFor additional information on NIST’s cybersecurity programs, projects and publications, visit the \nComputer Security Resource Center, csrc.nist.gov. Information on other efforts at NIST and in the \nInformation Technology Laboratory (ITL) is available at www.nist.gov and www.nist.gov/itl. \nDocument Conventions \nThe phrase “federal agencies” in this publication means those agencies responsible for non-\nnational security-related information in federal systems. \nFISMA refers to the Federal Information Security Management Act of 2002, as amended. The \nFederal Information Security Management Act of 2002 was updated through the Federal \nInformation Security Modernization Act of 2014 [1] [2]. \nThe term “Tiers” cited in NIST Special Publication (SP) 800-39, Managing Information Security \nRisk: Organization, Mission, and Information System View, will be referred to as “Levels” in this \nreport to avoid confusion with Cybersecurity Framework Implementation Tiers. Upcoming \nrevisions of SP 800-39 will use the term “Levels” consistently [3]. \nThe seven steps of the RMF described in NIST SP 800-37, Revision 2—Prepare, Categorize, \nSelect, Implement, Assess, Authorize, and Monitor—are indicated using capital letters. This \nconvention includes many conjugations in the context of those RMF steps (e.g., Authorize, \nAuthorizing, and Authorized all refer to the Authorize step of the RMF) [4]. \n“Cybersecurity Framework” refers to version 1.1 of the Framework for Improving Critical \nInfrastructure Cybersecurity, issued in April 2018 [5]. \nThe five Functions of the Cybersecurity Framework—Identify, Protect, Detect, Respond, and \nRecover—are indicated using capital letters. This convention includes many conjugations in the \ncontext of those Cybersecurity Framework steps (e.g., Detect, Detected, and Detecting all refer \nto the Detect Function of Cybersecurity Framework). \nFor the purposes of this document, the terms “enterprise risk management” and “organization-\nwide risk management” are used interchangeably.  These terms and the term ‘risk register’ are \ndiscussed in greater detail in Draft NISTIR 8286, Integrating Cybersecurity and Enterprise Risk \nManagement (ERM), released March 19, 2020."
  },
  {
    "chunk_id": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10_chunk_5",
    "filename": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10.pdf",
    "page_num": 6,
    "text": "NISTIR 8170 \n \nAPPROACHES FOR FEDERAL AGENCIES \nTO USE THE CYBERSECURITY FRAMEWORK \niv \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8170-upd \nExecutive Summary \nAll federal agencies are entrusted with safeguarding the information contained in their systems \nand ensuring that those systems operate securely and reliably. It is vital that agency personnel at \nall levels manage their assets wisely and address cybersecurity risks effectively. To do that, \nagencies need a holistic approach to their enterprises’ risk management that includes timely, \nstreamlined approaches and automated tools.  \nAs part of its statutory responsibilities under the Federal Information Security Management Act \nas amended (FISMA), the National Institute of Standards and Technology (NIST) develops \nstandards and guidelines—including minimum requirements—to provide adequate information \nsecurity for federal information and information systems [1]. This suite of security and privacy \nrisk management standards and guidelines provides guidance for an integrated, organization-\nwide program to manage information security risk. \nNIST produced this report to assist federal agencies in strengthening their cybersecurity risk \nmanagement processes by highlighting example approaches for implementing the Framework for \nImproving Critical Infrastructure Cybersecurity (known as the Cybersecurity Framework) [5]. \nDeveloped by NIST in close collaboration with private and public sectors, the Cybersecurity \nFramework is a risk-based approach used voluntarily by organizations across the United States. \nInitially developed to address cybersecurity challenges in the Nation’s Critical Infrastructure (CI) \nsectors, the voluntary Framework is used by a variety of organizations across the world.  The \nCybersecurity Framework aligns with and complements NIST’s suite of security and privacy risk \nmanagement standards and guidelines. \nThis report illustrates eight example approaches through which federal agencies can leverage the \nCybersecurity Framework to address common cybersecurity-related responsibilities. By doing \nso, agencies can integrate the Cybersecurity Framework with key NIST cybersecurity risk \nmanagement standards and guidelines that are already in wide use. These eight approaches \nsupport a mature agency-wide cybersecurity risk management program: \n1. Integrate enterprise and cybersecurity risk management \n2. Manage cybersecurity requirements \n3. Integrate and align cybersecurity and acquisition processes \n4. Evaluate organizational cybersecurity \n5. Manage the cybersecurity program \n6. Maintain a comprehensive understanding of cybersecurity risk \n7. Report cybersecurity risks \n8. Inform the tailoring process \nThe key concepts and cybersecurity approaches described in this document are intended to \npromote more effective risk management and to encourage dialogue within and among federal \nagencies."
  },
  {
    "chunk_id": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10_chunk_6",
    "filename": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10.pdf",
    "page_num": 7,
    "text": "NISTIR 8170 \n \nAPPROACHES FOR FEDERAL AGENCIES \nTO USE THE CYBERSECURITY FRAMEWORK \nv \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8170-upd \nTable of Contents \nExecutive Summary ..................................................................................................... iv \n1 \nIntroduction ............................................................................................................ 1 \n1.1 Audience ........................................................................................................... 1 \n1.2 Organization of this report ................................................................................. 2 \n2 \nExample Approaches ............................................................................................. 3 \n1. Integrate Enterprise and Cybersecurity Risk Management ................................. 5 \n2. Manage Cybersecurity Requirements ................................................................. 7 \n3. Integrate and Align Cybersecurity and Acquisition Processes ............................ 8 \n4. Evaluate Organizational Cybersecurity ............................................................... 9 \n5. Manage the Cybersecurity Program .................................................................. 10 \n6. Maintain a Comprehensive Understanding of Cybersecurity Risk ..................... 12 \n7. Report Cybersecurity Risks ............................................................................... 14 \n8. Inform the Tailoring Process ............................................................................. 15 \nReferences ................................................................................................................... 17 \n \nList of Appendices \nAppendix A— Acronyms ............................................................................................ 19 \nAppendix B— Glossary .............................................................................................. 20"
  },
  {
    "chunk_id": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10_chunk_7",
    "filename": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10.pdf",
    "page_num": 8,
    "text": "NISTIR 8170 \n \nAPPROACHES FOR FEDERAL AGENCIES \nTO USE THE CYBERSECURITY FRAMEWORK \nvi \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8170-upd \nErrata \nThis table contains changes that have been incorporated into NIST Interagency or Internal \nReport (NISTIR) 8170. Errata updates can include corrections, clarifications, or other minor \nchanges in the publication that are either editorial or substantive in nature. Any potential updates \nfor this document that are not yet published in an errata update or revision—including additional \nissues and potential corrections—will be posted as they are identified; see the NISTIR 8170 \npublication details. \nDate \nType \nChange \nPages \n08-17-2021 \nSubstantive \nFootnote 3 has been updated with the most \ncurrent NIST information regarding Risk \nAppetite and Risk Tolerance and refers \nstakeholders to two relevant NISTIRs: \n“For a more complete discussion and \nguidance on Risk Appetite and Risk \nTolerance, see the NISTIR 8286, Integrating \nCybersecurity and Enterprise Risk \nManagement (ERM)  and series documents, \nespecially NISTIR 8286A Identifying and \nEstimating Cybersecurity Risk for Enterprise \nRisk.”  \n6"
  },
  {
    "chunk_id": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10_chunk_8",
    "filename": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10.pdf",
    "page_num": 9,
    "text": "NISTIR 8170 \n \nAPPROACHES FOR FEDERAL AGENCIES \nTO USE THE CYBERSECURITY FRAMEWORK \n1 \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8170-upd \n1 \nIntroduction \nAs part of its statutory responsibilities under the Federal Information Security Management Act \nas amended (FISMA), NIST develops standards and guidelines—including minimum \nrequirements—to support information security for agency operations and assets. NIST guidelines \nfulfill the requirements of FISMA and Office of Management and Budget (OMB) Circular \nA-130, and are used by agencies to develop, implement, and maintain cybersecurity and privacy \nprograms [6]. They include Federal Information Processing Standards (FIPS), Special \nPublications (SPs), and NIST Interagency Reports (NISTIRs). \nThe Cybersecurity Enhancement Act of 2014 formally updated NIST’s role to include \nidentifying and developing cybersecurity risk frameworks for voluntary use by critical \ninfrastructure (CI) owners and operators. The frameworks’ subsequent widespread use and \nadoption demonstrates their universal applicability [7]. That statute’s assignments included work \nthat NIST began in February 2013 as a result of Executive Order (EO) 13636, Improving Critical \nInfrastructure Cybersecurity [8], which directed the Department of Commerce to lead the \ndevelopment of a voluntary framework to reduce CI cybersecurity risks. Accordingly, NIST \nconvened industry, academia, and government sectors to develop the Framework for Improving \nCritical Infrastructure Cybersecurity (known as the Cybersecurity Framework) that consists of \nstandards, methodologies, procedures, and processes that align policy, business, and \ntechnological approaches to address cybersecurity risks [5]. It offers a high-level vocabulary for \ncybersecurity risk management along with a set of cybersecurity outcomes and a methodology to \nassess and manage those outcomes. \nThe increasing frequency, creativity, and variety of cybersecurity attacks means that all \norganizations should place great emphasis on managing cybersecurity risk as a part of their \nEnterprise Risk Management (ERM) programs to fulfill their mission and business objectives. \nBy integrating the Cybersecurity Framework with NIST cybersecurity risk management \nstandards and guidelines already in wide use at various organizational levels, agencies can \ndevelop, implement, and continuously improve agency-wide cybersecurity risk management \nprocesses that inform strategic, operational, and other enterprise risk decisions.1 \n1.1 Audience \nThis document is intended for those responsible for overseeing, leading, and managing \ninformation systems within their agencies. That includes senior executives, line managers, and \nstaff. It is especially relevant for personnel who develop, implement, report, and improve \nenterprise and cybersecurity risk management processes within their organizations. While the \nfocus is on federal users, NIST expects that many public and private sector organizations that \n \n1 While this report is intended to help federal agencies incorporate key Cybersecurity Framework elements into their programs, \npublication of this document will not affect the Cybersecurity Framework’s primary focus on private sector critical \ninfrastructure owners and operators."
  },
  {
    "chunk_id": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10_chunk_9",
    "filename": "Approaches for Federal Agencies to Use the Cybersecurity Framework_first10.pdf",
    "page_num": 10,
    "text": "NISTIR 8170 \n \nAPPROACHES FOR FEDERAL AGENCIES \nTO USE THE CYBERSECURITY FRAMEWORK \n2 \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8170-upd \nchoose to use the NIST cybersecurity risk management suite of standards and guidelines will \nbenefit from this document. \n1.2 Organization of this report \nThe remainder of this document is structured as follows: \n• Section 2 provides guidance that includes eight approaches for how federal agencies can \neffectively use the Cybersecurity Framework in conjunction with existing NIST standards \nand guidelines to develop, implement, and continuously improve their cybersecurity risk \nmanagement programs. \n• The References section provides links to external sources of additional information. \n• Appendix A lists and explains acronyms that appear in the document. \n• Appendix B defines key terms."
  },
  {
    "chunk_id": "Assessing Federal and Commercial Information Security Needs_first10_chunk_0",
    "filename": "Assessing Federal and Commercial Information Security Needs_first10.pdf",
    "page_num": 1,
    "text": "Assessing Federal and\nCommercial Information\nSecurity Needs\nDavid\nF.\nFerraiolo\nDennis M.\nGiibert\nNickiiyn Lynch\nU.S. DEPARTMENT OF COMMERCE\nTechnology Administration\nNational\nInstitute\nof Standards\nand Technology\nComputer Security\nDivision\nComputer Systems Laboratory\nGaithersburg, MD 20899\nNIST"
  },
  {
    "chunk_id": "Assessing Federal and Commercial Information Security Needs_first10_chunk_1",
    "filename": "Assessing Federal and Commercial Information Security Needs_first10.pdf",
    "page_num": 3,
    "text": "10 ^\nU3\nAssessing Federal and\nCommercial Information\nSecurity Needs\nDavid\nF.\nFerraiolo\nDennis M.\nGiibert\nNickiiyn Lynch\nU.S. DEPARTMENT OF COMMERCE\nTechnology Administration\nNational\nInstitute\nof Standards\nand Technology\nComputer Security\nDivision\nCompHJter Systems Laboratory\nGaithersburg, MD 20899\nNovember 1992\nU.S. DEPARTMENT OF COMMERCE\nBarbara Hackman\nFranklin, Secretary\nTECHNOLOGY ADMINISTRATION\nRobert M. White,\nLinder Secretary for Technology\nNATIONAL INSTITLrrE OF STANDARDS\nAND TECHNOLOGY\nJohn W.\nLyons,\nDirector"
  },
  {
    "chunk_id": "Assessing Federal and Commercial Information Security Needs_first10_chunk_2",
    "filename": "Assessing Federal and Commercial Information Security Needs_first10.pdf",
    "page_num": 5,
    "text": "ABSTRACT\nIn a cooperative effort with government and industry,\nthe National\nInstitute of Standards and Technology\n(NIST)\nconducted\na study to\nassess the current and future information technology\n(IT)\nsecurity\nneeds of the commercial,\ncivil,\nand military sectors.\nThe primary objectives of the study were to:\no\ndetermine a basic set of information protection policies\nand\ncontrol\nobjectives\nthat\npertain\nto\nthe\nsecure\nprocessing needs of organizations within all sectors; and\no\nidentify protection requirements and technical approaches\nthat\nare\nused,\ndesired\nor\nsought\nso\nthey\ncan\nbe\nconsidered for future federal standards and guidelines.\nThe findings of this study address the basic security needs\nof\nIT\nproduct\nusers,\nincluding\nsystem\ndevelopers,\nend\nusers,\nadministrators,\nand\nevaluators.\nSecurity\nneeds\nhave\nbeen\nidentified based\non\nactual\nexisting\nand well-understood\nsecurity\norganizational practices.\ni"
  },
  {
    "chunk_id": "Assessing Federal and Commercial Information Security Needs_first10_chunk_3",
    "filename": "Assessing Federal and Commercial Information Security Needs_first10.pdf",
    "page_num": 6,
    "text": "'.i.\nV\n-.f\n.,\n^si\n'b'di\n,g4T\n\"\n':'\n-V ;iiK\ni...ih,s\n,\n'\n-\n'\n'‘W'\n''ijl\n'\n’\n'\"\n''\n'\n'\n,'\n\"\n''^'\n'\n.,\n,\n'\n,:'\nj.\"\n^\n'\n'\n'\n\"j]\n:s»'t\n'\n\\-m\n..\n't'^-'^;\n'.feoJSti',' |ib\"\n^\n„•\n' ^,, «'\nI'\nn\n''k\n. T'\n^'*>‘\n'\n»'**#\n**t -r\n'4,\n,\n\"\nmm\n^\n‘v\ny\nWJi^sfcs^'\n''Aiti^ t^'\nrtiii'(^y’:ii>^ m^aibCsM'''^it\njj'©' j\n\\\n\"\n*'\nV\n,.\n.*5\nV\nV\n.\n'ifeip^\n,<\n*A’*\n‘*>'\\f’«^. Jli.i1#'V-*\n.r ':pim<'Iu^ 1*^,"
  },
  {
    "chunk_id": "Assessing Federal and Commercial Information Security Needs_first10_chunk_4",
    "filename": "Assessing Federal and Commercial Information Security Needs_first10.pdf",
    "page_num": 7,
    "text": "EXECUTIVE SUMMARY\nThe\nfederal\ngovernment\nand\nprivate\nindustry\nrely\nheavily\non\ninformation\nprocessing\nsystems\nto\nmeet\ntheir\nindividual\noperational,\nfinancial,\nand\ninformation technology\nrequirements.\nCorruption, unauthorized disclosure, or theft of resources have the\npotential\nto disrupt operations\nand could have\nfinancial,\nlegal,\nhuman safety,\npersonal privacy,\nand public confidence\nimpact.\nEach\norganization\ninterviewed\nexhibited\nunique\nsecurity\ncharacteristics described\nin terms of the organization's missions\nand goals.\nSecurity needs were further characterized from system\nto system within an organization.\nSystem and organizational\nsecurity requirements were\nfound\nto\nbe\nbased\non\na\nhigher\nset\nof\nenvironmental\nand\npolicy\nfactors\nand\nconditions.\nComputer security technology\nis\napplied uniquely\nin\neach situation even though there are common concerns.\nBecause\neach\norganization\nhas\nunique\nsecurity\nneeds,\nsecurity\nproducts\nhave\nbeen\napplied\non\na\ncase\nby\ncase\nbasis\nto\nmeet\nindividual\nsecurity\nthreats\nand\nconcerns.\nProducts\nshould\nbe\nflexible enough to serve a broad spectrum of security needs at the\noperating system level,\nthe application level,\nthe organizational\nlevel,\nand the site\nlevel.\nOrganizational\nsecurity\nrequirements\nalso change over time and cannot be totally specified at the time\nof product acquisition.\nFor organizations that process unclassified sensitive information,\nthe availability of\na greater variety of trusted products that go\nbeyond\nC2\nin\nterms\nof\nfunctionality\nand\nflexibility\nis\nneeded.\nThere\nis\na demand to address data\nintegrity\nin\na more direct and\nuser friendly manner.\nVendors should consider new mechanisms that\ndirectly address discretionary and non~discretionary controls, such\nas role-based access controls,\nseparation of duties,\nseparation of\ntransactions,\nand user-oriented least privilege.\nMost organizations\nfelt security standards\nshould\ninclude\na wide\nrange\nof\nassurances\nincluding\na\n\"generally\naccepted\ncommercial\npractice\"\nlevel.\nThis\nnew\nlevel\nshould\nminimize\nthe\ncost\nof\ndeveloping new systems or retro-fitting new security functionality\nin existing systems.\nNearly\nall\nof those\ninterviewed\nexpressed\nthe\ndesire\nto\nhave\nan\nindependent third party give\na \"stamp of approval\" with regard to\nthe trustworthiness of the systems they were buying.\nHowever,\nthe\ncurrent evaluation and certification process\n(i.e., with respect to\na TCSEC class)\nwas not perceived by users\nas meeting their needs\nfor\na variety of reasons.\nThose\ninterviewed\nfelt\nthat\nsecurity\nstandards\nhave\nnot\nemerged\nii"
  },
  {
    "chunk_id": "Assessing Federal and Commercial Information Security Needs_first10_chunk_5",
    "filename": "Assessing Federal and Commercial Information Security Needs_first10.pdf",
    "page_num": 8,
    "text": "that\nwill\nallow\nintegrating\nsecurity\nacross\na\nmulti-vendor\nenvironment.\nA\nsystem\nshould\nprovide\na\nsingle\nuser\nview\nof\nsecurity\nservices\nacross\na\nwide\nrange\nof\noperating\nsystems.\nSecurity features should inter-operate with other security services\non both local and remote machines, without the need to train users\nin new security products.\nSecurity technology must support users\nworking effectively together,\nsharing\ninformation,\nresources\nand\nnetwork\napplications\nfrom\nwhatever\ndesktop\ndevice\nthey\nchoose\nwithin their authority,\nwhile providing\na common\nset\nof\nsecurity\nservices.\nThis\nstudy\nhas\nattempted\nto\nidentify\nbasic\nsecurity\nneeds\nof\ninformation technology product users,\nadministrators,\ndevelopers,\nand evaluators based on actual organizational practices.\nAlthough\nthe findings of this study should not be considered conclusive,\nit\nis hoped that they will be considered in the development of future\nprotection\nrequirements,\nstandards,\nguidelines\nand\nevaluation\nprograms\n.\niii"
  },
  {
    "chunk_id": "Assessing Federal and Commercial Information Security Needs_first10_chunk_6",
    "filename": "Assessing Federal and Commercial Information Security Needs_first10.pdf",
    "page_num": 9,
    "text": "TABLE OF CONTENTS\nPAGE\nABSTRACT\ni\nEXECUTIVE SUMMARY\nii\nLIST OF APPENDICES\nv\n1\nINTRODUCTION\n1.1\nDevelopment of Security Technology\n1-1\n1.2\nNotions of Trust\n1-2\n1.3\nConventions Used\nin this Document\n1-2\n1.4\nDocument Overview\n1-2\n2\nPROJECT APPROACH\n2.1\nOverview\n2-1\n2.2\nProfile of the Organizations\n2-1\n2.3\nTopics Covered\n2-2\n3\nFINDINGS\n3.1\nBasis\nfor Protection\n3-1\n3.1.1\nDriving Reguirements\n3-1\n3.1.2\nTypes of Information\n3-3\n3.2\nSector Protection Requirements\n3-3\n3.2.1\nCommon Notions of Protection\n3-3\n3.2.2\nDistinguishing Protection Characteristics\n.\n.3-5\n3.3\nOrganizational Security Approach\n...\n3-6\n3.3.1\nIdentification and Authentication\n3-6\n3.3.2\nAccess Control\n3-7\n3. 3. 2.1\nDiscretionary Access Control\n.\n.\n.\n.3-7\n3. 3. 2. 2\nRole-Based Controls\n3-8\n3. 3. 2. 3\nSeparation of Transactions\n3-9\n3. 3. 2. 4\nSeparation of Related Duties ....\n3-10\n3. 3. 2. 5\nPrinciple of Least Privilege ....\n3-10\n3. 3. 2. 6\nLabel-Based Mandatory Access\nControls\n3-11\n3. 3. 2. 7\nObject-Label Association\n3-12\n3.3.3\nUser Accountability\n3-12\n3.4\nElectronic Data Interchange\n(EDI)\n3-13\n3.5\nAssurance and Quality\n3-13\n3.6\nEvaluation\n3-14\n3.7\nCurrent Criteria Not Keeping Pace\n3-15\n3.8\nNeed for Security\nin Open Systems\n3-16\n3.9\nOwner-Custodian Relations\n.....\n3-16\n3.10 Security Policies and Environments Can\nChange Over Time\n3-17\nIV"
  },
  {
    "chunk_id": "Assessing Federal and Commercial Information Security Needs_first10_chunk_7",
    "filename": "Assessing Federal and Commercial Information Security Needs_first10.pdf",
    "page_num": 10,
    "text": "PAGE\n4\nCONCLUSIONS\n4.1\nMinimum Security Requirements\n4-1\n4.1.1\nBaseline Capabilities\n4-1\n4.2\nComputer Security Features Enabled by Default\n.\n.\n.4-2\n4.3\nAssurance\n4-2\n4.4\nEvaluation\n4-2\n4.5\nAdministration\n4-3\n4.5.1\nPassword Management\n4-3\n4.5.2\nEDI Capabilities\n4-3\n4.6\nAdd-On Packages\n4-3\n4.7\nCurrent Criteria\n4-4\n4.8\nSecurity Standards\nfor Multi-Vendor Systems\n.\n.\n.\n.4-4\n4.9\nClosing Thoughts\n4-5\nLIST OF\nAPPENDIX\nAPPENDIX\nAPPENDIX\nAPPENDIX\nAPPENDICES\nA:\nLIST OF ORGANIZATIONS\nB:\nSAMPLING OF JOB TITLES\nC:\nSAMPLE QUESTIONS\nD:\nRELATED NIST ACTIVITIES AND SOURCES\nOF INFORMATION\nAPPENDIX A-1\nAPPENDIX B-1\nAPPENDIX C-1\nAPPENDIX D-1\nV"
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_0",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 1,
    "text": "NIST Special Publication 800-53A \nRevision 5 \n \n \nAssessing Security and Privacy Controls in \nInformation Systems and Organizations \n \n \n \n \nJOINT TASK FORCE \n \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-53Ar5"
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_1",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 2,
    "text": "NIST Special Publication 800-53A \nRevision 5 \n \n \n Assessing Security and Privacy Controls \nin Information Systems and \nOrganizations \n \nJOINT TASK FORCE \n \n \n \n \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-53Ar5 \n \n \n \nJanuary 2022 \n \n \n \n \n \n \nU.S. Department of Commerce  \nGina M. Raimondo, Secretary  \n \nNational Institute of Standards and Technology  \nJames K. Olthoff, Performing the Non-Exclusive Functions and Duties of the Under Secretary of Commerce \nfor Standards and Technology & Director, National Institute of Standards and Technology"
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_2",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 3,
    "text": "Authority \nThis publication has been developed by NIST to further its statutory responsibilities under the \nFederal Information Security Modernization Act (FISMA), 44 U.S.C. § 3551 et seq., Public Law \n(P.L.) 113-283. NIST is responsible for developing information security standards and guidelines, \nincluding minimum requirements for federal information systems. Such information security \nstandards and guidelines shall not apply to national security systems without the express \napproval of the appropriate federal officials exercising policy authority over such systems. This \nguideline is consistent with the requirements of the Office of Management and Budget (OMB) \nCircular A-130. \nNothing in this publication should be taken to contradict the standards and guidelines made \nmandatory and binding on federal agencies by the Secretary of Commerce under statutory \nauthority. Nor should these guidelines be interpreted as altering or superseding the existing \nauthorities of the Secretary of Commerce, OMB Director, or any other federal official. This \npublication may be used by nongovernmental organizations on a voluntary basis and is not \nsubject to copyright in the United States. Attribution would, however, be appreciated by NIST.   \nNational Institute of Standards and Technology Special Publication 800-53A Revision 5 \nNatl. Inst. Stand. Technol. Spec. Publ. 800-53A, Rev. 5, 733 pages (January 2022) \nCODEN: NSPUE2 \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-53Ar5 \n \nCertain commercial entities, equipment, or materials may be identified in this document to describe an \nexperimental procedure or concept adequately. Such identification is not intended to imply \nrecommendation or endorsement by NIST, nor is it intended to imply that the entities, materials, or \nequipment are necessarily the best available for the purpose.  \nThere may be references in this publication to other publications currently under development by NIST in \naccordance with its assigned statutory responsibilities. The information in this publication, including \nconcepts, practices, and methodologies may be used by federal agencies even before the completion of \nsuch companion publications. Thus, until each publication is completed, current requirements, guidelines, \nand procedures, where they exist, remain operative. For planning and transition purposes, federal \nagencies may wish to closely follow the development of these new publications by NIST.   \nOrganizations are encouraged to review draft publications during the designated public comment periods \nand provide feedback to NIST. Many NIST publications, other than the ones noted above, are available at \nhttps://csrc.nist.gov/publications. \n \nSubmit comments on this publication to: sec-cert@nist.gov \nNational Institute of Standards and Technology \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 \nAll comments are subject to release under the Freedom of Information Act (FOIA) [FOIA96]."
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_3",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 4,
    "text": "NIST SP 800-53A REV. 5  \nASSESSING SECURITY AND PRIVACY CONTROLS IN INFORMATION SYSTEMS AND ORGANIZATIONS \n_________________________________________________________________________________________________ \nii \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-53Ar5 \nReports on Computer Systems Technology \nThe National Institute of Standards and Technology (NIST) Information Technology Laboratory \n(ITL) promotes the U.S. economy and public welfare by providing technical leadership for the \nNation’s measurement and standards infrastructure. ITL develops tests, test methods, reference \ndata, proof of concept implementations, and technical analyses to advance the development \nand productive use of information technology (IT). ITL’s responsibilities include the development \nof management, administrative, technical, and physical standards and guidelines for the cost-\neffective security of other than national security-related information in federal information \nsystems. The Special Publication 800-series reports on ITL’s research, guidelines, and outreach \nefforts in information systems security and privacy and its collaborative activities with industry, \ngovernment, and academic organizations. \nAbstract \nThis publication provides a methodology and set of procedures for conducting assessments of \nsecurity and privacy controls employed within systems and organizations within an effective risk \nmanagement framework. The assessment procedures, executed at various phases of the system \ndevelopment life cycle, are consistent with the security and privacy controls in NIST Special \nPublication 800-53, Revision 5. The procedures are customizable and can be easily tailored to \nprovide organizations with the needed flexibility to conduct security and privacy control \nassessments that support organizational risk management processes and are aligned with the \nstated risk tolerance of the organization. Information on building effective security and privacy \nassessment plans is also provided with guidance on analyzing assessment results. \nKeywords \nAssessment; assessment plan; assurance; control assessment; FISMA; Privacy Act; privacy \ncontrols; Open Security Controls Assessment Language; OSCAL; privacy requirements; Risk \nManagement Framework; security controls; security requirements."
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_4",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 5,
    "text": "NIST SP 800-53A REV. 5  \nASSESSING SECURITY AND PRIVACY CONTROLS IN INFORMATION SYSTEMS AND ORGANIZATIONS \n_________________________________________________________________________________________________ \niii \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-53Ar5 \nAcknowledgments \nThis publication was developed by the Joint Task Force Interagency Working Group. The group \nincludes representatives from the civil, defense, and intelligence communities. The National \nInstitute of Standards and Technology wishes to acknowledge and thank the senior leaders from \nthe Department of Commerce, Department of Defense, the Office of the Director of National \nIntelligence, the Committee on National Security Systems, and the members of the interagency \nworking group whose dedicated efforts contributed significantly to this publication. \nDepartment of Defense \nOffice of the Director of National \nIntelligence \nHON. John Sherman \nChief Information Officer \nMichael E. Waschull \nActing Chief Information Officer \nDr. Kelly Fletcher \nPrincipal Deputy Chief Information Officer  \nMichael E. Waschull \nDeputy Chief Information Officer \nDavid McKeown \nDeputy CIO for Cybersecurity and DoD CISO \nC. Matthew Conner \nCybersecurity Group and IC CISO \nMark Hakun \nPrincipal Deputy CIO for Cybersecurity \nCheri Benedict \nDirector, Security Coordination Center \nKevin Dulany \nDirector, Cybersecurity Policy and Partnerships \n \nNational Institute of Standards and \nTechnology \nCommittee on National Security \nSystems \nJames St. Pierre \nActing Director, Information Technology Laboratory (ITL) \nMark G. Hakun \nChair \nKevin Stine \nCybersecurity Advisor, ITL \nDominic A. Cussatt \nCo-Chair \nMatthew Scholl \nChief, Computer Security Division \nKevin Dulany \nTri-Chair—Defense Community \nKevin Stine \nChief, Applied Cybersecurity Division \nChris Johnson \nTri-Chair—Intelligence Community \nVictoria Yan Pillitteri \nRisk Management Framework Project Leader  \nVicki Michetti \nTri-Chair—Civil Agencies \nJoint Task Force (JTF) Working Group \nVictoria Yan Pillitteri \nNIST, JTF Leader  \nEduardo Takamura \nNIST \nKelley Dempsey \nNIST \nRon Ross \nNIST \nMcKay Tolboe \nDoD \nDave Myers \nVeterans Affairs \nVicki Michetti \nVeterans Affairs \nNaomi Lefkovitz \nNIST \nAndy Rovnak \nIntelligence Community \nPeter Duspiva \nIntelligence Community \nChris Johnson \nIntelligence Community \nJessica Dickson \nNIST \nAngela Smith \nNIST \nJon Boyens \nNIST \nNed Goren \nNIST \nKaitlin Boeckl \nNIST \nKatie Isaacson \nThe MITRE Corporation \nRandy Gabel \nThe MITRE Corporation \nDavid Black \nThe MITRE Corporation \nPam Miller \nThe MITRE Corporation"
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_5",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 6,
    "text": "NIST SP 800-53A REV. 5  \nASSESSING SECURITY AND PRIVACY CONTROLS IN INFORMATION SYSTEMS AND ORGANIZATIONS \n_________________________________________________________________________________________________ \niv \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-53Ar5 \nIn addition to the above acknowledgments, a special note of thanks goes to Jeff Brewer, Jim \nFoti, Cristina Ritfeld, Isabel Van Wyk, and the NIST web team for their outstanding \nadministrative support, Chris Enloe for his technical review and insight, and to David Waltermire \nand Wendell Piez for their contribution to the development of the SP 800-53A assessment \ntables (both electronic sources, and derivative publications) using Open Security Controls \nAssessment Language (OSCAL). The authors also wish to recognize the professional staff from \nthe NIST Computer Security Division and Applied Cybersecurity Division, and the representatives \nfrom the Federal Chief Information Officer (CIO) Council, Federal Chief Information Security \nOfficer (CISO) Council, and Federal Privacy Council for their ongoing contributions in helping to \nimprove the content of the publication. Finally, the authors gratefully acknowledge the \ncontributions from individuals and organizations in the public and private sectors, both \nnationally and internationally, whose insightful and constructive comments improved the \noverall quality, thoroughness, and usefulness of this publication.  \nHISTORICAL CONTRIBUTIONS TO NIST SPECIAL PUBLICATION 800-53A \n \nThe authors wanted to acknowledge the many individuals who contributed to previous versions of Special \nPublication 800-53A since its inception in 2005. They include Marshall Abrams, Dennis Bailey, Matt \nBarrett, Nadya Bartol, Frank Belz, Paul Bicknell, Deb Bodeau, Brett Burley, Bill Burr, Dawn Cappelli, \nCorinne Castanza, Matt Coose, George Dinolt, Donna Dodson, Randy Easter, Kurt Eleam, Jennifer Fabius, \nDaniel Faigin, Denise Farrar, Harriett Goldman, Peter Gouldmann, Richard Graubart, Jennifer Guild, \nSarbari Gupta, Peggy Himes, Bennett Hodge, Cynthia Irvina, Arnold Johnson, Roger Johnson, Lisa Kaiser, \nStu Katzke, Sharon Keller, Cass Kelly, Steve LaFountain, Steve Lipner, Bill MacGregor, Tom Macklin, Tom \nMadden, Erika McCallister, Tim McChesney, Michael McEvilley, John Mildner, Sandra Miravalle, Joji \nMontelibano, Doug Montgomery, George Moore, Harvey Newstrom, Robert Niemeyer, LouAnna \nNotargiacomo, Dorian Pappas, Tim Polk, Esten Porter, Karen Quigg, Steve Quinn, Ed Roback, George \nRogers, Scott Rose, Mike Rubin, Karen Scarfone, Roger Schell, Matt Scholl, Murugiah Souppaya, Kevin \nStine, Gary Stoneburner, Keith Stouffer, Marianne Swanson, Pat Toth, Glenda Turner, Joe Weiss, Richard \nWilsher, Mark Wilson, John Woodward, and Carol Woody."
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_6",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 7,
    "text": "NIST SP 800-53A REV. 5  \nASSESSING SECURITY AND PRIVACY CONTROLS IN INFORMATION SYSTEMS AND ORGANIZATIONS \n_________________________________________________________________________________________________ \nv \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-53Ar5 \nDocument Conventions  \nFor the purposes of this document, the term “security and privacy” is universally used since the \nguidance is applicable to both security and privacy control assessments. For certain systems, \nhowever, the guidance may only be relevant for security or privacy. Organizations make their \nown determinations on when to manage security and privacy control assessments together or \nseparately. \nSP 800-53A provides guidance on assessing controls in information security program plans, \nprivacy program plans, system security plans, and privacy plans. Where the guidance refers to all \nplans listed above, the term “security and privacy plans” is used. If the guidance is specific to a \nsingle type of plan (e.g., system security plan), the specific type of plan is specified.  \nSupplemental Content \nThe assessment procedures in Chapter 4 are published in multiple data formats, including \ncomma-separated values (CSV), plain text, and Open Security Controls Assessment (OSCAL). The \navailable data formats are accessible from the NIST SP 800-53A Revision 5, publication details \npage at https://csrc.nist.gov/publications/detail/sp/800-53a/rev-5/final. The OSCAL Content Git \nRepository is available at https://github.com/usnistgov/oscal-content. \nThe CSV, plain text, and OSCAL formats represent derivative formats of the (normative) \nassessment procedures in this publication. If there are any discrepancies between the content in \nderivative formats and this publication, please contact sec-cert@nist.gov.   \nPatent Disclosure Notice \nNOTICE: The Information Technology Laboratory (ITL) has requested that holders of patent \nclaims whose use may be required for compliance with the guidance or requirements of this \npublication disclose such patent claims to ITL. However, holders of patents are not obligated to \nrespond to ITL calls for patents and ITL has not undertaken a patent search in order to identify \nwhich, if any, patents may apply to this publication. \nAs of the date of publication and following call(s) for the identification of patent claims whose \nuse may be required for compliance with the guidance or requirements of this publication, no \nsuch patent claims have been identified to ITL. \nNo representation is made or implied by ITL that licenses are not required to avoid patent \ninfringement in the use of this publication."
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_7",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 8,
    "text": "NIST SP 800-53A REV. 5  \nASSESSING SECURITY AND PRIVACY CONTROLS IN INFORMATION SYSTEMS AND ORGANIZATIONS \n_________________________________________________________________________________________________ \nvi \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-53Ar5 \nDEVELOPING COMMON INFORMATION SECURITY AND PRIVACY FOUNDATIONS \nCOLLABORATION AMONG PUBLIC AND PRIVATE SECTOR ENTITIES \n \nIn developing standards and guidelines required by [FISMA], NIST consults with other federal agencies and \noffices as well as private sector entities to improve information security, avoid unnecessary and costly \nduplication of effort, and ensure that NIST publications complement the standards and guidelines \nemployed for the protection of national security systems. In addition to its comprehensive public review \nand vetting process, NIST collaborates with the Office of the Director of National Intelligence (ODNI), the \nDepartment of Defense (DoD), and the Committee on National Security Systems (CNSS) to establish and \nmaintain a unified framework and common foundation for information security across the Federal \nGovernment. A common foundation and framework for information security provides the intelligence, \ndefense, and civilian sectors of the Federal Government and their contractors more uniform and \nconsistent ways to manage risks to organizational operations and assets, individuals, other organizations, \nand the Nation that result from the operation and use of systems. A common foundation and framework \nalso provides a strong basis for the reciprocal acceptance of security authorization decisions and facilitate \ninformation sharing. NIST also works with public and private sector entities to establish and maintain \nspecific mappings and relationships between the security standards and guidelines developed by NIST, the \nInternational Organization for Standardization (ISO), and the International Electrotechnical Commission \n(IEC)."
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_8",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 9,
    "text": "NIST SP 800-53A REV. 5  \nASSESSING SECURITY AND PRIVACY CONTROLS IN INFORMATION SYSTEMS AND ORGANIZATIONS \n_________________________________________________________________________________________________ \nvii \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-53Ar5 \nASSESSMENT PROCEDURE FORMATTING \n \nThe new format for assessment procedures introduced in Special Publication (SP) 800-53A Revision 4, is \nfurther improved in this revision (SP 800-53A Revision 5). The format continues to reflect the \ndecomposition of assessment objectives into more granular determination statements wherever possible, \nthus providing the capability to identify and assess specific parts of security and privacy controls. Updates \nto SP 800-53A Revision 5: \n \n• \nIdentify determination statements for organization-defined parameters (ODPs) first and separately \nfrom the determination statements for each control item; \n• \nImprove the readability of the assessment procedures; \n• \nProvide a structured schema for automated tools when assessment information is imported into such \ntools; \n• \nProvide greater flexibility in conducting assessments by giving organizations the capability to target \ncertain aspects of controls (highlighting the particular weaknesses and/or deficiencies in controls),  \n• \nImprove the efficiency of security and privacy control assessments; \n• \nSupport continuous monitoring and ongoing authorization programs by providing a greater number \nof component parts of security and privacy controls that can be assessed at organization-defined \nfrequencies and degrees of rigor. \n \nThe ability to apply assessment and monitoring resources in a targeted and precise manner and \nsimultaneously maximize the use of automation technologies can result in more timely and cost-effective \nassessment processes for organizations. \n \nNote: NIST [SP 800-53] will be updated accordingly to ensure that the numbering scheme for all security and privacy \ncontrols is consistent with the new format introduced in this publication."
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_9",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 10,
    "text": "NIST SP 800-53A REV. 5  \nASSESSING SECURITY AND PRIVACY CONTROLS IN INFORMATION SYSTEMS AND ORGANIZATIONS \n_________________________________________________________________________________________________ \nviii \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-53Ar5 \nExecutive Summary \nSecurity and privacy control assessments are not about checklists, simple pass/fail results, or \ngenerating paperwork to pass inspections or audits. Rather, control assessments are the \nprincipal vehicle used to verify that selected security and privacy controls are implemented and \nmeeting stated goals and objectives. Special Publication (SP) 800-53A, Assessing Security and \nPrivacy Controls in Information Systems and Organizations, facilitates security control \nassessments and privacy control assessments conducted within an effective risk management \nframework. A major design objective for SP 800-53A is to provide an assessment framework and \ninitial starting point for assessment procedures that are flexible enough to meet the needs of \ndifferent organizations while providing consistency in conducting control assessments. Control \nassessment results provide organizational officials with: \n• \nEvidence of the effectiveness of implemented controls, \n• \nAn indication of the quality of the risk management processes, and \n• \nInformation about the security and privacy strengths and weaknesses of systems that \nare supporting organizational missions and business functions. \nThe findings identified by assessors are used to determine the overall effectiveness of security \nand privacy controls associated with systems and their environments of operation and to \nprovide credible and meaningful inputs to the organization’s risk management process. A well-\nexecuted assessment helps determine the validity of the controls contained in the organization’s \nsecurity and privacy plans and subsequently employed in organizational systems and \nenvironments of operation.  Control assessments facilitate a cost-effective approach to \nmanaging risk by identifying weaknesses or deficiencies in systems, thus enabling the \norganization to determine appropriate risk responses in a disciplined manner that is consistent \nwith organizational mission and business needs. \nSP 800-53A is a companion guideline to [SP 800-53] Security and Privacy Controls for Systems \nand Organizations. Each publication provides guidance for implementing specific steps in the \nRisk Management Framework (RMF).1 SP 800-53 and [SP 800-53B] address the Select step of the \nRMF and provide guidance on security and privacy control selection (i.e., determining the \ncontrols needed to manage risks to organizational operations and assets, individuals, other \norganizations, and the Nation). SP 800-53A addresses the Assess and Monitor steps of the RMF \nand provides guidance on the security and privacy control assessment processes. SP 800-53A \nalso includes guidance on how to build effective assessment plans and how to analyze and \nmanage assessment results. \nSP 800-53A provides a process that allows organizations to tailor the assessment procedures \noutlined in the guidance. Tailoring involves customizing the assessment procedures to match \nthe characteristics of the system and its environment of operation more closely. The tailoring \nprocess described in this guidance gives organizations the flexibility needed to avoid assessment \napproaches that are unnecessarily complex or costly while simultaneously meeting the \nassessment requirements and risk management principles established in the RMF. Tailoring \ndecisions are left to the discretion of the organization to maximize flexibility in developing \nassessment plans – applying the results of risk assessments to determine the extent, rigor, and \nlevel of intensity of the assessments needed to provide sufficient assurance about the security \nand privacy posture of the system.  \n \n \n1 [SP 800-37], Risk Management Framework for Information Systems and Organizations: A System Life Cycle Approach \nfor Security and Privacy, provides guidance on applying the RM"
  },
  {
    "chunk_id": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10_chunk_10",
    "filename": "Assessing Security and Privacy Controls in Information Systems and Organizations_first10.pdf",
    "page_num": 10,
    "text": " in the RMF. Tailoring \ndecisions are left to the discretion of the organization to maximize flexibility in developing \nassessment plans – applying the results of risk assessments to determine the extent, rigor, and \nlevel of intensity of the assessments needed to provide sufficient assurance about the security \nand privacy posture of the system.  \n \n \n1 [SP 800-37], Risk Management Framework for Information Systems and Organizations: A System Life Cycle Approach \nfor Security and Privacy, provides guidance on applying the RMF to systems and organizations."
  },
  {
    "chunk_id": "Assessing Security Requirements for Controlled Unclassified Information_first10_chunk_0",
    "filename": "Assessing Security Requirements for Controlled Unclassified Information_first10.pdf",
    "page_num": 1,
    "text": "NIST Special Publication 800 \nNIST SP 800-171Ar3 \nAssessing Security Requirements for \nControlled Unclassified Information \nRon Ross \nVictoria Pillitteri \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-171Ar3"
  },
  {
    "chunk_id": "Assessing Security Requirements for Controlled Unclassified Information_first10_chunk_1",
    "filename": "Assessing Security Requirements for Controlled Unclassified Information_first10.pdf",
    "page_num": 2,
    "text": "NIST Special Publication  \nNIST SP 800-171Ar3  \nAssessing Security Requirements for \nControlled Unclassified Information \nRon Ross \nVictoria Pillitteri \nComputer Security Division \nInformation Technology Laboratory \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.SP.800-171Ar3 \nMay 2024 \n \n \nU.S. Department of Commerce  \nGina M. Raimondo, Secretary \nNational Institute of Standards and Technology  \nLaurie E. Locascio, NIST Director and Under Secretary of Commerce for Standards and Technology"
  },
  {
    "chunk_id": "Assessing Security Requirements for Controlled Unclassified Information_first10_chunk_2",
    "filename": "Assessing Security Requirements for Controlled Unclassified Information_first10.pdf",
    "page_num": 3,
    "text": "NIST SP 800-171Ar3 \n \n Assessing CUI Security Requirements \nMay 2024 \n \n  \nCertain equipment, instruments, software, or materials, commercial or non-commercial, are identified in this \npaper in order to specify the experimental procedure adequately. Such identification does not imply \nrecommendation or endorsement of any product or service by NIST, nor does it imply that the materials or \nequipment identified are necessarily the best available for the purpose. \nThere may be references in this publication to other publications currently under development by NIST in \naccordance with its assigned statutory responsibilities. The information in this publication, including concepts and \nmethodologies, may be used by federal agencies even before the completion of such companion publications. \nThus, until each publication is completed, current requirements, guidelines, and procedures, where they exist, \nremain operative. For planning and transition purposes, federal agencies may wish to closely follow the \ndevelopment of these new publications by NIST. \nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback \nto NIST. Many NIST cybersecurity publications, other than the ones noted above, are available at \nhttps://csrc.nist.gov/publications. \nAuthority \nThis publication has been developed by NIST in accordance with its statutory responsibilities under the Federal \nInformation Security Modernization Act (FISMA) of 2014, 44 U.S.C. § 3551 et seq., Public Law (P.L.) 113-283 [1]. \nNIST is responsible for developing information security standards and guidelines, including minimum requirements \nfor federal information systems, but such standards and guidelines shall not apply to national security systems \nwithout the express approval of appropriate federal officials exercising policy authority over such systems. This \nguideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130 [2]. \n \nNothing in this publication should be taken to contradict the standards and guidelines made mandatory and \nbinding on federal agencies by the Secretary of Commerce under statutory authority. Nor should these guidelines \nbe interpreted as altering or superseding the existing authorities of the Secretary of Commerce, Director of the \nOMB, or any other federal official. This publication may be used by nongovernmental organizations on a voluntary \nbasis and is not subject to copyright in the United States. Attribution would, however, be appreciated by NIST.  \nNIST Technical Series Policies \nCopyright, Use, and Licensing Statements \nNIST Technical Series Publication Identifier Syntax \nPublication History \nApproved by the NIST Editorial Review Board on 2024-04-23 \nSupersedes NIST Special Publication 800-171A (June 2018) https://doi.org/10.6028/NIST.SP.800-171A \nHow to Cite this NIST Technical Series Publication:  \nRoss R, Pillitteri V (2024) Assessing Security Requirements for Controlled Unclassified Information \nand Organizations. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication \n(SP) NIST SP 800-171Ar3. https://doi.org/10.6028/NIST.SP.800-171Ar3 \nAuthor ORCID iDs \nRon Ross: 0000-0002-1099-9757 \nVictoria Pillitteri: 0000-0002-7446-7506"
  },
  {
    "chunk_id": "Assessing Security Requirements for Controlled Unclassified Information_first10_chunk_3",
    "filename": "Assessing Security Requirements for Controlled Unclassified Information_first10.pdf",
    "page_num": 4,
    "text": "NIST SP 800-171Ar3 \n \n Assessing CUI Security Requirements \nMay 2024 \n \n  \nSubmit Comments \n800-171comments@list.nist.gov \nNational Institute of Standards and Technology \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 \nAdditional Information \nAdditional information about this publication is available at https://csrc.nist.gov/pubs/sp/800/171/a/r3/final, \nincluding related content, potential updates, and document history. \nAll comments are subject to release under the Freedom of Information Act (FOIA)."
  },
  {
    "chunk_id": "Assessing Security Requirements for Controlled Unclassified Information_first10_chunk_4",
    "filename": "Assessing Security Requirements for Controlled Unclassified Information_first10.pdf",
    "page_num": 5,
    "text": "NIST SP 800-171Ar3 \n \n Assessing CUI Security Requirements \nMay 2024 \n \n  \ni \nAbstract \nThe protection of Controlled Unclassified Information (CUI) is of paramount importance to \nfederal agencies and can directly impact the ability of the Federal Government to successfully \nconduct its essential missions and functions. This publication provides organizations with \nassessment procedures and a methodology that can be used to conduct assessments of the \nsecurity requirements in NIST Special Publication 800-171, Protecting Controlled Unclassified \nInformation in Nonfederal Systems and Organizations. The assessment procedures are flexible \nand can be customized to the needs of organizations and assessors. Assessments can be \nconducted as independent, third-party assessments or as government-sponsored assessments. \nThe assessments can be applied with various degrees of rigor based on customer-defined depth \nand coverage attributes. \nKeywords \nassessment; assessment method; assessment object; assessment procedure; assurance; \nControlled Unclassified Information; coverage; FISMA; NIST Special Publication 800-171; NIST \nSpecial Publication 800-53A; nonfederal organization; nonfederal system; security assessment; \nsecurity requirement. \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test \nmethods, reference data, proof of concept implementations, and technical analyses to advance \nthe development and productive use of information technology. ITL’s responsibilities include \nthe development of management, administrative, technical, and physical standards and \nguidelines for the cost-effective security and privacy of other than national security-related \ninformation in federal information systems. The Special Publication 800-series reports on ITL’s \nresearch, guidelines, and outreach efforts in information system security, and its collaborative \nactivities with industry, government, and academic organizations."
  },
  {
    "chunk_id": "Assessing Security Requirements for Controlled Unclassified Information_first10_chunk_5",
    "filename": "Assessing Security Requirements for Controlled Unclassified Information_first10.pdf",
    "page_num": 6,
    "text": "NIST SP 800-171Ar3 \n \n Assessing CUI Security Requirements \nMay 2024 \n \n  \nii \nAudience \nThis publication serves a diverse group of individuals and organizations in the public and private \nsectors, including individuals with: \n• System development life cycle responsibilities (e.g., program managers, \nmission/business owners, information owners/stewards, system designers and \ndevelopers, system/security engineers, systems integrators) \n• Acquisition or procurement responsibilities (e.g., contracting officers) \n• System, security, or risk management and oversight responsibilities (e.g., authorizing \nofficials, chief information officers, chief information security officers, system owners, \ninformation security managers) \n• Security assessment and monitoring responsibilities (e.g., auditors, system evaluators, \nassessors, independent verifiers/validators, analysts) \nThe above roles and responsibilities can be viewed from two perspectives: \n• Federal perspective: The entity establishing and conveying security assessment \nrequirements in contractual vehicles or other types of agreements \n• Nonfederal perspective: The entity responding to and complying with the security \nassessment requirements set forth in contracts or agreements"
  },
  {
    "chunk_id": "Assessing Security Requirements for Controlled Unclassified Information_first10_chunk_6",
    "filename": "Assessing Security Requirements for Controlled Unclassified Information_first10.pdf",
    "page_num": 7,
    "text": "NIST SP 800-171Ar3 \n \n Assessing CUI Security Requirements \nMay 2024 \n \n  \niii \nPatent Disclosure Notice \nNOTICE: ITL has requested that holders of patent claims whose use may be required for \ncompliance with the guidance or requirements of this publication disclose such patent claims to \nITL. However, holders of patents are not obligated to respond to ITL calls for patents and ITL has \nnot undertaken a patent search in order to identify which, if any, patents may apply to this \npublication. \nAs of the date of publication and following call(s) for the identification of patent claims whose \nuse may be required for compliance with the guidance or requirements of this publication, no \nsuch patent claims have been identified to ITL.  \nNo representation is made or implied by ITL that licenses are not required to avoid patent \ninfringement in the use of this publication."
  },
  {
    "chunk_id": "Assessing Security Requirements for Controlled Unclassified Information_first10_chunk_7",
    "filename": "Assessing Security Requirements for Controlled Unclassified Information_first10.pdf",
    "page_num": 8,
    "text": "NIST SP 800-171Ar3 \n \n Assessing CUI Security Requirements \nMay 2024 \n \n  \niv \nTable of Contents \n1. Introduction ...................................................................................................................................1 \n2. The Fundamentals ..........................................................................................................................3 \n3. The Procedures ..............................................................................................................................7 \nReferences ....................................................................................................................................... 99 \nAppendix A. Acronyms ................................................................................................................... 100 \nAppendix B. Glossary ..................................................................................................................... 101 \nAppendix C. Security Requirement Assessment............................................................................... 103 \nAppendix D. Organization-Defined Parameters ............................................................................... 107 \nAppendix E. Change Log ................................................................................................................. 112"
  },
  {
    "chunk_id": "Assessing Security Requirements for Controlled Unclassified Information_first10_chunk_8",
    "filename": "Assessing Security Requirements for Controlled Unclassified Information_first10.pdf",
    "page_num": 9,
    "text": "NIST SP 800-171Ar3 \n \n Assessing CUI Security Requirements \nMay 2024 \n \n  \nv \nList of Tables \nTable 1. Security Requirement Families ..............................................................................................3 \nTable 2. Summary of Assessment Preparation Phase ....................................................................... 104 \nTable 3. Summary of Assessment Plan Development Phase ............................................................. 105 \nTable 4. Summary of Assessment Execution Phase .......................................................................... 106 \nTable 5. Summary of Assessment Analysis, Documentation, and Reporting Phase ........................... 106 \nTable 6. Organization-Defined Parameters ...................................................................................... 107 \nTable 7. Change Log ....................................................................................................................... 113"
  },
  {
    "chunk_id": "Assessing Security Requirements for Controlled Unclassified Information_first10_chunk_9",
    "filename": "Assessing Security Requirements for Controlled Unclassified Information_first10.pdf",
    "page_num": 10,
    "text": "NIST SP 800-171Ar3 \n \n Assessing CUI Security Requirements \nMay 2024 \n \n  \nvi \nAcknowledgments \nThe authors gratefully acknowledge and appreciate the significant contributions from \nindividuals and organizations in the public and private sectors whose constructive comments \nimproved the overall quality, thoroughness, and usefulness of this publication. The authors also \nwish to thank the NIST technical editing and production staff – Jim Foti, Jeff Brewer, Eduardo \nTakamura, Isabel Van Wyk, Cristina Ritfeld, Derek Sappington, and Chris Enloe – for their \noutstanding support in preparing this document for publication. \nHistorical Contributions \nThe authors wish to acknowledge the following individuals for their historic contributions to \nthis publication: Jon Boyens, Devin Casey, Ned Goren, Gary Guissanie, Jody Jacobs, Jeff Marron, \nVicki Michetti, Mark Riddle, Mary Thomas, Gary Stoneburner, Patricia Toth, and Patrick Viscuso."
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_0",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 1,
    "text": "A111D3\nDflTSbb\nNATL INST OF STANDARDS & TfCH R.I.C.\nA1 11 03089566\nNBS Invitational Wor/Aud^ and evaluatio\nQC100 .U57 NO.500-19, 1977 C.2 NBS-PUB-O\nIMCE & TECHNOLOGY:\nUDIT AND EVALUATION\nOF COMPUTER SECURITY\niO-19\nNBS Special\nPublication 500-19\nU.S. DEPARTMEMT OF COMMERCE\nNational Bureau\nof Standards"
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_1",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 2,
    "text": "NATIONAL BUREAU OF STANDARDS\nThe National Bureau of Standards^ was established by an\nact of Congress March\n3,\n1901. The Bureau's overall goal\nis\nto\nstrengthen and advance the Nation's science and technology and facilitate their effective application for public benefit. To this\nend, the Bureau conducts research and provides:\n(1) a basis for the Nation's physical measurement system,\n(2)\nscientific and\ntechnological services for industry and government,\n(3) a technical basis for equity\nin trade, and (4) technical services to pro-\nmote public safety. The Bureau consists of the Institute for Basic Standards, the Institute for Materials Research, the Institute\nfor Applied Technology, the Institute for Computer Sciences and Technology, the Office\nfor Information Programs, and the\nOffice of Experimental Technology Incentives Program.\nTHE INSTITUTE FOR BASIC STANDARDS provides the central basis within the United States of a complete and consist-\nent system of physical measurement; coordinates that system with measurement systems of other nations; and furnishes essen-\ntial services leading to accurate and uniform physical measurements throughout the Nation's\nscientific community,\nindustry,\nand commerce. The Institute consists of the Office of Measurement Services, and the following center and divisions:\nApplied Mathematics — Electricity — Mechanics — Heat — Optical Physics — Center for Radiation Research — Lab-\noratory Astrophysics- — Cryogenics^ — Electromagnetics — Time and Frequency'.\nTHE INSTITUTE FOR MATERIALS RESEARCH conducts\nmaterials research leading\nto improved methods of measure-\nment, standards, and data on the properties of well-characterized materials needed by industry, commerce, educational\ninsti-\ntutions, and Government: provides advisory and research services to other Government agencies; and develops, produces, and\ndistributes standard reference materials. The Institute consists of the Office of Standard Reference Materials, the Office of Air\nand Water Measurement, and the following divisions:\nAnalytical Chemistry — Polymers — Metallurgy — Inorganic Materials — Reactor Radiation — Physical Chemistry.\nTHE INSTITUTE FOR APPLIED TECHNOLOGY provides\ntechnical\nservices developing and promoting the use of\navail-\nable technology; cooperates with public and private organizations in developing technological standards, codes, and test meth-\nods; and provides technical advice services, and information to Government agencies and the public. The Institute consists of\nthe following divisions and centers:\nStandards Application and Analysis —\n• Electronic Technology — Center\nfor Consumer Product Technology: Product\nSystems Analysis; Product Engineering — Center for Building Technology;\nStructures,\nMaterials,\nand\nSafety;\nBuilding\nEnvironment; Technical Evaluation and Application — Center for Fire Research: Fire Science; Fire Safety Engineering.\nTHE INSTITUTE FOR COMPUTER SCIENCES AND TECHNOLOGY conducts\nresearch and provides\ntechnical\nservices\ndesigned to aid Government agencies in improving cost effectiveness\nin the conduct of their programs through\nthe\nselection,\nacquisition, and effective utilization of automatic data processing equipment: and serves as the principal focus wthin the exec-\nutive branch\nfor the development of Federal standards for automatic data processing equipment,\ntechniques, and computer\nlanguages. The\nInstitute consist of the following\ndivisions:\nComputer Services — Systems and Software — Computer Systems Engineering — Information Technology.\nTHE OFFICE OF EXPERIMENTAL TECHNOLOGY INCENTIVES PROGRAM seeks to affect public policy and process\nto facilitate technological change\nin the private sector by examining and experimenting with Government policies and prac-\ntices in order to identify and remove Government-related barriers and\nto correct inherent market imperfections\nthat impede\nthe innovation process.\nTHE OFFICE FOR INFORMATION PROGRAMS promotes optimum dissemination and accessibility of scientific inform"
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_2",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 2,
    "text": "divisions:\nComputer Services — Systems and Software — Computer Systems Engineering — Information Technology.\nTHE OFFICE OF EXPERIMENTAL TECHNOLOGY INCENTIVES PROGRAM seeks to affect public policy and process\nto facilitate technological change\nin the private sector by examining and experimenting with Government policies and prac-\ntices in order to identify and remove Government-related barriers and\nto correct inherent market imperfections\nthat impede\nthe innovation process.\nTHE OFFICE FOR INFORMATION PROGRAMS promotes optimum dissemination and accessibility of scientific informa-\ntion generated within NBS; promotes the development of the National Standard Reference Data System and a system of\nin-\nformation analysis centers dealing with the broader aspects of the National Measurement System; provides appropriate services\nto ensure that the NBS staff has optimum accessibility to the\nscientific information of the world. The\nOffice\nconsists\nof\nthe\nfollowing organizational units:\nOffice of Standard Reference Data — Office of Information Activities — Office of Technical Publications — Library —\nOffice of International Standards — Office of International Relations.\n' Headquarters and Laboratories\nat Gaithersburg, Maryland, imless\notherwise noted; mailing address Washington, D.C. 20234.\n^ Located at Boulder, Colorado 80302."
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_3",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 3,
    "text": "ona!\nBureau\noi\ni>ianaarg®\nOCT\n2\n6\n1977\n-\nCOMPUTER SCIENCE & TECHNOLOGY:\n>cioo\n.)^^\nAudit and Evaluation\n1)6\nof Computer Security\n^\nProceedings of the NBS Invitational Workshop\nheld at Miami Beach, Florida, March 22-24, 1977\nEdited by:\nZella G. Ruthberg\nInstitute for Computer Sciences and Technology\nNational Bureau of Standards\nWashington, D. C.\n20234\nRobert G. McKenzie\nGeneral Accounting Office\nWashington, D. C.\n20548\nSession Chairpersons;\nWilliam E. Perry\nC. O. Smith\nBlake Greenlee\nCarl Hammer\nW. H. Murray\nClark Weissman\nLeonard\n1. Krauss\nJerry FitzGerald\nRichard D. Webb\nHart J. Will\n^^^^^^ °'\noo,\nU.S. DEPARTMENT OF COMMERCE, Juanita M. Kreps, Secretary\nDr. Sidney Harman, Under Secretary\nJordan\nJ. Baruch, Assistant Secretary for Science and Technology\nU A\n.\nNATIONAL BUREAU OF STANDARDS, Ernest Ambler, Acting Director\nIssued October 1977"
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_4",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 4,
    "text": "Reports on Computer Science and Technology\nThe National Bureau of Standards has a special responsibility within the Federal\nGovernment for computer science and technology activities. The programs of the\nNBS Institute for Computer Sciences and Technology are designed to provide ADP\nstandards, guidelines, and technical advisory services to improve the effectiveness of\ncomputer utilization in the Federal sector, and to perform appropriate research and\ndevelopment efforts as foundation for such activities and programs. This publication\nseries will report these NBS efforts to the Federal computer community as well as to\ninterested specialists\nin the academic and private sectors. Those wishing to receive\nnotices of publications in this series should complete and return the form at the end\nof this publication.\nNational Bureau of Standards Special Publication 500-19\nNat. Bur. Stand. (U.S.), Spec. Publ. 500-19, 256 pages (Oct.\n1977)\nCODEN: XNBSAV\nLibrary of Congress Catalog Card Number:\n77-600045\nU.S. GOVERNMENT PRINTING OFFICE\nWASHINGTON:\n1977\nFor\nsale\nby\nthe\nSuperintendent\nof\nDocuments,\nU.S.\nGovernment\nPrinting\nOffice,\nWashington,\nD.C.\n20402\nPrice $4—Stock No. 003-003-01848-1"
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_5",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 5,
    "text": "FOREWORD\nThe increasing use of computers\nby Government and private organiza-\ntions\nfor\nthe storage and manipulation of records of all kinds—personal\nas well\nas of a business nature— has placed computers and the systems\nin\nwhich they reside in an extremely sensitive position\nin our society.\nThe\nneeds of the individual\nas well as Government and private organizations\nrequire\nthat\nthis data and their resident\nsystems\nbe accurate and reli-\nable.\nThese needs also require that this data and these systems\nbe\ngiven adequate protection from threats and hazards.\nThe establishment of\nsecure computer systems\nis\nthe way in which the computer community as-\nsures the users\nof such systems that all of these requirements are being\nmet\n.\nThe auditing and evaluating\nof computer systems\nfor adequate secu-\nrity has been\na natural outgrowth of this widening interest\nin this\narea.\nControls that provide computer security are\nof interest\nto both\nthe financial\nand internal auditors and has been made\na subject\nof spe-\ncial consideration by organizations such as\nthe Institute of Internal\nAuditors,\nthe American Institute\nof Certified\nPublic Accountants,\nand\nthe EDP Auditors Associtation.\nThe National Bureau of Standards, with the support of the U.S.\nGen-\neral Accounting Office,\nsponsored\nan invitational workshop\nin March of\n1977\nto explore\nthe subject of \"Audit and Evaluation of Computer Securi-\nty.\"\nLeading experts\nin the audit\nand computer communities were invited\nto share their thoughts and develop a consensus view on ten aspects of\nthe\nsubject.\nThese Proceedings are\nthe results of that meeting.\nTo all\nthose concerned with the audit and evaluation of computer\nsecurity\ntoday,\nwe at the National Bureau of Standards offer this series\nof consensus reports\nfor your consideration.\nThe views expressed\ndo not\nnecessarily reflect those of the National Bureau of Standards,\nthe\nU.\nS.\nGeneral Accounting Office,\nor any of the organizations that\nsponsored an\nindividual\nat\nthe workshop.\nHowever,\nthese reports do reflect\nthe compo-\nsite thoughts of a group that deserves your serious attention.\nM.\nZane Thornton\nActing Director\nInstitute\nfor Computer\nSciences and Technology\niil"
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_6",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 6,
    "text": "PREFACE\nThe National Bureau of Standards\n(NBS)\ninitiated\na Task Group\nwithin the Federal\nInformation Processing Standards\n(FIPS)\nprogram in\n1973\nto develop standards\nin Computer Systems Security.\nTask Group\n15\n(TG-15)\nwas composed of representatives\nfrom private industry as well as\nFederal,\nState and local governments.\nThe NBS Invitational Workshop on\nAudit and Evaluation of Computer Security was organized as one phase\nof\na two-phase project defined\nby the Task Group\nin this important area of\ncomputer security.\nThese Proceedings are\nthe result of phase\none.\nThe\nsecond phase will\nbe\nto adapt this information\nto\nthe needs of Federal\nagencies\nin the form of Federal\nInformation Processing Guidelines.\nThis\nlatter effort will\nbe carried\nout\nby a working group convened\nfor this\npurpose\nand will result\nin\na FIPS publication by NBS.\nThe General Chairman and organizer of the Workshop was Robert\nG.\nMcKenzie\nof the\nU.S.\nGeneral Accounting Office.\nAs leader of the TG-15\nproject on computer security auditing,\nhe\ninitiated and planned\nthe\nWorkshop and co-edited these Proceedings.\nMr.\nMcKenzie\nis an audit\nmanager at GAG and has conducted\na number\nof reviews\nof computer securi-\nty of proposed and on-going systems\nin\nthe Federal Government.\nThe General Vice-Chairman of the Workshop was Zella\nG.\nRuthberg\nof\nthe National Bureau of Standards.\nAs NBS coordinator of the TG-15\nsecu-\nrity audit\nproject,\nMrs.\nRuthberg worked closely with Mr.\nMcKenzie\non\nthe planning,\nacted as the Workshop arrangements chairman,\nand\nis co-\neditor of these Proceedings.\nShe has conducted\na wide range of projects\nin computer science at NBS and most recently has become active in the\nmanagerial procedures required\nfor computer security.\nMr.\nS.\nJeffery,\nChief of the Systems and Software Division of the\nInstitute\nfor Computer Sciences and Technology of NBS,\nheaded the NBS\nstaff at the Workshop.\nMr.\nJeffery has been active in the formulation\nof policy concerning the effective utilization of computers within the\nFederal Government and\nis manager of the computer program at\nNBS.\nThis\nprogram provided\nthe needed technical\nand administrative support\nfor\nthis Workshop.\nI would\nlike to thank all\nof the particitpants\nin this Workshop,\nthe Chairmen and Recorders\nof the\nsessions,\nand\nthe three individuals\nnamed above for the success of the Workshop.\nThe products\nto\nbe derived\nfrom the Workshop and subsequent efforts\nin this area will have far-\nreaching,\nbeneficial\neffects on the use of computers throughout\nthe\ncountry\nDennis\nK.\nBrans tad\nChairman,\nTG-15\niv"
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_7",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 7,
    "text": "ABSTRACT\nThe National Bureau of Standards,\nwith the support of the U.S.\nGen-\neral Accounting Office,\nsponsored an invitational workshop\non \"Audit and\nEvaluation of Computer Security,\"\nheld\nin Miami Beach,\nFlorida on March\n22-24,\n1977.\nIts purpose was\nto explore\nthe state-of-the-art\nin this\narea and define appropriate subjects for future research.\nLeading\nex-\nperts\nin\nthe audit and computer communities were invited\nto discuss the\nsubject\nin one\nof ten sessions,\neach of which considered\na different as-\npect.\nA consensus report was produced\nby each of the ten sessions and\nthese reports form the body of these Proceedings.\nThe ten topics re-\nported\non are:\nInternal Audit Standards,\nQualifications and Training,\nSecurity Administration,\nAudit Considerations\nin Various System Environ-\nments,\nAdministrative and Physical\nControls,\nProgram Integrity,\nData In-\ntegrity,\nCommunications,\nPost-Processing Audit Tools and Techniques,\nand\nInteractive Audit Tools and Techniques.\nKEYWORDS:\nAudit\nstandards,\naudit techniques,\naudit\ntools,\naudit\ntraining,\ncommunications security,\ncomputer controls,\ncomputer\nsecurity,\ndata integrity,\ninteractive audit,\ninternal\naudit,\npost-\nprocessing audit,\nprogram integrity."
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_8",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 8,
    "text": "ACKNOViLEDGEMENTS\nThe success of the Workshop was dependent\non the work of many peo-\nple.\nWe would particularly like\nto\ntake this opportunity to thank all\nthe Session Chairmen,\nthe Session Recorders,\nand the attendees\nfor their\nefforts\nin behalf of this Workshop.\nWe would also like\nto thank the\nses-\nsion coordinators Robert\nV.\nJacobson,\nJohn Panagacos,\nand Thomas\nC.\nLowe\nfor making things run smoothly while the Workshop was taking place;\nand\nDennis\nK.\nBranstad\nfor photographing scenes from the Workshop.\nTHE EDITORS\nvi"
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_9",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 9,
    "text": "TABLE OF CONTENTS\nFOREWORD\niii\nPREFACE\niv\nEXECUTIVE SUMMARY\nxix\nPART\nI:\nINTRODUCTION\n1-1\n1.\nHOST WELCOMING ADDRESS\n1-1\n2.\nEDITORS'\nCOMMENTS\nON THE SESSIONS AND THE REPORTS\n...\n1-3\n2.1\nSome Definitions\nof Terms\n1-3\n2.2\nObservations\n1-4\n2.3\nReading\nthe Proceedings\n1-4\nPART\nII:\nKEYNOTE ADDRESS\n2-1\n1.\nINTRODUCTION\n2-2\n2.\nAN APPROACH TO THE WORKSHOP\n2-2\n3.\nCOMMENTS\nON\nPROPOSED TOPICS\n........\n2-3\n3.1\nInternal\nAudit Standards\n....\n2-3\n3.2\nQualifications\nand Training ............\n2-3\n3.3\nSecurity Administration\n.....\n2-4\n3.4\nAudit Considerations\nin Various System\nEnvironments\n.....\n2-4\n3.5\nAdministrative and\nPhysical\nControls\n.......\n2-4\n3.6\nProgram\nIntegrity\n.....\n2-4\n3.7\nData\nIntegrity\n2-4\n3.8\nCommunications\n2-5\n3.9\nPost-Processing Audit Tools\nand Techniques\n....\n2-5\n3.10\nInteractive Audit Tools\nand Techniques\n2-5\nPART\nIII:\nINTERNAL AUDIT STANDARDS\n......\n3-1\nEDITORS'\nNOTE .......................\n3-2\nSupplemental\nStandards\nfor\nInternal\nAuditor's\nExpanded\nRole\nin Reviewing Computer Systems\nand Their Development\n.\n.\n3-3\n1.\nINTRODUCTION\n3-3\n1.1\nAutomated Systems\nEffect on Environment ......\n3-3\n1.2\nComputer Security Defined .............\n3-3\n1.3\nDiscussion\nof Audit\nInvolvement\nin Computer\n1.4\nChanging Auditor Requirement ...........\n3-5\nvi i"
  },
  {
    "chunk_id": "Audit and Evaluation of Computer Security_first10_chunk_10",
    "filename": "Audit and Evaluation of Computer Security_first10.pdf",
    "page_num": 10,
    "text": "2.\nSUPPLEMENTAL STANDARDS\nFOR COMPUTER INTERNAL AUDIT\nWORK\n„\n.\no\n.\n,\n.\n3-5\n2.1\nGeneral\n3-5\n2.2\nSupplemental\nStandard\nfor Systems\nDevelopment\n.\n.\n.\n3-5\n2. 2 J\nCommentary\n„\n.\n.\n„\n.\n.\n.\n3-6\n2.3\nSupplemental\nStandard\nfor Operational\nSystems\n(Application\nControls)\no\no\n.\n3-7\n2.3.1\nCommentary\n3-7\n2.4\nSupplemental\nStandard\nfor Physical\nSecurity and\nGeneral\nControls\no\n3-8\n2o4.1\nCommentary\n»\n.\n.\no\n.\no\n=\n.\n.\n3-8\n2e5\nOther Audit Requirements\n3-10\n3.\nRECOMMENDED COURSE OF ACTION\no\n3-10\n4.\nREFERENCES\no\n3-11\nPART\nIV:\nQUALIFICATIONS AND TRAINING ...........\no\n,\n.\n4-1\nEDITORS'\nNOTE\n.\n.\n.\n.\n4-2\nQualifications\nand Training\n.\n4-3\n•\n0\nINTRODUCTION\n4-3\n0\nCONSIDERATIONS ASSOCIATED WITH\nDEVELOPING A COMMON\nBODY OF KNOWLEDGE .........\n4-3\n0\nTHE EIGHT\nPARTS OF THE COMMON BODY OF KNOWLEDGE .....\n4-6\n1.\nCOMPUTER SYSTEM,\nOPERATIONS, AND SOFTWARE\n4-6\n2.\nDATA PROCESSING TECHNIQUES\n.........\n4-7\n3.\nMANAGEMENT OF THE\nDATA PROCESSING FUNCTION\n„\n.\n„\n.\no\n.\n.\n4-7\n4.\nSECURITY OF THE\nDATA PROCESSING\nFUNCTION\no\n.\n4-7\n5„\nRISK ANALYSIS AND THREAT ASSESSMENT ..........\n4-8\n6.\nMANAGEMENT CONCEPTS AND PRACTICES\no\n.\no\n.\no\n4-8\n\"\n7.\nAUDITING CONCEPTS AND PRACTICES\n.\n.\n.\n.\no\no\n.\n.\no\n.\no\n.\n4-9\n8.\nBASIC QUALIFICATIONS NEEDED TO EVALUATE COMUTER\nSECURITY\n4-9\n0\nOUTLINE OF THE\nCOMMON\nBODY OF KNOWLEDGE\n.\n.\n.\n.\no\n.\no\no\no\n4-11\n0\nBIBLIOGRAPHY\n4-13\nPART\nV:\nSECURITY ADMINISTRATION\n.\n.\n.\no\n.......\n5-1\nEDITORS'\nNOTE\no\n.\n.\n5-2\nle\nINTRODUCTION\no\n5-3\nlal\nGeneral\no\n.\n.\n.\n.\n5-3\n1.2\nPrivacy Legislation\n.\no\no\n.\no\no\n.\n.\n.\n.\n5-4\n1.201\nThe Privacy Act of 1974\no\n.\n.\no\n5-4\n1.202\nLaws\nin Other Countries\n5-4\nle2.3\nInternational\nPrivacy Law Compatibility\n.\n.\n5-5\n1.3\nOrganization of this\nReport\n.\n.\no\n.\n.\n5-5\nvi ii"
  },
  {
    "chunk_id": "Automated Information System Security Accreditation Guidelines_first10_chunk_0",
    "filename": "Automated Information System Security Accreditation Guidelines_first10.pdf",
    "page_num": 1,
    "text": "NISTIR 4378\nAUTOMATED\nINFORMATION\nSYSTEM SECURITY\nACCREDITATION\nGUIDELINES\nU.S. Department of Transportation\nFederal Aviation Administration\nEdward Roback\nNIST Coordinator\nU.S. DEPARTMENT OF COMMERCE\nNational institute of Standards\nand Technology\nGaithersburg, MD 20899\nU.S. DEPARTMENT OF COMMERCE\nRobert A. Mosbacher, Secretary\nNATIONAL INSTITUTE OF STANDARDS\nAND TECHNOLOGY\nJohn W. Lyons, Director\nNIST"
  },
  {
    "chunk_id": "Automated Information System Security Accreditation Guidelines_first10_chunk_1",
    "filename": "Automated Information System Security Accreditation Guidelines_first10.pdf",
    "page_num": 3,
    "text": "NISTIR 4378\nAUTOMATED\nINFORMATION\nSYSTEM SECURITY\nACCREDITATION\nGUIDELINES\nU.S. Department of Transportation\nFederal Aviation Administration\nEdward Roback\nNIST Coordinator\nU.S. DEPARTMENT OF COMMERCE\nNational Institute of Standards\nand Technology\nGaithersburg, MD 20899\nAugust 1990\nU.S. DEPARTMENT OF COMMERCE\nRobert A. Mosbacher, Secretary\nNATIONAL INSTITUTE OF STANDARDS\nAND TECHNOLOGY\nJohn W. Lyons, Director"
  },
  {
    "chunk_id": "Automated Information System Security Accreditation Guidelines_first10_chunk_2",
    "filename": "Automated Information System Security Accreditation Guidelines_first10.pdf",
    "page_num": 5,
    "text": "Preface\nThis\nNational\nInstitute\nof\nStandards\nand\nTechnology\nInteragency\nReport\n(NISTIR)\npresents\nthe\nFederal\nAviation\nAdministration's\nAutomated\nInformation\nSystem\nSecurity\nAccreditation\nGuidelines.\nThis\ndocument\nprovides\nprocedures\nfor\nthe\npreparation\nof\ndocumentation\nfor\nthe\nsecurity\naccreditation\nof\nautomated\ninformation systems.\nThe National Institute of Standards and Technology\n(NIST)\nmakes no\nclaim\nor\nendorsement\nof\nthis\nmethodology.\nHowever,\nas\nthis\nmaterial may be of use to other organizations,\nthe report\nis being\nreprinted by NIST to provide for broad public dissemination of this\nfederally sponsored work.\nThis publication is part of a continuing\neffort to assist federal agencies in accordance with NIST's mandate\nunder the Computer Security Act\nof\n1987.\nNIST\nexpresses\nits\nappreciation\nto\nthe\nFederal\nAviation\nAdministration,\nU.S.\nDepartment\nof\nTransportation,\nfor\ntheir\npermission to publish this\nreport.\nQuestions\nregarding\nthis\npublication\nshould\nbe\naddressed\nto\nthe\nAssociate Director for Computer Security, National Computer Systems\nLaboratory,\nBuilding\n225,\nRoom\nB154,\nNational\nInstitute\nof\nStandards and Technology,\nGaithersburg,\nMD,\n20899.\nAdditional copies of this publication may be purchased through the\nNational\nTechnical\nInformation\nService,\nSpringfield,\nVA,\n22161,\ntelephone:\n(703)\n487-4650."
  },
  {
    "chunk_id": "Automated Information System Security Accreditation Guidelines_first10_chunk_3",
    "filename": "Automated Information System Security Accreditation Guidelines_first10.pdf",
    "page_num": 7,
    "text": "AUTOMATED INFORMATION SYSTEM\nSECURITY ACCREDITATION GUIDELINES\n30 November\n1989\nDEPARTMENT OF TRANSPORTATION\nFEDERAL AVIATION ADMINISTRATION\nv"
  },
  {
    "chunk_id": "Automated Information System Security Accreditation Guidelines_first10_chunk_4",
    "filename": "Automated Information System Security Accreditation Guidelines_first10.pdf",
    "page_num": 9,
    "text": "CONTENTS\nSECTION\nPAGE\nPURPOSE\n1\nDEFINITION\n1\nRESPONSIBILITY\n1\nTHE REQUIREMENT\n2\nDPI AND DPA IDENTIFICATION\n2\nSCHEDULE\n5\n1.\nPROPOSED DATES\n5\n2.\nACTUAL COMPLETION DATES\n6\n3.\nREVISIONS\n6\nTHE ACCREDITATION REPORT\n8\n1.\nTITLE PAGE\n8\n2.\nTABLE OF CONTENTS\n10\n3.\nDPA SECURITY PROFILE\n10\n4.\nOFFICE AUTOMATION DPA RISK ASSESSMENT\n17\n5 .\nLAVA\n2 8\n6.\nCONTINGENCY PLAN\n29\n7.\nSENSITIVE APPLICATION SECURITY CERTIFICATION\nSTATEMENTS\n3 2\n8.\nSUMMARY\n33\n9.\nACCREDITATION REQUEST\n33\nTRANSMITTAL\n3 5\nACCREDITATION ACTION\n35\nAPPENDIX\ni\nAISSM\ni\nAISSC\ni\nTHE DAA\nii\nFORMS\n1.\nDPA Security Profile\n13\n2.\nOffice Automation DPA Risk Assessment\n19\n3.\nContingency Plan Waiver\n31\n4.\nSensitive Application Security Certification Waiver\n34\n5.\nAccreditation Request\n37\n6.\nAccreditation Statement\n38\nvi\ni\nContents Page No.\ni"
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_0",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 1,
    "text": "NIST Cybersecurity White Paper \nNIST CSWP 30 \nAutomation Support for Control \nAssessments \nProject Update and Vision \n8011\nSERIES\nAUTOMATION SUPPORT FOR\nCONTROL ASSESSMENTS\nIR 8011\nEduardo Takamura \nJeremy Licata \nVictoria Pillitteri \nComputer Security Division \nInformation Technology Laboratory \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.CSWP.30 \nDecember 6, 2023"
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_1",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 2,
    "text": "Automation Support for \nNIST CSWP 30 \nDecember 6, 2023 \nControl Assessments \nCertain equipment, instruments, software, or materials, commercial or non-commercial, are identified in this \npaper in order to specify the experimental procedure adequately. Such identification does not imply \nrecommendation or endorsement of any product or service by NIST, nor does it imply that the materials or \nequipment identified are necessarily the best available for the purpose. \nNIST Technical Series Policies \nCopyright, Use, and Licensing Statements \nNIST Technical Series Publication Identifier Syntax \nPublication History \nApproved by the NIST Editorial Review Board on 2023-11-27 \nHow to Cite this NIST Technical Series Publication:  \nTakamura E, Licata J, Pillitteri V (2023) Automation Support for Control Assessments: Project Update and Vision. \n(National Institute of Standards and Technology, Gaithersburg, MD), NIST Cybersecurity White Paper (CSWP) NIST \nCSWP 30. https://doi.org/10.6028/NIST.CSWP.30   \nAuthor ORCID iDs \nEduardo Takamura: \n0000-0002-9978-9050 \nJeremy Licata:  \n \n0000-0001-8793-5471 \nVictoria Pillitteri:   \n0000-0002-7446-7506 \nContact Information \n8011comments@list.nist.gov \nNational Institute of Standards and Technology \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 \nAll comments are subject to release under the Freedom of Information Act (FOIA)."
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_2",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 3,
    "text": "Automation Support for \nNIST CSWP 30 \nDecember 6, 2023 \nControl Assessments \ni \nAbstract \nIn 2017, the National Institute of Standards and Technology (NIST) published a methodology for \nsupporting the automation of Special Publication (SP) 800-53 control assessments in the form \nof Interagency Report (IR) 8011. IR 8011 is a multi-volume series that starts with an overview of \nthe methodology (volume 1) and provides guidance and specifications for automating the \nassessment of controls that support specific information security continuous monitoring \nsecurity capabilities, one volume per capability. Four volumes have been released so far, and \nmore volumes are in development. In 2023, the NIST Risk Management Framework project — \nresponsible for the development and maintenance of Federal Information Security \nModernization Act (FISMA)-supporting technical publications and the IR 8011 series — \nperformed an internal review of the IR 8011 project. This review yielded results that offered the \nIR 8011 Development Team opportunities to improve the current IR 8011 methodology, \nfacilitate its adoption, and more. This cybersecurity white paper summarizes some of the \nfindings from this internal review. \nKeywords \nactual state; assessment; attack; automation; capability; community of interest; CoI; control; \ncontrol assessment; control item; defect; defect check; defend; desired state specification; \nFISMA; information security continuous monitoring; ISCM; methodology; monitoring; ongoing \nassessment; privacy; risk; risk management; security; security automation."
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_3",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 4,
    "text": "Automation Support for \nControl Assessments \nii \nNIST CSWP 30 \nDecember 6, 2023 \nTable of Contents \n1. Introduction ...................................................................................................................................1 \n2. Updates to the IR 8011 Methodology ..............................................................................................2 \n3. Updated Guidance and Updated Language ......................................................................................6 \n4. Interested Party Engagement .........................................................................................................7 \n5. Operationalization of IR 8011 .........................................................................................................8 \n6. IR 8011 Project and Development Roadmap ...................................................................................9 \n7. Conclusion ................................................................................................................................... 10 \nReferences ....................................................................................................................................... 11 \nAppendix A. Notional Implementations and Uses for IR 8011 ............................................................ 12 \nList of Tables \nTable 1. Updated IR 8011 methodology workflow output summary ....................................................5 \nList of Figures \nFig. 1. IR 8011 methodology workflow summarized as security capability abstraction layers ................3 \nFig. 2. Updated IR 8011 methodology workflow with output ...............................................................4"
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_4",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 5,
    "text": "Automation Support for \nControl Assessments \niii \nNIST CSWP 30 \nDecember 6, 2023 \nAcknowledgments \nThe authors would like to thank Kelley Dempsey, Paul Eavy, George Moore, and all past \ncollaborators for their historical contributions to the IR 8011 project, including helping establish \nthe foundation on which IR 8011 is built; Jim Foti for layout, formatting, and styling guidance \nand support; Isabel Van Wyk for copy editing this publication; and Ned Goren and Allen \nWilkinson for reviewing this paper. \nTerminology and Conventions \nKey concepts are introduced and described in IR 8011, Volume 1 [2], including terms such as \ndesired and actual state, defect check, and attack and block steps. One important term that is \nused throughout the IR 8011 series is capability, specifically security capability. NIST \npublications, including those that support the NIST Risk Management Framework (RMF)1\n1 The NIST Risk Management Framework (RMF) is described in NIST Special Publication 800-37 [\n, refer \nto capability to express the potential to achieve an objective, whether it is a security objective \nor a privacy objective. In many cases, this potential is provided through the implementation of \ncontrols. In the context of IR 8011, the term capability refers to the potential provided by a set \nof controls to achieve a common objective. The objective in this case is the defense against a \npossible but specific attack that can compromise the confidentiality, integrity, and availability of \ninformation including private information. Meeting this objective means having a functional \ncapability. This functional capability is associated with the defense capability of a system or \norganization against an attack or attack vector and is further broken down into sub-capabilities. \nSub-capabilities facilitate the automation of control assessments that focus on the testable \nparts of the controls. The actual tests are what IR 8011 refers to as defect checks.  \nThe premise of IR 8011 is supporting the automation of control assessments, which in turn can \nenable information security continuous monitoring (ISCM) 2\n2 For more on continuous monitoring and continuous monitoring strategy, see SP 800-37 [\n, ongoing assessment, and ongoing \nauthorization.3\n3 For more on ongoing assessments and ongoing authorization, see SP 800-37 [\n The term ISCM security capability will be maintained in a future revision to IR \n8011, Volume 1 [2] as a legacy term. A proposed updated methodology for IR 8011 will be \ndisassociated from ISCM in order to support other control-based frameworks and provide \nadditional implementation options for its operationalization. New volumes will continue to be \nbased on SP 800-53 controls, and each volume will be dedicated to a specific ISCM security \ncapability. \nWhen referring to the individual documents or collection of volumes comprising the series, the \nauthors use the terms “IR 8011,” “IR 8011 series,” or simply “the Series.” When referring to a \nspecific volume, the authors use “IR 8011vN,” where “N” is the volume number. For example, \nNIST IR 8011, Volume 2 [3] can be expressed as “IR 8011v2,” and NIST IR 8011, Volume 4 [5] can \nbe expressed as “IR 8011v4.” When referring to the NIST project responsible for the \ndevelopment and maintenance of the IR 8011 volumes, the authors use “IR 8011 Project.” “IR \n8011 Team” refers to"
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_5",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 5,
    "text": " volume number. For example, \nNIST IR 8011, Volume 2 [3] can be expressed as “IR 8011v2,” and NIST IR 8011, Volume 4 [5] can \nbe expressed as “IR 8011v4.” When referring to the NIST project responsible for the \ndevelopment and maintenance of the IR 8011 volumes, the authors use “IR 8011 Project.” “IR \n8011 Team” refers to the “IR 8011 Development Team,” which includes members of the NIST \nRMF Team. \n5].  \n5] and SP 800-137 [1]. \n5]."
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_6",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 6,
    "text": "Automation Support for \nNIST CSWP 30 \nDecember 6, 2023 \nControl Assessments \niv \nIn Sec. 4, the term “interested party” is used in lieu of the term “stakeholder” because involved \nparties may or may not have a stake in IR 8011 (e.g., development, implementation/adoption, \nsupport). \nFinally, when automation is not explicit in reference to control testing, there is an assumption \nthat such testing is automated or at least semi-automated. IR 8011 is not about automating the \nimplementation of security and privacy controls. Rather, it is about supporting the assessment \nof controls using automation."
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_7",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 7,
    "text": "Automation Support for \nControl Assessments \n1 \nNIST CSWP 30 \nDecember 6, 2023 \n1. Introduction\nNIST Interagency Report (IR) 8011, Automation Support for Security Control Assessments, is a \nmulti-volume series that provides a blueprint for supporting automated control assessments. It \nproposes an approach for creating specific tests (denominated defect checks) that can be \nexecuted using automation to help verify that controls are in place and operating as expected. \nIR 8011 supports the NIST Risk Management Framework (RMF) — the methodology for \nmanaging security and privacy risks that is described in NIST Special Publication (SP) 800-37, \nRisk Management Framework for Information Systems and Organizations: A System Life Cycle \nApproach for Security and Privacy [5]. It expands on the guidance provided by SP 800-53A, \nAssessing Security and Privacy Controls in Information Systems and Organizations [9], which is \nthe guide for assessing SP 800-53, Security and Privacy Controls for Information Systems and \nOrganizations [7]. IR 8011 was developed to ultimately support information security continuous \nmonitoring (ISCM) activities4\n4 See SP 800-137 [1] for more information on developing a continuous monitoring strategy and on implementing a continuous monitoring \nprogram. \n, including ongoing assessments and ongoing authorizations.5\n5 See SP 800-37 [4] for more information on the NIST RMF, RMF steps, ISCM, ongoing assessments, and ongoing authorizations. \n \nThe first volume in the IR 8011 series (Overview) establishes the approach and organization of \nthe methodology that is followed and adhered to by subsequent volumes. Both the Overview \nvolume (8011v1 [2]) and the first capability-specific volume (Hardware Asset Management [3]) \nwere published in 2017. The second capability-specific volume (Software Asset Management \n[4]) was released in 2018, and the third capability-specific volume (Software Vulnerability \nManagement [6]) was published in 2020. NIST updated SP 800-53 [7] in 2020 and SP 800-53A \n[9] in 2022.\nThe NIST RMF Project performed a full review of the IR 8011 series in preparation for aligning \nthe IR 8011 publications with the major revisions to key RMF publications, namely SP 800-53 \n[7], SP 800-53B [8], and SP 800-53A [9]. In the process, the Team identified a number of \nopportunities for improving IR 8011, ranging from an updated IR 8011 methodology and \nguidance to the potential for the operationalization of IR 8011. \nThis paper summarizes some of the findings from this internal review of the IR 8011 Project. It \nprovides a glimpse of what is coming next and updates the IR 8011 development and \nmaintenance roadmap. The authors recommend reviewing IR 8011v1 prior to proceeding. The \ninternal review conducted in 2023 considered past analysis work and previously obtained \nfeedback from the public to identify opportunities for improvement to the Series. Most of the \npublic comments were received in response to the IR 8011v4 [5] draft comments and the \nFebruary 2023 call for adoption feedback [9]."
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_8",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 8,
    "text": "Automation Support for \nNIST CSWP 30 \nDecember 6, 2023 \nControl Assessments \n2 \n2. Updates to the IR 8011 Methodology\nThree updates to the IR 8011 methodology are planned:\n1. Restructuring the IR 8011 workflow to improve readability and make it easier to\nunderstand.\n2. Expanding the scope of the keyword search function to include additional control\ndescriptors (e.g., the “Discussion” text of each control).\n3. Abstracting the security framework so that the model can be used with any control-\nbased (or requirement-based) framework, which also supports the development of\ndefect checks for any control/control family, not just for ISCM security capabilities (see\nSec. 2.3).\nNote: the abstraction of the security framework is only intended to promote wider\nadoption of the methodology for the development of defect checks. For IR 8011, the\ndevelopment of new volumes will continue to be based on the SP 800-53 control\ncatalog, focusing on a given ISCM security capability – one capability per volume – as\ndesigned.\n Logical Workflow6\n6 This section covers the original (legacy) IR 8011 methodology presented by IR 8011v1 [2] (2017). \n \nUnderstanding the methodology is key to adoption, so the order in which the IR 8011 elements \nare presented in IR 8011v1 [2] will be updated to improve readability. For example, the \nworkflow will be presented in a staged manner with a description of each stage (including \nindividual stages for each abstraction layer in the methodology) and what occurs in them, \nsimilar to phases or steps being described in a process.  \nAs a preview, the original IR 8011 methodology will be further explained using the following \nupdated workflow: \n1. For each ISCM security capability, identify potential attacks/attack vectors.7\n7 This is a reference to the attack step abstraction layer (IR 8011v1 [1], Sec. 3). \n2. For each attack/attack vector, determine the necessary defense. This will become the\nfunctional capability8\n8 This is a reference to the functional capability abstraction layer (IR 8011v1 [1], Sec. 3) \n (i.e., the security capability9\n9 Not to confuse with “ISCM security capability.” \n to defend against attacks).\n3. For each defense (referred to as “block or delay” in IR 8011v1 [2]), determine what can\nbe tested via automated means. These will become sub-capabilities.10\n10 This is a reference to the sub-capability abstraction layer (IR 8011v1 [1], Sec. 3) \n4. For each sub-capability, specify the desired states.11\n11 The desired states should include any organization-defined parameter (ODP) values. \n These will become control items.\n5. For each desired state specification, determine how an actual state can be tested. These\nwill become defect checks."
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_9",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 9,
    "text": "Automation Support for \nNIST CSWP 30 \nDecember 6, 2023 \nControl Assessments \n3 \nFigure 1 lays out the four security capability abstraction layers (discussed in Sec. 3 of IR 8011, \nVolume 1 [2]) followed by the defect check component, which refers to the necessary tests that \ncan be automated in support of an assessment against an ISCM security capability \nimplementation. \n Keyword Searches \nOne of the main goals of IR 8011 is the development of defect checks. The defect check \ndevelopment process in the IR 8011 methodology relies heavily on searches of a control source \n(i.e., control catalog) using specific keywords to identify controls. If the appropriate keywords \nare not used, the correct controls may not be found.12\n12 As a result, false positives and false negatives may occur. \n Control catalogs (i.e., the source) may \nhave different structures with both normative and informative content.  \nThe methodology will be updated to expand the scope of the keyword search to include SP 800-\n53 [7] control discussion text in addition to the control title and description. Additional \nguidance will also be included regarding the use of synonyms for keyword searches to avoid \nlimiting searches to a single variation of a word. \nFinally, IR 8011v1 [2] will include a discussion on the limitation of the current keyword search \nprocess, a limitation that one day may be addressed by artificial intelligence to enhance and \nimprove the control search process.  \n Security Framework Abstraction \nThe original IR 8011 methodology described in IR 8011v1 [2] focuses on the development of \ndefect checks in support of ISCM security capabilities13\n13 IR 8011v1 [2] enumerates all ISCM security capabilities that will be addressed by IR 8011. \n, and each volume in the IR 8011 series is \ndedicated to a single ISCM security capability. Thus, the defect checks in each IR 8011 volume \nare derived from the identified potential attacks/attack vectors against an ISCM security \ncapability (see Fig. 1 above for the methodology workflow).  \nThe IR 8011 methodology is being slightly modified and adapted to support the development of \ndefect checks for any control, control item, or control family, and not just for a specific ISCM \nsecurity capability. This updated methodology will be described in the next revision to IR \n8011v1. Figure 2 provides a preview of the updated methodology workflow highlighting the \n(1) \nAttack \nStep \nLayer \n(2) \nFunctional \nCapability \nLayer \n(3) \nSub-\nCapability \nLayer \n(4) \nControl \nItems \nLayer \n(5) \nDefect \nCheck \nFig. 1. IR 8011 methodology workflow summarized as security capability abstraction layers"
  },
  {
    "chunk_id": "Automation Support for Control Assessments_ Project Update and Vision_first10_chunk_10",
    "filename": "Automation Support for Control Assessments_ Project Update and Vision_first10.pdf",
    "page_num": 10,
    "text": "Automation Support for \nNIST CSWP 30 \nDecember 6, 2023 \nControl Assessments \n4 \nstages and the outcomes of each stage of the model. Table 1 further describes the output of \neach stage of the workflow. \nThis update to the IR 8011 methodology will not affect the maintenance of existing volumes in \nthe Series or the development of new volumes, which will continue to focus on defect checks \nfor specific ISCM security capabilities utilizing the NIST SP 800-53 control catalog.  \n8011\nATTACK STEP\nATTACKER \nACTION\nDEFENDER\nACTION\nDEFEND STEP\nFUNCTIONAL\nCAPABILITY\nDESIRED \nSTATE\nDEFINE\nDEFENDER\nIMPLEMENTATION\nDEFECT  \nCHECK\nDEFINE\nIMPLEMENTATION\nVARIANCE\nAUTOMATED\nTESTING\nSUB-\nCAPABILITY\nDEFINE\nDEFENDER \nCAPABILITY\nACTIONS\nDEFINE DEFENDER \nCAPABILITY\n8011\nMethod Flow\nOne-to-Many Process Flow\nProcess Association\nOne-to-One Process Flow\nManual Process\nMethodology Stage\nAutomated Process\nData Flow\nLEGEND\nFig. 2. Updated IR 8011 methodology workflow with output"
  },
  {
    "chunk_id": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10_chunk_0",
    "filename": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10.pdf",
    "page_num": 1,
    "text": "NISTIR 8011 \nVolume 1 \nAutomation Support for  \nSecurity Control Assessments \nVolume 1: Overview \nKelley Dempsey \nPaul Eavy \nGeorge Moore \n \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8011-1"
  },
  {
    "chunk_id": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10_chunk_1",
    "filename": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10.pdf",
    "page_num": 2,
    "text": "NISTIR 8011 \nVolume 1 \nAutomation Support for  \nSecurity Control Assessments \nVolume 1: Overview \nKelley Dempsey \nComputer Security Division \nInformation Technology Laboratory \n \nPaul Eavy \nFederal Network Resilience Division \nDepartment of Homeland Security \n \nGeorge Moore \nJohns Hopkins University \nApplied Physics Laboratory \n \n  \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8011-1 \n \n \nJune 2017 \n \n \n \n \nU.S. Department of Commerce  \nWilbur L. Ross, Jr., Secretary \n \nNational Institute of Standards and Technology  \nKent Rochford, Acting NIST Director and Under Secretary of Commerce for Standards and Technology"
  },
  {
    "chunk_id": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10_chunk_2",
    "filename": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10.pdf",
    "page_num": 3,
    "text": "National Institute of Standards and Technology Interagency Report 8011, Volume 1 \n93 pages (June 2017) \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.IR.8011-1 \nCertain commercial entities, equipment, or materials may be identified in this document in order to describe \nan experimental procedure or concept adequately. Such identification is not intended to imply \nrecommendation or endorsement by NIST, nor is it intended to imply that the entities, materials, or equipment \nare necessarily the best available for the purpose. \nThere may be references in this publication to other publications currently under development by NIST in \naccordance with its assigned statutory responsibilities. The information in this publication, including \nconcepts and methodologies, may be used by federal agencies even before the completion of such companion \npublications. Thus, until each publication is completed, current requirements, guidelines, and procedures, \nwhere they exist, remain operative. For planning and transition purposes, federal agencies may wish to \nclosely follow the development of new publications by NIST.  \nOrganizations are encouraged to review all draft publications during public comment periods and provide \nfeedback to NIST. Many NIST information security publications, other than the ones noted above, are \navailable at http://csrc.nist.gov/publications.  \n \n \nComments on this publication may be submitted to: \nNational Institute of Standards and Technology  \nAttn: Computer Security Division, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930  \nEmail: sec-cert@nist.gov \nAll comments are subject to release under the Freedom of Information Act (FOIA)."
  },
  {
    "chunk_id": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10_chunk_3",
    "filename": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10.pdf",
    "page_num": 4,
    "text": "NISTIR 8011 VOL. 1 \n \nAUTOMATION SUPPORT FOR \n \n \nSECURITY ASSESSMENTS: OVERVIEW \nii \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8011-1 \nReports on Computer Systems Technology \nThe Information Technology Laboratory (ITL) at the National Institute of Standards and \nTechnology (NIST) promotes the U.S. economy and public welfare by providing technical \nleadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test \nmethods, reference data, proof-of-concept implementations, and technical analyses to advance \nthe development and productive use of information technology. ITL’s responsibilities include the \ndevelopment of management, administrative, technical, and physical standards and guidelines for \nthe cost-effective security and privacy of other than national security-related information in \nfederal systems. \nAbstract \nThis volume introduces concepts to support automated assessment of most of the security \ncontrols in NIST Special Publication (SP) 800-53. Referencing SP 800-53A, the controls are \ndivided into more granular parts (determination statements) to be assessed. The parts of the \ncontrol assessed by each determination statement are called control items. The control items are \nthen grouped into the appropriate security capabilities. As suggested by SP 800-53 Revision 4, \nsecurity capabilities are groups of controls that support a common purpose. For effective \nautomated assessment, testable defect checks are defined that bridge the determination statements \nto the broader security capabilities to be achieved and to the SP 800-53 security control items \nthemselves. The defect checks correspond to security sub-capabilities—called sub-capabilities \nbecause each is part of a larger capability. Capabilities and sub-capabilities are both designed \nwith the purpose of addressing a series of attack steps. Automated assessments (in the form of \ndefect checks) are performed using the test assessment method defined in SP 800-53A by \ncomparing a desired and actual state (or behavior). \nKeywords \nactual state; assessment; assessment boundary; assessment method; authorization boundary; \nautomated security control assessment; automation; capability; continuous diagnostics and \nmitigation; information security continuous monitoring; dashboard; defect; defect check; desired \nstate specification; ISCM dashboard; mitigation; ongoing assessment; root cause analysis; \nsecurity automation; security capability; security control; security control assessment; security \ncontrol item."
  },
  {
    "chunk_id": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10_chunk_4",
    "filename": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10.pdf",
    "page_num": 5,
    "text": "NISTIR 8011 VOL. 1 \n \nAUTOMATION SUPPORT FOR \n \n \nSECURITY ASSESSMENTS: OVERVIEW \niii \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8011-1 \nAcknowledgments \nThe authors, Kelley Dempsey of the National Institute of Standards and Technology (NIST), \nDr. George Moore of the Applied Physics Laboratory at Johns Hopkins University, and Paul \nEavy of the Department of Homeland Security, wish to thank their colleagues who reviewed \ndrafts of this document, including Nadya Bartol, Craig Chase, Ann Dixon, Terry Fletcher, Jim \nFoti, Susan Hansche, Amy Heydman, Alicia Jones, Betsy Kulick, Elizabeth Lennon, Susan \nPagan, Daniel Portwood, Ron Ross, Martin Stanley, Kevin Stine, Robin Walker, David \nWaltermire, Kimberly Watson, and Jim Wiggins. The authors also gratefully acknowledge and \nappreciate the comments and contributions made by government agencies, private \norganizations, and individuals in providing direction and assistance in the development of this \ndocument."
  },
  {
    "chunk_id": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10_chunk_5",
    "filename": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10.pdf",
    "page_num": 6,
    "text": "NISTIR 8011 VOL. 1 \n \nAUTOMATION SUPPORT FOR \n \n \nSECURITY ASSESSMENTS: OVERVIEW \niv \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8011-1 \nTable of Contents \nExecutive Summary ..................................................................................................................... ix \n1. Introduction ................................................................................................................................1 \n1.1 Purpose and Scope..................................................................................................................1 \n1.2 Target Audience ......................................................................................................................2 \n1.3 Organization of Volume 1 .......................................................................................................3 \n2. Overview of an Automated Security Control Assessment Process .......................................4 \n2.1 Prerequisites to Automated Security Control Assessment ......................................................4 \n2.2 Automating the Test Assessment Method ................................................................................5 \n2.2.1 Terms for Referring to Assessment Objects ......................................................................6 \n2.3 Factors for Determining When to Trust Automated Ongoing Assessments ...........................6 \n2.4 An Automated Security Control Assessment Program: ISCM ................................................7 \n2.5 Preparing for Automated Security Control Assessments ........................................................9 \n3. Focusing Security Control Assessments on Security Results ...............................................10 \n3.1 Applying Security Capabilities to Automated Assessments ..................................................11 \n3.1.1 Supports Strong Systems Engineering of Security Capabilities .....................................11 \n3.1.2 Supports Guidance for Control Selection .......................................................................11 \n3.1.3 Simplifies Understanding of the Overall Protection Process .........................................12 \n3.1.4 Enables Assessment of Security Results at a Higher Level than Individual Controls ....12 \n3.1.5 Improves Risk Management by Measuring Security Results More Closely Aligned with \nDesired Business Results ............................................................................................12 \n3.2 Attack Steps ...........................................................................................................................13 \n3.2.1 Adversarial Attack Step Model .......................................................................................14 \n3.3 Security Capabilities .............................................................................................................17 \n3.3.1 SP 800-53 Control Families and Security Capabilities ..................................................17 \n3.3.2 SP 800-137 Security Automation Domains and Security Capabilities ...........................17 \n3.3.3 Using Security Capabilities in Security Control Assessment .........................................18 \n3.3.4 Security Capabilities and ISCM......................................................................................18 \n3.3.5 Example Security Capabilities Listed and Defined ........................................................18"
  },
  {
    "chunk_id": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10_chunk_6",
    "filename": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10.pdf",
    "page_num": 7,
    "text": "NISTIR 8011 VOL. 1 \n \nAUTOMATION SUPPORT FOR \n \n \nSECURITY ASSESSMENTS: OVERVIEW \nv \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8011-1 \n3.3.6 Tracing Requirements: Mapping Capability to Attack Steps .........................................23 \n3.3.7 Organization-Defined Security Capabilities...................................................................23 \n3.4 Sub-Capabilities....................................................................................................................24 \n3.4.1 Examples of Sub-Capabilities (from HWAM) .................................................................24 \n3.4.2 Tracing Sub-Capabilities to Attack Steps .......................................................................26 \n3.5 Security Control Items ..........................................................................................................26 \n3.5.1 Tracing Security Control Items to Attack Steps ..............................................................26 \n3.5.2 Tracing Security Control Items to Capabilities ..............................................................27 \n3.5.3 Tracing Security Control Items to Sub-Capabilities .......................................................29 \n3.6 Synergies Across Each Abstraction Level ............................................................................29 \n3.6.1 Multiple Capabilities Support Addressing Each Attack Step .........................................29 \n3.6.2 Many Controls Support Multiple Capabilities ................................................................30 \n4. Using Actual State and Desired State Specification to Detect Defects ................................32 \n4.1 Actual State and Desired State Specification .......................................................................32 \n4.2 Collectors and the Collection System ...................................................................................32 \n4.2.1 Actual State Collectors ...................................................................................................32 \n4.2.2 Collection of Desired State Specifications ......................................................................32 \n4.2.3 The Collection System .....................................................................................................33 \n4.3 Authorization Boundary and Assessment Boundary .............................................................34 \n4.3.1 System Authorization Boundary ......................................................................................35 \n4.3.2 ISCM Assessment Boundary ...........................................................................................35 \n4.3.3 Tracing System Risk to its Sources .................................................................................37 \n4.4 The Desired State Specification ............................................................................................38 \n4.4.1 Types of Desired State Specifications .............................................................................39 \n4.4.2 Desired State Specification Reflects Policy ....................................................................40 \n4.4.3 Desired State Specification Demonstrates the Existence of Policy ................................40 \n4.5 Using Automation to Compare Actual State and Desired State Specification .....................41 \n5. Defect Checks ...........................................................................................................................42 \n5.1 Defect Checks and Determination Statements ......................................................................42 \n5.2 Interpreting Defect Checks as Tests of Control Items ..........................................................43 \n5.3 Interpreting Defect Checks as Tests of Sub-Capabilities and Control Items .......................43"
  },
  {
    "chunk_id": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10_chunk_7",
    "filename": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10.pdf",
    "page_num": 8,
    "text": "NISTIR 8011 VOL. 1 \n \nAUTOMATION SUPPORT FOR \n \n \nSECURITY ASSESSMENTS: OVERVIEW \nvi \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8011-1 \n5.4 Defect Check Documentation ...............................................................................................47 \n5.5 Data Quality Measures .........................................................................................................49 \n5.6 Assessment Criteria Device Groupings to Consider ............................................................49 \n5.7 Why Not Call Defects Vulnerabilities or Weaknesses? ........................................................50 \n5.8 Security Controls Selected/Not Selected and Defect Checks ................................................50 \n5.9 Foundational and Local Defect Checks................................................................................51 \n5.10 Documenting Tailoring Decisions ......................................................................................52 \n6. Assessment Plan Documentation ............................................................................................53 \n6.1 Introduction to Security Assessment Plan Narratives ..........................................................53 \n6.2 Assessment Scope ..................................................................................................................54 \n6.3 Determination Statements within the Narratives ..................................................................55 \n6.4 Roles and Assessment Methods in the Narratives ................................................................55 \n6.5 Defect Check Rationale Table ..............................................................................................56 \n6.6 Tailoring of Security Assessment Plan Narratives ...............................................................56 \n6.7 Control Allocation Tables .....................................................................................................57 \n6.8 Documenting Selected Controls and Tailoring Decisions ....................................................58 \n7. Root Cause Analysis ................................................................................................................60 \n7.1 Knowing Who Is Responsible ...............................................................................................60 \n7.2 Root Cause Analysis .............................................................................................................60 \n7.2.1 Root Cause Analysis How-to: Controls ..........................................................................61 \n7.2.2 Root Cause Analysis How-to: Defect Types ...................................................................62 \n8. Roles and Responsibilities .......................................................................................................66 \n8.1 SP 800-37-Defined Management Responsibilities ...............................................................66 \n8.2 ISCM Operational Responsibilities ......................................................................................66 \n9. Relationship of Automated Security Control Assessment to the NIST Risk Management \nFramework .......................................................................................................................69 \n9.1 Linking ISCM to Specific RMF Assessment Tasks................................................................69 \nAppendix A. References ........................................................................................................... A-1 \nAppendix B. Glossary ................................................................................................................B-1 \nAppendix C. Acronyms and Abbreviations ............................................................................ C-1"
  },
  {
    "chunk_id": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10_chunk_8",
    "filename": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10.pdf",
    "page_num": 9,
    "text": "NISTIR 8011 VOL. 1 \n \nAUTOMATION SUPPORT FOR \n \n \nSECURITY ASSESSMENTS: OVERVIEW \nvii \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8011-1 \n \nList of Figures \nFigure 1: Overview of an Automated Security Control Assessment Process ..................................8 \nFigure 2: Attack Step Model ..........................................................................................................14 \nFigure 3: ISCM Security Capabilities Used in this NISTIR ..........................................................19 \nFigure 4: Capabilities Work Together to Block Attack Steps .......................................................30 \nFigure 5: ISCM Collection System ................................................................................................34 \nFigure 6: Focus of Defect Checks and Determination Statements ................................................44 \nFigure 7: Example of a Security Assessment Plan Narrative ........................................................54 \nFigure 8: Flow of Cause and Effect from Control Items to Security Results ................................61"
  },
  {
    "chunk_id": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10_chunk_9",
    "filename": "Automation Support for Security Control Assessments_ Volume 1_ Overview_first10.pdf",
    "page_num": 10,
    "text": "NISTIR 8011 VOL. 1 \n \nAUTOMATION SUPPORT FOR \n \n \nSECURITY ASSESSMENTS: OVERVIEW \nviii \n \nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8011-1 \nList of Tables \nTable 1: SP 800-53A Assessment Methods .....................................................................................5 \nTable 2: Descriptions of the Attack Steps......................................................................................15 \nTable 3: ISCM Security Capabilities .............................................................................................20 \nTable 4: Tracing the HWAM Capability to Blocking Attack Steps ..............................................23 \nTable 5: Selected Examples of Sub-Capabilities (HWAM) ..........................................................25 \nTable 6: Example of Tracing HWAM Security Control Items to Attack Steps ............................27 \nTable 7: Illustrative Keyword Rules to Map to Capabilities .........................................................28 \nTable 8: Tracing Control Items to the HWAM Capability (EXAMPLE) .....................................28 \nTable 9: Tracing Control Items to the Sub-Capabilities: Selected Examples for the Prevent \nAuthorized Devices without a Device Manager Sub-Capability ...........................29 \nTable 10: Example of a Control Item Supporting Multiple Capabilities .......................................31 \nTable 11: Types of Desired State Specifications ...........................................................................39 \nTable 12: Equivalence of Prohibited and Desired State Specification – An Example ..................39 \nTable 13: Example Control and Determination Statements ..........................................................42 \nTable 14: Sensitivity and Specificity Notes ...................................................................................45 \nTable 15: Sample Rows from a Hypothetical Sub-Capability and Defect Check Descriptiona ....47 \nTable 16: Data Quality Measures ..................................................................................................49 \nTable 17: Example of a Control Item and Its Determination Statements ......................................55 \nTable 18: Control Allocation Table Column Explanations ...........................................................58 \nTable 19: Notional Control Allocation Table – Example ..............................................................59 \nTable 20: Notional Way to Look up Controls Tested by a Defect Check .....................................64 \nTable 21: Impact Scenarios/Impact Analysis ................................................................................65 \nTable 22: SO and SSO Responsibilities.........................................................................................66 \nTable 23: Notional Example of ISCM Operational Roles for HWAM .........................................67"
  }
]